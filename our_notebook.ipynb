{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52777f1d-a960-4b1a-9a67-54f6ebaba326",
   "metadata": {},
   "source": [
    "# Centralised Learning and Federated Learning on the CICIoT2023 dataset\n",
    "\n",
    "This notebook extends on the functionality of the CICIoT2023 example notebook, to account for improvement to the centralised training of all data instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef491788-2e80-4cfc-a86b-556eb4624ad8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "#warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94bf33f7-12e7-4f6e-958b-6b5b0f8b2fbc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATASET_DIRECTORY = '../datasets/CICIoT2023/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7618e631",
   "metadata": {},
   "source": [
    "Include the defines for the dataframe columns and the attack labels and their mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b893d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from includes import X_columns, y_column, dict_34_classes, dict_8_classes, dict_7_classes, dict_2_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b341488c-b030-4d79-96ac-ef52166f4237",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_sets = [k for k in os.listdir(DATASET_DIRECTORY) if k.endswith('.csv')]\n",
    "df_sets.sort()\n",
    "\n",
    "# # Create the training and test sets\n",
    "training_sets = df_sets[:int(len(df_sets)*.8)]\n",
    "test_sets = df_sets[int(len(df_sets)*.8):]\n",
    "\n",
    "# TODO - REMOVE THIS - Works on 20% of the data for low memory machines\n",
    "# Create the training and test sets - LOW MEMORY CLUDGE FOR JON\n",
    "# training_sets = df_sets[:int(len(df_sets)*.2)]\n",
    "# test_sets = df_sets[int(len(df_sets)*.8):]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde99b74",
   "metadata": {},
   "source": [
    "---\n",
    "# TEMP CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4926641e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HACK TO REPLICATE ORIGINAL AUTHORS CODE WITH ONE FILE TRAIN - ['part-00134-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv']\n"
     ]
    }
   ],
   "source": [
    "# Set training_sets to the last entry of training_sets\n",
    "training_sets = training_sets[-1:]\n",
    "print(f\"HACK TO REPLICATE ORIGINAL AUTHORS CODE WITH ONE FILE TRAIN - {training_sets}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1fc92e",
   "metadata": {},
   "source": [
    "Remove this if you have more than a morsel of memory\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4d10ad-299a-4741-bed8-dfb6d0a0e6fd",
   "metadata": {},
   "source": [
    "# Create a new DataFrame that consists of all CSV datA\n",
    "\n",
    "This is **memory intensive** as it will create a DataFrame with 36 million rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d95c0bce-0698-4e23-b070-3701040ac4f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Depreciated method\n",
    "# df = []\n",
    "\n",
    "# count = 0\n",
    "# for train_set in tqdm(training_sets):\n",
    "#     if count == 0:\n",
    "#         df = pd.read_csv(DATASET_DIRECTORY + train_set)\n",
    "#     else:\n",
    "#         df_new = pd.read_csv(DATASET_DIRECTORY + train_set)\n",
    "#         df = df.append(df_new, ignore_index=True)\n",
    "#     count = count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c75f3f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.52it/s]\n"
     ]
    }
   ],
   "source": [
    "# New faster method not using depreciated pandas append\n",
    "dfs = []\n",
    "for train_set in tqdm(training_sets):\n",
    "    df_new = pd.read_csv(DATASET_DIRECTORY + train_set)\n",
    "    dfs.append(df_new)\n",
    "df = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5c6873b-ece2-4e99-a5a0-bb1733024e06",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flow_duration</th>\n",
       "      <th>Header_Length</th>\n",
       "      <th>Protocol Type</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Rate</th>\n",
       "      <th>Srate</th>\n",
       "      <th>Drate</th>\n",
       "      <th>fin_flag_number</th>\n",
       "      <th>syn_flag_number</th>\n",
       "      <th>rst_flag_number</th>\n",
       "      <th>...</th>\n",
       "      <th>Std</th>\n",
       "      <th>Tot size</th>\n",
       "      <th>IAT</th>\n",
       "      <th>Number</th>\n",
       "      <th>Magnitue</th>\n",
       "      <th>Radius</th>\n",
       "      <th>Covariance</th>\n",
       "      <th>Variance</th>\n",
       "      <th>Weight</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000838</td>\n",
       "      <td>54.62</td>\n",
       "      <td>6.05</td>\n",
       "      <td>64.00</td>\n",
       "      <td>11.961779</td>\n",
       "      <td>11.961779</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111473</td>\n",
       "      <td>54.45</td>\n",
       "      <td>8.307598e+07</td>\n",
       "      <td>9.5</td>\n",
       "      <td>10.392912</td>\n",
       "      <td>0.037895</td>\n",
       "      <td>0.035900</td>\n",
       "      <td>0.02</td>\n",
       "      <td>141.55</td>\n",
       "      <td>DDoS-TCP_Flood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.005486</td>\n",
       "      <td>75.88</td>\n",
       "      <td>6.00</td>\n",
       "      <td>64.00</td>\n",
       "      <td>29.502125</td>\n",
       "      <td>29.502125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100314</td>\n",
       "      <td>54.24</td>\n",
       "      <td>8.309325e+07</td>\n",
       "      <td>9.5</td>\n",
       "      <td>10.395361</td>\n",
       "      <td>0.143036</td>\n",
       "      <td>0.346802</td>\n",
       "      <td>0.03</td>\n",
       "      <td>141.55</td>\n",
       "      <td>DDoS-SYN_Flood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>45.61</td>\n",
       "      <td>65.81</td>\n",
       "      <td>151.517376</td>\n",
       "      <td>151.517376</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>57.165223</td>\n",
       "      <td>576.80</td>\n",
       "      <td>8.369379e+07</td>\n",
       "      <td>9.5</td>\n",
       "      <td>33.783684</td>\n",
       "      <td>80.958879</td>\n",
       "      <td>8638.780727</td>\n",
       "      <td>0.40</td>\n",
       "      <td>141.55</td>\n",
       "      <td>Mirai-greeth_flood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>54.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>64.00</td>\n",
       "      <td>1.500542</td>\n",
       "      <td>1.500542</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54.00</td>\n",
       "      <td>8.309408e+07</td>\n",
       "      <td>9.5</td>\n",
       "      <td>10.392305</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>141.55</td>\n",
       "      <td>DDoS-SYN_Flood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.004568</td>\n",
       "      <td>745.42</td>\n",
       "      <td>5.95</td>\n",
       "      <td>65.13</td>\n",
       "      <td>8.082100</td>\n",
       "      <td>8.082100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>549.190629</td>\n",
       "      <td>927.04</td>\n",
       "      <td>8.333561e+07</td>\n",
       "      <td>9.5</td>\n",
       "      <td>41.550978</td>\n",
       "      <td>776.661367</td>\n",
       "      <td>318084.344439</td>\n",
       "      <td>0.95</td>\n",
       "      <td>141.55</td>\n",
       "      <td>DDoS-ACK_Fragmentation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243644</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>54.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>64.00</td>\n",
       "      <td>19.582485</td>\n",
       "      <td>19.582485</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54.00</td>\n",
       "      <td>8.331443e+07</td>\n",
       "      <td>9.5</td>\n",
       "      <td>10.392305</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>141.55</td>\n",
       "      <td>DDoS-PSHACK_Flood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243645</th>\n",
       "      <td>0.037146</td>\n",
       "      <td>78.22</td>\n",
       "      <td>36.21</td>\n",
       "      <td>63.18</td>\n",
       "      <td>24.542045</td>\n",
       "      <td>24.542045</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>110.233513</td>\n",
       "      <td>453.78</td>\n",
       "      <td>8.358187e+07</td>\n",
       "      <td>9.5</td>\n",
       "      <td>30.338676</td>\n",
       "      <td>154.660856</td>\n",
       "      <td>23401.960226</td>\n",
       "      <td>0.53</td>\n",
       "      <td>141.55</td>\n",
       "      <td>Mirai-greip_flood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243646</th>\n",
       "      <td>3.293075</td>\n",
       "      <td>1025996.92</td>\n",
       "      <td>17.00</td>\n",
       "      <td>64.00</td>\n",
       "      <td>572.160392</td>\n",
       "      <td>572.160392</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>554.00</td>\n",
       "      <td>8.378910e+07</td>\n",
       "      <td>9.5</td>\n",
       "      <td>33.286634</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>141.55</td>\n",
       "      <td>Mirai-udpplain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243647</th>\n",
       "      <td>0.047343</td>\n",
       "      <td>35223.00</td>\n",
       "      <td>17.00</td>\n",
       "      <td>64.00</td>\n",
       "      <td>15083.107398</td>\n",
       "      <td>15083.107398</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.00</td>\n",
       "      <td>8.309852e+07</td>\n",
       "      <td>9.5</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>141.55</td>\n",
       "      <td>DDoS-UDP_Flood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243648</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>64.00</td>\n",
       "      <td>9.308130</td>\n",
       "      <td>9.308130</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>536.729102</td>\n",
       "      <td>949.52</td>\n",
       "      <td>8.324966e+07</td>\n",
       "      <td>9.5</td>\n",
       "      <td>45.017352</td>\n",
       "      <td>759.033957</td>\n",
       "      <td>306570.231772</td>\n",
       "      <td>0.94</td>\n",
       "      <td>141.55</td>\n",
       "      <td>DDoS-ICMP_Fragmentation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>243649 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        flow_duration  Header_Length  Protocol Type  Duration          Rate  \\\n",
       "0            0.000838          54.62           6.05     64.00     11.961779   \n",
       "1            0.005486          75.88           6.00     64.00     29.502125   \n",
       "2            0.000000           0.00          45.61     65.81    151.517376   \n",
       "3            0.000000          54.00           6.00     64.00      1.500542   \n",
       "4            0.004568         745.42           5.95     65.13      8.082100   \n",
       "...               ...            ...            ...       ...           ...   \n",
       "243644       0.000000          54.00           6.00     64.00     19.582485   \n",
       "243645       0.037146          78.22          36.21     63.18     24.542045   \n",
       "243646       3.293075     1025996.92          17.00     64.00    572.160392   \n",
       "243647       0.047343       35223.00          17.00     64.00  15083.107398   \n",
       "243648       0.000000           0.00           1.00     64.00      9.308130   \n",
       "\n",
       "               Srate  Drate  fin_flag_number  syn_flag_number  \\\n",
       "0          11.961779    0.0              0.0              0.0   \n",
       "1          29.502125    0.0              0.0              1.0   \n",
       "2         151.517376    0.0              0.0              0.0   \n",
       "3           1.500542    0.0              0.0              1.0   \n",
       "4           8.082100    0.0              0.0              0.0   \n",
       "...              ...    ...              ...              ...   \n",
       "243644     19.582485    0.0              0.0              0.0   \n",
       "243645     24.542045    0.0              0.0              0.0   \n",
       "243646    572.160392    0.0              0.0              0.0   \n",
       "243647  15083.107398    0.0              0.0              0.0   \n",
       "243648      9.308130    0.0              0.0              0.0   \n",
       "\n",
       "        rst_flag_number  ...         Std  Tot size           IAT  Number  \\\n",
       "0                   0.0  ...    0.111473     54.45  8.307598e+07     9.5   \n",
       "1                   0.0  ...    0.100314     54.24  8.309325e+07     9.5   \n",
       "2                   0.0  ...   57.165223    576.80  8.369379e+07     9.5   \n",
       "3                   0.0  ...    0.000000     54.00  8.309408e+07     9.5   \n",
       "4                   0.0  ...  549.190629    927.04  8.333561e+07     9.5   \n",
       "...                 ...  ...         ...       ...           ...     ...   \n",
       "243644              0.0  ...    0.000000     54.00  8.331443e+07     9.5   \n",
       "243645              0.0  ...  110.233513    453.78  8.358187e+07     9.5   \n",
       "243646              0.0  ...    0.000000    554.00  8.378910e+07     9.5   \n",
       "243647              0.0  ...    0.000000     50.00  8.309852e+07     9.5   \n",
       "243648              0.0  ...  536.729102    949.52  8.324966e+07     9.5   \n",
       "\n",
       "         Magnitue      Radius     Covariance  Variance  Weight  \\\n",
       "0       10.392912    0.037895       0.035900      0.02  141.55   \n",
       "1       10.395361    0.143036       0.346802      0.03  141.55   \n",
       "2       33.783684   80.958879    8638.780727      0.40  141.55   \n",
       "3       10.392305    0.000000       0.000000      0.00  141.55   \n",
       "4       41.550978  776.661367  318084.344439      0.95  141.55   \n",
       "...           ...         ...            ...       ...     ...   \n",
       "243644  10.392305    0.000000       0.000000      0.00  141.55   \n",
       "243645  30.338676  154.660856   23401.960226      0.53  141.55   \n",
       "243646  33.286634    0.000000       0.000000      0.00  141.55   \n",
       "243647  10.000000    0.000000       0.000000      0.00  141.55   \n",
       "243648  45.017352  759.033957  306570.231772      0.94  141.55   \n",
       "\n",
       "                          label  \n",
       "0                DDoS-TCP_Flood  \n",
       "1                DDoS-SYN_Flood  \n",
       "2            Mirai-greeth_flood  \n",
       "3                DDoS-SYN_Flood  \n",
       "4        DDoS-ACK_Fragmentation  \n",
       "...                         ...  \n",
       "243644        DDoS-PSHACK_Flood  \n",
       "243645        Mirai-greip_flood  \n",
       "243646           Mirai-udpplain  \n",
       "243647           DDoS-UDP_Flood  \n",
       "243648  DDoS-ICMP_Fragmentation  \n",
       "\n",
       "[243649 rows x 47 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08029a2f",
   "metadata": {},
   "source": [
    "## Map the y labels to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6ed9fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map y column to the dict_34_classes values\n",
    "df['label'] = df['label'].map(dict_34_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edb73a9-e0e6-44b2-8ad5-291e42fc3f0c",
   "metadata": {},
   "source": [
    "# Save this output to a Pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7dafe71b-84f3-4dea-b906-a4fe31f31ebd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_pickle('training_data.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f819a842-d247-4b52-9e87-1d55b2d173e1",
   "metadata": {},
   "source": [
    "We can now retrieve the dataset from the pkl in further work (pickle file approx 2GB compared to 12GB of CSV data).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41888ad",
   "metadata": {},
   "source": [
    "# Read the pickle file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e109b533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the pickle file\n",
    "df = pd.read_pickle('training_data.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad30fdf1-6d0c-4a1a-8cea-0a6ae53288f0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Scale the input features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae08745b-9b58-4fad-8754-7051afed7b8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "scaler = StandardScaler()\n",
    "df[X_columns] = scaler.fit_transform(df[X_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841f18dd-f569-4c67-a320-54f5a2d1360a",
   "metadata": {},
   "source": [
    "# Classification Problem (2-class, 8-class, or 34-class)\n",
    "Select which size classification problem you want to solve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99c225c6-a510-4652-bd04-2a6027743158",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary 2 Class Classifier...\n"
     ]
    }
   ],
   "source": [
    "binary_classifier = True\n",
    "group_classifier = False\n",
    "individual_classifier = False\n",
    "\n",
    "if group_classifier:\n",
    "    print(\"Group 8 Class Classifier...\")\n",
    "    # Map y column to the dict_7_classes values\n",
    "    df['label'] = df['label'].map(dict_8_classes)\n",
    "    class_size = \"8\"\n",
    "        \n",
    "elif binary_classifier:\n",
    "    print(\"Binary 2 Class Classifier...\")\n",
    "    # Map y column to the dict_2_classes values\n",
    "    df['label'] = df['label'].map(dict_2_classes)\n",
    "    class_size = \"2\"\n",
    "\n",
    "else:\n",
    "    print (\"Individual 34 Class classifier...\")\n",
    "    class_size = \"34\"\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc76b81-34a2-4db2-84e9-664f4ea99ecd",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Model Creation (LR, RF, MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "970ab1fc-d4d4-4394-88b0-85ce92992c71",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-08 12:30:43.940463  : Fit LogisticRegression model...\n",
      "2023-07-08 12:30:59.935965  : Fit LogisticRegression model complete...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [01:00<00:00,  1.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### LogisticRegression (2 classes) #####\n",
      "accuracy_score:  0.9890232850339564\n",
      "recall_score:  0.8904023664038468\n",
      "precision_score:  0.8631580080482479\n",
      "f1_score:  0.8762598157224799\n",
      "\n",
      "\n",
      "2023-07-08 12:32:29.668409  : Fit RandomForestClassifier model...\n",
      "2023-07-08 12:32:46.538445  : Fit RandomForestClassifier model complete...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [01:58<00:00,  3.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### RandomForestClassifier (2 classes) #####\n",
      "accuracy_score:  0.9968563352156702\n",
      "recall_score:  0.963039124051402\n",
      "precision_score:  0.9690356854646043\n",
      "f1_score:  0.9660170961654488\n",
      "\n",
      "\n",
      "2023-07-08 12:35:14.283741  : Fit MLPClassifier model...\n",
      "2023-07-08 12:37:39.177590  : Fit MLPClassifier model complete...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [01:12<00:00,  2.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### MLPClassifier (2 classes) #####\n",
      "accuracy_score:  0.9933677048162016\n",
      "recall_score:  0.9224608691470502\n",
      "precision_score:  0.9356547334449308\n",
      "f1_score:  0.928950718304631\n",
      "\n",
      "\n",
      "CPU times: total: 19min 25s\n",
      "Wall time: 8min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "ML_models = [\n",
    "    (\"LogisticRegression\", LogisticRegression(n_jobs=-1), f\"logreg-{class_size}class-model.pkl\"),\n",
    "    (\"RandomForestClassifier\", RandomForestClassifier(), f\"rf-{class_size}class-model.pkl\"),\n",
    "    (\"MLPClassifier\", MLPClassifier(), f\"mlp-{class_size}class-model.pkl\")\n",
    "]\n",
    "\n",
    "def train_and_evaluate(name, model, model_file, df):\n",
    "    print(datetime.now(), f\" : Fit {name} model...\")\n",
    "    model.fit(df[X_columns], df[y_column])\n",
    "    print(datetime.now(), f\" : Fit {name} model complete...\")\n",
    "    \n",
    "    with open(model_file, \"wb\") as f:\n",
    "        pickle.dump(model, f)\n",
    "    \n",
    "    y_test = []\n",
    "    preds = []\n",
    "    for test_set in tqdm(test_sets):\n",
    "        d_test = pd.read_csv(DATASET_DIRECTORY + test_set)\n",
    "        d_test[X_columns] = scaler.transform(d_test[X_columns])\n",
    "\n",
    "        # Always map the y column to the dict_34_classes values\n",
    "        new_y = [dict_34_classes[k] for k in d_test[y_column]]\n",
    "        d_test[y_column] = new_y\n",
    "\n",
    "        if binary_classifier:\n",
    "            # binary classifier (2-class)\n",
    "            new_y = [dict_2_classes[k] for k in d_test[y_column]]\n",
    "            d_test[y_column] = new_y\n",
    "\n",
    "        elif group_classifier:\n",
    "            # group classifier (8-class)\n",
    "            new_y = [dict_8_classes[k] for k in d_test[y_column]]\n",
    "            d_test[y_column] = new_y\n",
    "\n",
    "        else:\n",
    "            # individual_classifier\n",
    "            pass\n",
    "\n",
    "        y_test += list(d_test[y_column].values)\n",
    "\n",
    "        y_pred = list(model.predict(d_test[X_columns]))\n",
    "        preds += y_pred\n",
    "\n",
    "    print(f\"##### {name} ({class_size} classes) #####\")\n",
    "    print('accuracy_score: ', accuracy_score(preds, y_test))\n",
    "    print('recall_score: ', recall_score(preds, y_test, average='macro'))\n",
    "    print('precision_score: ', precision_score(preds, y_test, average='macro'))\n",
    "    print('f1_score: ', f1_score(preds, y_test, average='macro'))\n",
    "    print('\\n')\n",
    "\n",
    "for name, model, model_file in ML_models:\n",
    "    train_and_evaluate(name, model, model_file, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9984dd7-6601-49ea-94be-d9882ac4b439",
   "metadata": {},
   "source": [
    "# Load in a Pickled model result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6bd1c099-824b-4111-b174-7f662ee7001a",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'model.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Jon\\Documents\\VSCode Projects\\CICIoT2023\\our_notebook.ipynb Cell 28\u001b[0m in \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Jon/Documents/VSCode%20Projects/CICIoT2023/our_notebook.ipynb#X35sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mmodel.pkl\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Jon/Documents/VSCode%20Projects/CICIoT2023/our_notebook.ipynb#X35sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     model \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mload(f)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'model.pkl'"
     ]
    }
   ],
   "source": [
    "with open(\"model.pkl\", \"rb\") as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f241ec19-4db5-4fa0-8640-15f334a7d7f8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Calculate Test Performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1632303c-d95a-4461-b3e8-0eff5ae64a6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_test = []\n",
    "preds = {i:[] for i in range(len(ML_models))}\n",
    "for test_set in tqdm(test_sets):\n",
    "    d_test = pd.read_csv(DATASET_DIRECTORY + test_set)\n",
    "    d_test[X_columns] = scaler.transform(d_test[X_columns])\n",
    "\n",
    "    if binary_classifier:\n",
    "        # binary classifier (2-class)\n",
    "        new_y = [dict_2_classes[k] for k in d_test[y_column]]\n",
    "        d_test[y_column] = new_y\n",
    "\n",
    "\n",
    "    elif group_classifier:\n",
    "        # group classifier (8-class)\n",
    "        new_y = [dict_7_classes[k] for k in d_test[y_column]]\n",
    "        d_test[y_column] = new_y\n",
    "\n",
    "    else:\n",
    "        # individual_classifier\n",
    "        pass\n",
    "\n",
    "    y_test += list(d_test[y_column].values)\n",
    "\n",
    "    y_pred = list(model.predict(d_test[X_columns]))\n",
    "    preds[0] = preds[0] + y_pred\n",
    "\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "for k,v in preds.items():\n",
    "    y_pred = v\n",
    "    print(f\"##### {ML_names[k]} (34 classes) #####\")\n",
    "    print('accuracy_score: ', accuracy_score(y_pred, y_test))\n",
    "    print('recall_score: ', recall_score(y_pred, y_test, average='macro'))\n",
    "    print('precision_score: ', precision_score(y_pred, y_test, average='macro'))\n",
    "    print('f1_score: ', f1_score(y_pred, y_test, average='macro'))\n",
    "    print()\n",
    "    print()\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
