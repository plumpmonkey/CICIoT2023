{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 - Federated Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the available types of federated learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### THIS SECTION NEEDS TO BE SET TO DETERMINE WHICH CONFIGURATION METHOD TO UTILISE\n",
    "\n",
    "SPLIT_AVAILABLE_METHODS = ['INDIVIDUAL_ATTACK', 'ATTACK_GROUP', 'STRATIFIED']\n",
    "METHOD = 'STRATIFIED'\n",
    "NUM_OF_STRATIFIED_CLIENTS = 10  # only applies to stratified method\n",
    "NUM_OF_ROUNDS = 10              # Number of FL rounds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Include the defines for the dataframe columns and the attack labels and their mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "from includes import dict_34_classes, dict_8_classes, dict_7_classes, dict_2_classes, X_columns, y_column, Colours\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install flwr[simulation] torch torchvision matplotlib sklearn openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import flwr as fl\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "#warnings.filterwarnings('ignore')\n",
    "\n",
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from flwr.common import Metrics\n",
    "from torch.utils.data import DataLoader, random_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flwr 1.4.0\n",
      "numpy 1.24.2\n",
      "torch 1.13.1\n",
      "Training on cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(\"flwr\", fl.__version__)\n",
    "print(\"numpy\", np.__version__)\n",
    "print(\"torch\", torch.__version__)\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Training on {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIRECTORY = '../datasets/CICIoT2023/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Either read the training pickle file if it exists, or process the dataset from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists, loading data...\n",
      "Training data loaded from pickle file.\n",
      "Training data size: (243649, 47)\n"
     ]
    }
   ],
   "source": [
    "# Check to see if the file 'training_data.pkl' exists in the directory. If it does, load it. If not, print an error.\n",
    "if os.path.isfile('training_data.pkl'):\n",
    "    print(\"File exists, loading data...\")\n",
    "    train_df = pd.read_pickle('training_data.pkl')\n",
    "    print(\"Training data loaded from pickle file.\")\n",
    "\n",
    "else:\n",
    "    df_sets = [k for k in os.listdir(DATASET_DIRECTORY) if k.endswith('.csv')]\n",
    "    df_sets.sort()\n",
    "    training_sets = df_sets[:int(len(df_sets)*.8)]\n",
    "    test_sets = df_sets[int(len(df_sets)*.8):]\n",
    "\n",
    "    # Print the number of files in each set\n",
    "    print('Training sets: {}'.format(len(training_sets)))\n",
    "    print('Test sets: {}'.format(len(test_sets)))\n",
    "\n",
    "    ######################\n",
    "    # HACK TEMP CODE\n",
    "    ######################\n",
    "    # Set training_sets to the last entry of training_sets\n",
    "    training_sets = training_sets[-1:]\n",
    "    print(f\"HACK TO REPLICATE ORIGINAL AUTHORS CODE WITH ONE FILE TRAIN - {training_sets}\")\n",
    "    ######################\n",
    "    # HACK END TEMP CODE\n",
    "    ######################\n",
    "\n",
    "    # Concatenate all training sets into one dataframe\n",
    "    dfs = []\n",
    "    print(\"Reading training data...\")\n",
    "    for train_set in tqdm(training_sets):\n",
    "        df_new = pd.read_csv(DATASET_DIRECTORY + train_set)\n",
    "        dfs.append(df_new)\n",
    "    train_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    # Map y column to the dict_34_classes values - The pickle file already has this done.\n",
    "    train_df['label'] = train_df['label'].map(dict_34_classes)\n",
    "\n",
    "    # Save the output to a pickle file\n",
    "    print(\"Writing training data to pickle file...\")\n",
    "    train_df.to_pickle('training_data.pkl')\n",
    "\n",
    "print(\"Training data size: {}\".format(train_df.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flow_duration</th>\n",
       "      <th>Header_Length</th>\n",
       "      <th>Protocol Type</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Rate</th>\n",
       "      <th>Srate</th>\n",
       "      <th>Drate</th>\n",
       "      <th>fin_flag_number</th>\n",
       "      <th>syn_flag_number</th>\n",
       "      <th>rst_flag_number</th>\n",
       "      <th>...</th>\n",
       "      <th>Std</th>\n",
       "      <th>Tot size</th>\n",
       "      <th>IAT</th>\n",
       "      <th>Number</th>\n",
       "      <th>Magnitue</th>\n",
       "      <th>Radius</th>\n",
       "      <th>Covariance</th>\n",
       "      <th>Variance</th>\n",
       "      <th>Weight</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000838</td>\n",
       "      <td>54.62</td>\n",
       "      <td>6.05</td>\n",
       "      <td>64.00</td>\n",
       "      <td>11.961779</td>\n",
       "      <td>11.961779</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111473</td>\n",
       "      <td>54.45</td>\n",
       "      <td>8.307598e+07</td>\n",
       "      <td>9.5</td>\n",
       "      <td>10.392912</td>\n",
       "      <td>0.037895</td>\n",
       "      <td>0.035900</td>\n",
       "      <td>0.02</td>\n",
       "      <td>141.55</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.005486</td>\n",
       "      <td>75.88</td>\n",
       "      <td>6.00</td>\n",
       "      <td>64.00</td>\n",
       "      <td>29.502125</td>\n",
       "      <td>29.502125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100314</td>\n",
       "      <td>54.24</td>\n",
       "      <td>8.309325e+07</td>\n",
       "      <td>9.5</td>\n",
       "      <td>10.395361</td>\n",
       "      <td>0.143036</td>\n",
       "      <td>0.346802</td>\n",
       "      <td>0.03</td>\n",
       "      <td>141.55</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>45.61</td>\n",
       "      <td>65.81</td>\n",
       "      <td>151.517376</td>\n",
       "      <td>151.517376</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>57.165223</td>\n",
       "      <td>576.80</td>\n",
       "      <td>8.369379e+07</td>\n",
       "      <td>9.5</td>\n",
       "      <td>33.783684</td>\n",
       "      <td>80.958879</td>\n",
       "      <td>8638.780727</td>\n",
       "      <td>0.40</td>\n",
       "      <td>141.55</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>54.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>64.00</td>\n",
       "      <td>1.500542</td>\n",
       "      <td>1.500542</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54.00</td>\n",
       "      <td>8.309408e+07</td>\n",
       "      <td>9.5</td>\n",
       "      <td>10.392305</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>141.55</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.004568</td>\n",
       "      <td>745.42</td>\n",
       "      <td>5.95</td>\n",
       "      <td>65.13</td>\n",
       "      <td>8.082100</td>\n",
       "      <td>8.082100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>549.190629</td>\n",
       "      <td>927.04</td>\n",
       "      <td>8.333561e+07</td>\n",
       "      <td>9.5</td>\n",
       "      <td>41.550978</td>\n",
       "      <td>776.661367</td>\n",
       "      <td>318084.344439</td>\n",
       "      <td>0.95</td>\n",
       "      <td>141.55</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243644</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>54.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>64.00</td>\n",
       "      <td>19.582485</td>\n",
       "      <td>19.582485</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54.00</td>\n",
       "      <td>8.331443e+07</td>\n",
       "      <td>9.5</td>\n",
       "      <td>10.392305</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>141.55</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243645</th>\n",
       "      <td>0.037146</td>\n",
       "      <td>78.22</td>\n",
       "      <td>36.21</td>\n",
       "      <td>63.18</td>\n",
       "      <td>24.542045</td>\n",
       "      <td>24.542045</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>110.233513</td>\n",
       "      <td>453.78</td>\n",
       "      <td>8.358187e+07</td>\n",
       "      <td>9.5</td>\n",
       "      <td>30.338676</td>\n",
       "      <td>154.660856</td>\n",
       "      <td>23401.960226</td>\n",
       "      <td>0.53</td>\n",
       "      <td>141.55</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243646</th>\n",
       "      <td>3.293075</td>\n",
       "      <td>1025996.92</td>\n",
       "      <td>17.00</td>\n",
       "      <td>64.00</td>\n",
       "      <td>572.160392</td>\n",
       "      <td>572.160392</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>554.00</td>\n",
       "      <td>8.378910e+07</td>\n",
       "      <td>9.5</td>\n",
       "      <td>33.286634</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>141.55</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243647</th>\n",
       "      <td>0.047343</td>\n",
       "      <td>35223.00</td>\n",
       "      <td>17.00</td>\n",
       "      <td>64.00</td>\n",
       "      <td>15083.107398</td>\n",
       "      <td>15083.107398</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.00</td>\n",
       "      <td>8.309852e+07</td>\n",
       "      <td>9.5</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>141.55</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243648</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>64.00</td>\n",
       "      <td>9.308130</td>\n",
       "      <td>9.308130</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>536.729102</td>\n",
       "      <td>949.52</td>\n",
       "      <td>8.324966e+07</td>\n",
       "      <td>9.5</td>\n",
       "      <td>45.017352</td>\n",
       "      <td>759.033957</td>\n",
       "      <td>306570.231772</td>\n",
       "      <td>0.94</td>\n",
       "      <td>141.55</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>243649 rows Ã— 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        flow_duration  Header_Length  Protocol Type  Duration          Rate  \\\n",
       "0            0.000838          54.62           6.05     64.00     11.961779   \n",
       "1            0.005486          75.88           6.00     64.00     29.502125   \n",
       "2            0.000000           0.00          45.61     65.81    151.517376   \n",
       "3            0.000000          54.00           6.00     64.00      1.500542   \n",
       "4            0.004568         745.42           5.95     65.13      8.082100   \n",
       "...               ...            ...            ...       ...           ...   \n",
       "243644       0.000000          54.00           6.00     64.00     19.582485   \n",
       "243645       0.037146          78.22          36.21     63.18     24.542045   \n",
       "243646       3.293075     1025996.92          17.00     64.00    572.160392   \n",
       "243647       0.047343       35223.00          17.00     64.00  15083.107398   \n",
       "243648       0.000000           0.00           1.00     64.00      9.308130   \n",
       "\n",
       "               Srate  Drate  fin_flag_number  syn_flag_number  \\\n",
       "0          11.961779    0.0              0.0              0.0   \n",
       "1          29.502125    0.0              0.0              1.0   \n",
       "2         151.517376    0.0              0.0              0.0   \n",
       "3           1.500542    0.0              0.0              1.0   \n",
       "4           8.082100    0.0              0.0              0.0   \n",
       "...              ...    ...              ...              ...   \n",
       "243644     19.582485    0.0              0.0              0.0   \n",
       "243645     24.542045    0.0              0.0              0.0   \n",
       "243646    572.160392    0.0              0.0              0.0   \n",
       "243647  15083.107398    0.0              0.0              0.0   \n",
       "243648      9.308130    0.0              0.0              0.0   \n",
       "\n",
       "        rst_flag_number  ...         Std  Tot size           IAT  Number  \\\n",
       "0                   0.0  ...    0.111473     54.45  8.307598e+07     9.5   \n",
       "1                   0.0  ...    0.100314     54.24  8.309325e+07     9.5   \n",
       "2                   0.0  ...   57.165223    576.80  8.369379e+07     9.5   \n",
       "3                   0.0  ...    0.000000     54.00  8.309408e+07     9.5   \n",
       "4                   0.0  ...  549.190629    927.04  8.333561e+07     9.5   \n",
       "...                 ...  ...         ...       ...           ...     ...   \n",
       "243644              0.0  ...    0.000000     54.00  8.331443e+07     9.5   \n",
       "243645              0.0  ...  110.233513    453.78  8.358187e+07     9.5   \n",
       "243646              0.0  ...    0.000000    554.00  8.378910e+07     9.5   \n",
       "243647              0.0  ...    0.000000     50.00  8.309852e+07     9.5   \n",
       "243648              0.0  ...  536.729102    949.52  8.324966e+07     9.5   \n",
       "\n",
       "         Magnitue      Radius     Covariance  Variance  Weight  label  \n",
       "0       10.392912    0.037895       0.035900      0.02  141.55      5  \n",
       "1       10.395361    0.143036       0.346802      0.03  141.55      3  \n",
       "2       33.783684   80.958879    8638.780727      0.40  141.55     17  \n",
       "3       10.392305    0.000000       0.000000      0.00  141.55      3  \n",
       "4       41.550978  776.661367  318084.344439      0.95  141.55      8  \n",
       "...           ...         ...            ...       ...     ...    ...  \n",
       "243644  10.392305    0.000000       0.000000      0.00  141.55      2  \n",
       "243645  30.338676  154.660856   23401.960226      0.53  141.55     18  \n",
       "243646  33.286634    0.000000       0.000000      0.00  141.55     19  \n",
       "243647  10.000000    0.000000       0.000000      0.00  141.55      4  \n",
       "243648  45.017352  759.033957  306570.231772      0.94  141.55     10  \n",
       "\n",
       "[243649 rows x 47 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale the training data input features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "train_df[X_columns] = scaler.fit_transform(train_df[X_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Test Data\n",
    "Concat the test data into a single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File testing_data.pkl exists, loading data...\n",
      "Test data loaded from pickle file.\n",
      "Testing data size: (234745, 47)\n"
     ]
    }
   ],
   "source": [
    "# Check to see if the file 'test_data.pkl' exists in the directory. If it does, load it. If not, print an error.\n",
    "testing_data_pickle_file = 'testing_data.pkl'\n",
    "\n",
    "if os.path.isfile(testing_data_pickle_file):\n",
    "    print(f\"File {testing_data_pickle_file} exists, loading data...\")\n",
    "    test_df = pd.read_pickle(testing_data_pickle_file)\n",
    "    print(\"Test data loaded from pickle file.\")\n",
    "\n",
    "else:\n",
    "    print(f\"File {testing_data_pickle_file} does not exist, constructing data...\")\n",
    "\n",
    "    df_sets = [k for k in os.listdir(DATASET_DIRECTORY) if k.endswith('.csv')]\n",
    "    df_sets.sort()\n",
    "    training_sets = df_sets[:int(len(df_sets)*.8)]\n",
    "    test_sets = df_sets[int(len(df_sets)*.8):]\n",
    "\n",
    "    ############################################\n",
    "    ############################################\n",
    "    # HACK - Make things quicker for now\n",
    "    ############################################\n",
    "    ############################################\n",
    "\n",
    "    test_sets = df_sets[int(len(df_sets)*.95):]\n",
    "    \n",
    "    # Set training_sets to the last entry of training_sets\n",
    "    test_sets = test_sets[-1:]\n",
    "    \n",
    "    ############################################\n",
    "    ############################################\n",
    "    # END HACK \n",
    "    ############################################\n",
    "    ############################################\n",
    "\n",
    "    # Print the number of files in each set\n",
    "    print('Test sets: {}'.format(len(test_sets)))\n",
    "    \n",
    "    # Concatenate all testing sets into one dataframe\n",
    "    dfs = []\n",
    "    print(\"Reading test data...\")\n",
    "    for test_set in tqdm(test_sets):\n",
    "        df_new = pd.read_csv(DATASET_DIRECTORY + test_set)\n",
    "        dfs.append(df_new)\n",
    "    test_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    # Map y column to the dict_34_classes values - The pickle file already has this done.\n",
    "    test_df['label'] = test_df['label'].map(dict_34_classes)\n",
    "\n",
    "    # Save the output to a pickle file\n",
    "    print(f\"Writing test data to pickle file {testing_data_pickle_file}...\")\n",
    "    test_df.to_pickle(testing_data_pickle_file)\n",
    "\n",
    "print(\"Testing data size: {}\".format(test_df.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale the testing data input features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "test_df[X_columns] = scaler.fit_transform(test_df[X_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Define the classification problem - (2 classes, 8 classes or 34 classes)\n",
    "Change the following cell to select the classification type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_classifier = False\n",
    "group_classifier = False\n",
    "individual_classifier = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual 34 Class classifier... - No adjustments to labels in test and train dataframes\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class_size_map = {2: \"Binary\", 8: \"Group\", 34: \"Individual\"}\n",
    "\n",
    "if group_classifier:\n",
    "    print(\"Group 8 Class Classifier... - Adjusting labels in test and train dataframes\")\n",
    "    # Map y column to the dict_7_classes values\n",
    "    test_df['label'] = test_df['label'].map(dict_8_classes)\n",
    "    train_df['label'] = train_df['label'].map(dict_8_classes)\n",
    "    class_size = \"8\"\n",
    "        \n",
    "elif binary_classifier:\n",
    "    print(\"Binary 2 Class Classifier... - Adjusting labels in test and train dataframes\")\n",
    "    # Map y column to the dict_2_classes values\n",
    "    test_df['label'] = test_df['label'].map(dict_2_classes)\n",
    "    train_df['label'] = train_df['label'].map(dict_2_classes)\n",
    "    class_size = \"2\"\n",
    "\n",
    "else:\n",
    "    print (\"Individual 34 Class classifier... - No adjustments to labels in test and train dataframes\")\n",
    "    class_size = \"34\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratify the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jon\\anaconda3\\envs\\py310copy\\lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 5 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define fl_X_train and fl_y_train\n",
    "fl_X_train = []\n",
    "fl_y_train = []\n",
    "\n",
    "# take the train_df[X_columns] and split them into 10 smaller groups in the fl_X_train list using  StratifiedKFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=NUM_OF_STRATIFIED_CLIENTS, shuffle=True, random_state=42)\n",
    "for train_index, test_index in skf.split(train_df[X_columns], train_df[y_column]):\n",
    "    fl_X_train.append(train_df[X_columns].iloc[test_index])\n",
    "    fl_y_train.append(train_df[y_column].iloc[test_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the testing daya to X_test and y_test ndarrays\n",
    "X_test = test_df[X_columns].to_numpy()\n",
    "y_test = test_df[y_column].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Data check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM_CLIENTS: 10\n",
      "NUM_ROUNDS: 10\n",
      "\n",
      "Original train_df size: (243649, 47)\n",
      "Checking training data split groups\n",
      "0 : X Shape (24365, 46) Y Shape (24365,)\n",
      "1 : X Shape (24365, 46) Y Shape (24365,)\n",
      "2 : X Shape (24365, 46) Y Shape (24365,)\n",
      "3 : X Shape (24365, 46) Y Shape (24365,)\n",
      "4 : X Shape (24365, 46) Y Shape (24365,)\n",
      "5 : X Shape (24365, 46) Y Shape (24365,)\n",
      "6 : X Shape (24365, 46) Y Shape (24365,)\n",
      "7 : X Shape (24365, 46) Y Shape (24365,)\n",
      "8 : X Shape (24365, 46) Y Shape (24365,)\n",
      "9 : X Shape (24364, 46) Y Shape (24364,)\n",
      "\n",
      "Checking testing data\n",
      "X_test size: (234745, 46)\n",
      "y_test size: (234745,)\n",
      "\n",
      "Deploy Simulation\n"
     ]
    }
   ],
   "source": [
    "NUM_OF_CLIENTS = len(fl_X_train)\n",
    "print(\"NUM_CLIENTS:\", NUM_OF_CLIENTS)\n",
    "\n",
    "print(\"NUM_ROUNDS:\", NUM_OF_ROUNDS)\n",
    "print()\n",
    "print(\"Original train_df size: {}\".format(train_df.shape))\n",
    "\n",
    "print(\"Checking training data split groups\")\n",
    "for i in range(len(fl_X_train)):\n",
    "    print(i, \":\", \"X Shape\", fl_X_train[i].shape, \"Y Shape\", fl_y_train[i].shape)\n",
    "\n",
    "\n",
    "# Print the sizes of X_test and y_test\n",
    "print(\"\\nChecking testing data\")\n",
    "print(\"X_test size: {}\".format(X_test.shape))\n",
    "print(\"y_test size: {}\".format(y_test.shape))\n",
    "\n",
    "print(\"\\nDeploy Simulation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# Federated Learning\n",
    "## Import the libraries and print the versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import flwr as fl\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Make TensorFlow log less verbose\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "label = train_df[y_column]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the Client and Server code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scikit-learn 1.2.0.\n",
      "flwr 1.4.0\n",
      "numpy 1.24.2\n",
      "tf 2.11.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import flwr as fl\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "print('scikit-learn {}.'.format(sklearn.__version__))\n",
    "print(\"flwr\", fl.__version__)\n",
    "print(\"numpy\", np.__version__)\n",
    "print(\"tf\", tf.__version__)\n",
    "# Make TensorFlow log less verbose\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "import datetime\n",
    "\n",
    "class NumpyFlowerClient(fl.client.NumPyClient):\n",
    "    def __init__(self, cid, model, train_data, train_labels):\n",
    "        self.model = model\n",
    "        self.cid = cid\n",
    "        self.train_data = train_data\n",
    "        self.train_labels = train_labels\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        return self.model.get_weights()\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        self.model.set_weights(parameters)\n",
    "        print (\"Client \", self.cid, \"Training...\")\n",
    "        self.model.fit(self.train_data, self.train_labels, epochs=10, batch_size=64)\n",
    "        print (\"Client \", self.cid, \"Training complete...\")\n",
    "        return self.model.get_weights(), len(self.train_data), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        self.model.set_weights(parameters)\n",
    "        print (\"Client \", self.cid, \"Evaluating...\")\n",
    "        loss, accuracy = self.model.evaluate(self.train_data, self.train_labels, batch_size=64)\n",
    "        print(f\"{Colours.YELLOW.value}Client {self.cid} evaluation complete - Accuracy: {accuracy:.6f}, Loss: {loss:.6f}{Colours.NORMAL.value}\")\n",
    "\n",
    "        return loss, len(self.train_data), {\"accuracy\": accuracy}\n",
    "    \n",
    "    def predict(self, incoming):\n",
    "        prediction = np.argmax( self.model.predict(incoming) ,axis=1)\n",
    "        return prediction\n",
    "\n",
    "def client_fn(cid: str) -> NumpyFlowerClient:\n",
    "    \"\"\"Create a Flower client representing a single organization.\"\"\"\n",
    "\n",
    "    # Load model\n",
    "    #model = tf.keras.applications.MobileNetV2((32, 32, 3), classes=10, weights=None)\n",
    "    #model.compile(\"adam\", \"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    print (\"Client ID:\", cid)\n",
    "\n",
    "    model = Sequential([\n",
    "      #Flatten(input_shape=(79,1)),\n",
    "      Flatten(input_shape=(fl_X_train[0].shape[1] , 1)),\n",
    "      Dense(50, activation='relu'),  \n",
    "      Dense(25, activation='relu'),  \n",
    "      Dense(len(label.unique()), activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "   \n",
    "    partition_id = int(cid)\n",
    "    X_train_c = fl_X_train[partition_id]\n",
    "    y_train_c = fl_y_train[partition_id]\n",
    "\n",
    "    # Create a  single Flower client representing a single organization\n",
    "    return NumpyFlowerClient(cid, model, X_train_c, y_train_c)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "eval_count = 0\n",
    "\n",
    "def get_evaluate_fn(server_model):\n",
    "    global eval_count\n",
    "    \"\"\"Return an evaluation function for server-side evaluation.\"\"\"\n",
    "    # The `evaluate` function will be called after every round\n",
    "    \n",
    "    \n",
    "    def evaluate(server_round, parameters, config):\n",
    "        global eval_count\n",
    "        \n",
    "        # Update model with the latest parameters\n",
    "        server_model.set_weights(parameters)\n",
    "        print (f\"Server Evaluating... Evaluation Count:{eval_count}\")\n",
    "        loss, accuracy = server_model.evaluate(X_test, y_test)\n",
    "        \n",
    "        y_pred = server_model.predict(X_test)\n",
    "        print (\"Prediction: \", y_pred, y_pred.shape)\n",
    "        #cmatrix = confusion_matrix(y_test, np.rint(y_pred))\n",
    "        #print (\"confusion_matrix:\", cmatrix, cmatrix.shape)\n",
    "                        \n",
    "        print(f\"{Colours.YELLOW.value}Server evaluation complete - Accuracy: {accuracy:.4f}, Loss: {loss:.4f}{Colours.NORMAL.value}\")\n",
    "        \n",
    "        np.save(\"y_pred-\" + str(eval_count) + \".npy\", y_pred)\n",
    "        #np.save(\"cmatrix-\" + str(eval_count) + \".npy\", cmatrix)\n",
    "        eval_count = eval_count + 1\n",
    "        \n",
    "        return loss, {\"accuracy\": accuracy}\n",
    "    return evaluate\n",
    "\n",
    "\n",
    "\n",
    "server_model = Sequential([\n",
    "    #Flatten(input_shape=(79,1)),\n",
    "    Flatten(input_shape=(fl_X_train[0].shape[1] , 1)),\n",
    "    Dense(50, activation='relu'),  \n",
    "    Dense(25, activation='relu'),  \n",
    "    Dense(len(label.unique()), activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "server_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Create FedAvg strategy\n",
    "strategy = fl.server.strategy.FedAvg(\n",
    "        fraction_fit=1.0,\n",
    "        fraction_evaluate=0.5,\n",
    "        min_fit_clients=2, #10,\n",
    "        min_evaluate_clients=2, #5,\n",
    "        min_available_clients=2, #10,\n",
    "        evaluate_fn=get_evaluate_fn(server_model),\n",
    "        #evaluate_metrics_aggregation_fn=weighted_average,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2023-07-08 18:07:58,500 | app.py:146 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[33m Deploy simulation... Individual (34) Classifier\n",
      "\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=31164)\u001b[0m 233/381 [=================>............] - ETA: 0s - loss: 0.2189 - accuracy: 0.9247\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=31164)\u001b[0m 345/381 [==========================>...] - ETA: 0s - loss: 0.2223 - accuracy: 0.9259\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=31164)\u001b[0m 173/381 [============>.................] - ETA: 0s - loss: 0.2170 - accuracy: 0.9245\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=31164)\u001b[0m \u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=31164)\u001b[0m   1/381 [..............................] - ETA: 55s - loss: 0.1734 - accuracy: 0.9531\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=31728)\u001b[0m 110/381 [=======>......................] - ETA: 0s - loss: 0.2022 - accuracy: 0.9284\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=31164)\u001b[0m 381/381 [==============================] - 0s 874us/step - loss: 0.2416 - accuracy: 0.9262\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=31728)\u001b[0m 336/381 [=========================>....] - ETA: 0s - loss: 0.2122 - accuracy: 0.9260\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=31164)\u001b[0m  59/381 [===>..........................] - ETA: 0s - loss: 0.2006 - accuracy: 0.9266 \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=31164)\u001b[0m 115/381 [========>.....................] - ETA: 0s - loss: 0.2249 - accuracy: 0.9235\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=31728)\u001b[0m 225/381 [================>.............] - ETA: 0s - loss: 0.2129 - accuracy: 0.9258\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=31164)\u001b[0m 289/381 [=====================>........] - ETA: 0s - loss: 0.2283 - accuracy: 0.9243\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=31164)\u001b[0m Client ID: 8\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=31164)\u001b[0m Client  8 Evaluating...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=31164)\u001b[0m \u001b[33mClient 8 evaluation complete - Accuracy: 0.926247, Loss: 0.241581\u001b[0m\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-08 18:08:07,357\tINFO worker.py:1636 -- Started a local Ray instance.\n",
      "INFO flwr 2023-07-08 18:08:11,761 | app.py:180 | Flower VCE: Ray initialized with resources: {'memory': 33186653799.0, 'object_store_memory': 16593326899.0, 'node:127.0.0.1': 1.0, 'GPU': 1.0, 'CPU': 24.0}\n",
      "INFO flwr 2023-07-08 18:08:11,762 | server.py:86 | Initializing global parameters\n",
      "INFO flwr 2023-07-08 18:08:11,763 | server.py:273 | Requesting initial parameters from one random client\n",
      "INFO flwr 2023-07-08 18:08:16,070 | server.py:277 | Received initial parameters from one random client\n",
      "INFO flwr 2023-07-08 18:08:16,071 | server.py:88 | Evaluating initial parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server Evaluating... Evaluation Count:0\n",
      "\u001b[2m\u001b[36m(launch_and_get_parameters pid=11452)\u001b[0m Client ID: 8\n",
      "7336/7336 [==============================] - 6s 805us/step - loss: 3.6030 - accuracy: 0.0028\n",
      "7336/7336 [==============================] - 5s 676us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2023-07-08 18:08:28,983 | server.py:91 | initial parameters (loss, other metrics): 3.6029906272888184, {'accuracy': 0.00281156157143414}\n",
      "INFO flwr 2023-07-08 18:08:28,984 | server.py:101 | FL starting\n",
      "DEBUG flwr 2023-07-08 18:08:28,984 | server.py:218 | fit_round 1: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  [[0.02992653 0.03126754 0.02904467 ... 0.02681075 0.02970578 0.03015781]\n",
      " [0.02459189 0.02276448 0.03464108 ... 0.02579838 0.02492208 0.02309379]\n",
      " [0.00474771 0.01133377 0.02067517 ... 0.02803671 0.02325244 0.00640528]\n",
      " ...\n",
      " [0.0299165  0.03137764 0.02900952 ... 0.02662995 0.02983134 0.03018039]\n",
      " [0.02694871 0.0215764  0.03307845 ... 0.02735349 0.02607144 0.0229846 ]\n",
      " [0.02931084 0.02730506 0.04097372 ... 0.03597809 0.01964962 0.02071021]] (234745, 34)\n",
      "\u001b[33mServer evaluation complete - Accuracy: 0.0028, Loss: 3.6030\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m Client ID: 3\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m Client  3 Training...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m Epoch 1/10\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m   1/381 [..............................] - ETA: 3:55 - loss: 3.4667 - accuracy: 0.0000e+00\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m  43/381 [==>...........................] - ETA: 0s - loss: 3.0793 - accuracy: 0.3150      \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m  81/381 [=====>........................] - ETA: 0s - loss: 2.5209 - accuracy: 0.4666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 119/381 [========>.....................] - ETA: 0s - loss: 2.0557 - accuracy: 0.5320\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 159/381 [===========>..................] - ETA: 0s - loss: 1.7354 - accuracy: 0.5839\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 199/381 [==============>...............] - ETA: 0s - loss: 1.5206 - accuracy: 0.6183\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 237/381 [=================>............] - ETA: 0s - loss: 1.3843 - accuracy: 0.6398\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 275/381 [====================>.........] - ETA: 0s - loss: 1.2777 - accuracy: 0.6578\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 315/381 [=======================>......] - ETA: 0s - loss: 1.1909 - accuracy: 0.6728\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 354/381 [==========================>...] - ETA: 0s - loss: 1.1316 - accuracy: 0.6816\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 381/381 [==============================] - 1s 1ms/step - loss: 1.0909 - accuracy: 0.6879\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m Epoch 2/10\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m   1/381 [..............................] - ETA: 0s - loss: 0.3968 - accuracy: 0.8281\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m  39/381 [==>...........................] - ETA: 0s - loss: 0.5530 - accuracy: 0.7808\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m  77/381 [=====>........................] - ETA: 0s - loss: 0.5429 - accuracy: 0.7804\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 115/381 [========>.....................] - ETA: 0s - loss: 0.5440 - accuracy: 0.7781\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 155/381 [===========>..................] - ETA: 0s - loss: 0.5395 - accuracy: 0.7809\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 191/381 [==============>...............] - ETA: 0s - loss: 0.5354 - accuracy: 0.7811\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 231/381 [=================>............] - ETA: 0s - loss: 0.5353 - accuracy: 0.7799\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 269/381 [====================>.........] - ETA: 0s - loss: 0.5333 - accuracy: 0.7809\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 307/381 [=======================>......] - ETA: 0s - loss: 0.5322 - accuracy: 0.7814\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 348/381 [==========================>...] - ETA: 0s - loss: 0.5295 - accuracy: 0.7804\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 381/381 [==============================] - 0s 1ms/step - loss: 0.5286 - accuracy: 0.7802\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m Epoch 3/10\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m   1/381 [..............................] - ETA: 0s - loss: 0.4900 - accuracy: 0.7500\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m  38/381 [=>............................] - ETA: 0s - loss: 0.5267 - accuracy: 0.7796\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m  78/381 [=====>........................] - ETA: 0s - loss: 0.5089 - accuracy: 0.7873\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 119/381 [========>.....................] - ETA: 0s - loss: 0.5019 - accuracy: 0.7915\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 160/381 [===========>..................] - ETA: 0s - loss: 0.5011 - accuracy: 0.7915\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 201/381 [==============>...............] - ETA: 0s - loss: 0.5014 - accuracy: 0.7903\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 243/381 [==================>...........] - ETA: 0s - loss: 0.4967 - accuracy: 0.7903\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 282/381 [=====================>........] - ETA: 0s - loss: 0.4960 - accuracy: 0.7886\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 321/381 [========================>.....] - ETA: 0s - loss: 0.4973 - accuracy: 0.7874\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 361/381 [===========================>..] - ETA: 0s - loss: 0.4929 - accuracy: 0.7894\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 381/381 [==============================] - 0s 1ms/step - loss: 0.4939 - accuracy: 0.7898\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m Epoch 4/10\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m   1/381 [..............................] - ETA: 0s - loss: 0.4635 - accuracy: 0.8281\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m  42/381 [==>...........................] - ETA: 0s - loss: 0.4920 - accuracy: 0.7876\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m  85/381 [=====>........................] - ETA: 0s - loss: 0.4907 - accuracy: 0.7853\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 128/381 [=========>....................] - ETA: 0s - loss: 0.4862 - accuracy: 0.7903\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 169/381 [============>.................] - ETA: 0s - loss: 0.4838 - accuracy: 0.7928\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 212/381 [===============>..............] - ETA: 0s - loss: 0.4780 - accuracy: 0.7934\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 254/381 [===================>..........] - ETA: 0s - loss: 0.4800 - accuracy: 0.7912\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 291/381 [=====================>........] - ETA: 0s - loss: 0.4795 - accuracy: 0.7920\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 324/381 [========================>.....] - ETA: 0s - loss: 0.4786 - accuracy: 0.7931\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 358/381 [===========================>..] - ETA: 0s - loss: 0.4772 - accuracy: 0.7940\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 381/381 [==============================] - 0s 1ms/step - loss: 0.4761 - accuracy: 0.7939\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m Epoch 5/10\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m   1/381 [..............................] - ETA: 0s - loss: 0.4602 - accuracy: 0.7812\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m  41/381 [==>...........................] - ETA: 0s - loss: 0.4544 - accuracy: 0.8037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m  79/381 [=====>........................] - ETA: 0s - loss: 0.4513 - accuracy: 0.8040\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 120/381 [========>.....................] - ETA: 0s - loss: 0.4574 - accuracy: 0.7996\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 165/381 [===========>..................] - ETA: 0s - loss: 0.4574 - accuracy: 0.7984\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 207/381 [===============>..............] - ETA: 0s - loss: 0.4629 - accuracy: 0.7968\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 250/381 [==================>...........] - ETA: 0s - loss: 0.4635 - accuracy: 0.7964\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 290/381 [=====================>........] - ETA: 0s - loss: 0.4652 - accuracy: 0.7955\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 330/381 [========================>.....] - ETA: 0s - loss: 0.4658 - accuracy: 0.7950\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 370/381 [============================>.] - ETA: 0s - loss: 0.4626 - accuracy: 0.7977\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 381/381 [==============================] - 0s 1ms/step - loss: 0.4636 - accuracy: 0.7975\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m Epoch 6/10\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m   1/381 [..............................] - ETA: 0s - loss: 0.3472 - accuracy: 0.8906\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m  41/381 [==>...........................] - ETA: 0s - loss: 0.4662 - accuracy: 0.7927\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m  82/381 [=====>........................] - ETA: 0s - loss: 0.4611 - accuracy: 0.7933\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 121/381 [========>.....................] - ETA: 0s - loss: 0.4591 - accuracy: 0.7982\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 163/381 [===========>..................] - ETA: 0s - loss: 0.4600 - accuracy: 0.7961\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 206/381 [===============>..............] - ETA: 0s - loss: 0.4579 - accuracy: 0.7982\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 246/381 [==================>...........] - ETA: 0s - loss: 0.4595 - accuracy: 0.7990\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 285/381 [=====================>........] - ETA: 0s - loss: 0.4583 - accuracy: 0.7985\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 327/381 [========================>.....] - ETA: 0s - loss: 0.4581 - accuracy: 0.7991\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 368/381 [===========================>..] - ETA: 0s - loss: 0.4564 - accuracy: 0.7981\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 381/381 [==============================] - 0s 1ms/step - loss: 0.4561 - accuracy: 0.7980\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m Epoch 7/10\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m   1/381 [..............................] - ETA: 0s - loss: 0.4400 - accuracy: 0.8438\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m  41/381 [==>...........................] - ETA: 0s - loss: 0.4449 - accuracy: 0.8037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m  82/381 [=====>........................] - ETA: 0s - loss: 0.4449 - accuracy: 0.8003\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 118/381 [========>.....................] - ETA: 0s - loss: 0.4466 - accuracy: 0.8038\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 153/381 [===========>..................] - ETA: 0s - loss: 0.4451 - accuracy: 0.8054\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 193/381 [==============>...............] - ETA: 0s - loss: 0.4494 - accuracy: 0.8027\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 235/381 [=================>............] - ETA: 0s - loss: 0.4502 - accuracy: 0.8014\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 275/381 [====================>.........] - ETA: 0s - loss: 0.4496 - accuracy: 0.8007\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 318/381 [========================>.....] - ETA: 0s - loss: 0.4494 - accuracy: 0.8008\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 360/381 [===========================>..] - ETA: 0s - loss: 0.4508 - accuracy: 0.7992\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 381/381 [==============================] - 0s 1ms/step - loss: 0.4506 - accuracy: 0.7998\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m Epoch 8/10\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m   1/381 [..............................] - ETA: 0s - loss: 0.4224 - accuracy: 0.8438\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m  41/381 [==>...........................] - ETA: 0s - loss: 0.4372 - accuracy: 0.8110\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m  84/381 [=====>........................] - ETA: 0s - loss: 0.4532 - accuracy: 0.8015\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 124/381 [========>.....................] - ETA: 0s - loss: 0.4529 - accuracy: 0.8017\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 164/381 [===========>..................] - ETA: 0s - loss: 0.4513 - accuracy: 0.7989\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 206/381 [===============>..............] - ETA: 0s - loss: 0.4514 - accuracy: 0.7982\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 245/381 [==================>...........] - ETA: 0s - loss: 0.4520 - accuracy: 0.7978\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 286/381 [=====================>........] - ETA: 0s - loss: 0.4497 - accuracy: 0.7991\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 325/381 [========================>.....] - ETA: 0s - loss: 0.4487 - accuracy: 0.7989\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 365/381 [===========================>..] - ETA: 0s - loss: 0.4471 - accuracy: 0.8002\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 381/381 [==============================] - 0s 1ms/step - loss: 0.4456 - accuracy: 0.8013\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m Epoch 9/10\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m   1/381 [..............................] - ETA: 0s - loss: 0.4786 - accuracy: 0.8125\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m  40/381 [==>...........................] - ETA: 0s - loss: 0.4361 - accuracy: 0.8059\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m  78/381 [=====>........................] - ETA: 0s - loss: 0.4387 - accuracy: 0.8033\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 117/381 [========>.....................] - ETA: 0s - loss: 0.4433 - accuracy: 0.8037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 156/381 [===========>..................] - ETA: 0s - loss: 0.4424 - accuracy: 0.8028\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 195/381 [==============>...............] - ETA: 0s - loss: 0.4418 - accuracy: 0.8039\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 233/381 [=================>............] - ETA: 0s - loss: 0.4404 - accuracy: 0.8053\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 271/381 [====================>.........] - ETA: 0s - loss: 0.4394 - accuracy: 0.8063\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 313/381 [=======================>......] - ETA: 0s - loss: 0.4381 - accuracy: 0.8059\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 354/381 [==========================>...] - ETA: 0s - loss: 0.4404 - accuracy: 0.8042\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 381/381 [==============================] - 0s 1ms/step - loss: 0.4418 - accuracy: 0.8031\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m Epoch 10/10\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m   1/381 [..............................] - ETA: 0s - loss: 0.3714 - accuracy: 0.8125\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m  36/381 [=>............................] - ETA: 0s - loss: 0.4449 - accuracy: 0.7930\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m  75/381 [====>.........................] - ETA: 0s - loss: 0.4421 - accuracy: 0.7969\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 115/381 [========>.....................] - ETA: 0s - loss: 0.4401 - accuracy: 0.7974\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 154/381 [===========>..................] - ETA: 0s - loss: 0.4379 - accuracy: 0.8003\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 194/381 [==============>...............] - ETA: 0s - loss: 0.4379 - accuracy: 0.8015\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 234/381 [=================>............] - ETA: 0s - loss: 0.4398 - accuracy: 0.8019\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 275/381 [====================>.........] - ETA: 0s - loss: 0.4397 - accuracy: 0.8022\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 318/381 [========================>.....] - ETA: 0s - loss: 0.4385 - accuracy: 0.8030\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 361/381 [===========================>..] - ETA: 0s - loss: 0.4380 - accuracy: 0.8034\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 381/381 [==============================] - 0s 1ms/step - loss: 0.4376 - accuracy: 0.8039\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m Client  3 Training complete...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=33188)\u001b[0m Client ID: 2\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=33188)\u001b[0m Client  2 Training...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=33188)\u001b[0m Epoch 1/10\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=3456)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=3456)\u001b[0m   1/381 [..............................] - ETA: 3:39 - loss: 3.4968 - accuracy: 0.0000e+00\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=37660)\u001b[0m  40/381 [==>...........................] - ETA: 0s - loss: 3.1810 - accuracy: 0.2605      \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m  62/381 [===>..........................] - ETA: 0s - loss: 2.8852 - accuracy: 0.3944\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14900)\u001b[0m  97/381 [======>.......................] - ETA: 0s - loss: 2.3034 - accuracy: 0.4878\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=37660)\u001b[0m 103/381 [=======>......................] - ETA: 0s - loss: 2.3107 - accuracy: 0.4964\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m 121/381 [========>.....................] - ETA: 0s - loss: 2.1057 - accuracy: 0.5360\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14900)\u001b[0m 151/381 [==========>...................] - ETA: 0s - loss: 1.7731 - accuracy: 0.5736\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=37660)\u001b[0m 156/381 [===========>..................] - ETA: 0s - loss: 1.8131 - accuracy: 0.5773\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14900)\u001b[0m 185/381 [=============>................] - ETA: 0s - loss: 1.5787 - accuracy: 0.6015\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m  31/381 [=>............................] - ETA: 0s - loss: 3.2692 - accuracy: 0.1689      \u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=3456)\u001b[0m 191/381 [==============>...............] - ETA: 0s - loss: 1.5689 - accuracy: 0.6177\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14900)\u001b[0m 219/381 [================>.............] - ETA: 0s - loss: 1.4383 - accuracy: 0.6225\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=9228)\u001b[0m 251/381 [==================>...........] - ETA: 0s - loss: 1.3728 - accuracy: 0.6401\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14900)\u001b[0m 316/381 [=======================>......] - ETA: 0s - loss: 1.1854 - accuracy: 0.6650\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14900)\u001b[0m 348/381 [==========================>...] - ETA: 0s - loss: 1.1310 - accuracy: 0.6743\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14900)\u001b[0m 381/381 [==============================] - 1s 2ms/step - loss: 1.0818 - accuracy: 0.6839\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m 284/381 [=====================>........] - ETA: 0s - loss: 1.3000 - accuracy: 0.6532\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=33188)\u001b[0m 319/381 [========================>.....] - ETA: 0s - loss: 1.1895 - accuracy: 0.6703\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=3456)\u001b[0m 381/381 [==============================] - ETA: 0s - loss: 1.0963 - accuracy: 0.6879\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=33188)\u001b[0m 127/381 [=========>....................] - ETA: 0s - loss: 1.9993 - accuracy: 0.5436\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=37660)\u001b[0m 254/381 [===================>..........] - ETA: 0s - loss: 0.5452 - accuracy: 0.7786\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=33188)\u001b[0m 229/381 [=================>............] - ETA: 0s - loss: 0.5370 - accuracy: 0.7746\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=1336)\u001b[0m 297/381 [======================>.......] - ETA: 0s - loss: 0.5375 - accuracy: 0.7746\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=3456)\u001b[0m 332/381 [=========================>....] - ETA: 0s - loss: 0.5338 - accuracy: 0.7740\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14900)\u001b[0m 359/381 [===========================>..] - ETA: 0s - loss: 0.5293 - accuracy: 0.7789\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=3456)\u001b[0m 166/381 [============>.................] - ETA: 0s - loss: 0.5028 - accuracy: 0.7808\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m 374/381 [============================>.] - ETA: 0s - loss: 1.1261 - accuracy: 0.6816\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m 267/381 [====================>.........] - ETA: 0s - loss: 0.5024 - accuracy: 0.7842\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=37660)\u001b[0m 103/381 [=======>......................] - ETA: 0s - loss: 0.4783 - accuracy: 0.7976\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14900)\u001b[0m 211/381 [===============>..............] - ETA: 0s - loss: 0.4764 - accuracy: 0.7901\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=37660)\u001b[0m  39/381 [==>...........................] - ETA: 0s - loss: 0.4661 - accuracy: 0.7917\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m  72/381 [====>.........................] - ETA: 0s - loss: 0.4482 - accuracy: 0.8016\u001b[32m [repeated 46x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m Client ID: 6\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m Client  6 Training...\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m Epoch 8/10\u001b[32m [repeated 71x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=9228)\u001b[0m \u001b[32m [repeated 981x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m   1/381 [..............................] - ETA: 0s - loss: 0.4323 - accuracy: 0.7969\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=33188)\u001b[0m 192/381 [==============>...............] - ETA: 0s - loss: 0.4452 - accuracy: 0.7994\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m  61/381 [===>..........................] - ETA: 0s - loss: 0.4508 - accuracy: 0.7930\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m  91/381 [======>.......................] - ETA: 0s - loss: 0.4472 - accuracy: 0.7989\u001b[32m [repeated 46x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=33188)\u001b[0m 102/381 [=======>......................] - ETA: 0s - loss: 0.4351 - accuracy: 0.8022\u001b[32m [repeated 32x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m 120/381 [========>.....................] - ETA: 0s - loss: 0.4507 - accuracy: 0.7941\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m 147/381 [==========>...................] - ETA: 0s - loss: 0.4504 - accuracy: 0.7937\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=9064)\u001b[0m 153/381 [===========>..................] - ETA: 0s - loss: 0.4508 - accuracy: 0.7940\u001b[32m [repeated 43x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=9064)\u001b[0m 184/381 [=============>................] - ETA: 0s - loss: 0.4467 - accuracy: 0.7969\u001b[32m [repeated 30x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m  31/381 [=>............................] - ETA: 0s - loss: 0.4593 - accuracy: 0.7873\u001b[32m [repeated 70x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=9228)\u001b[0m 192/381 [==============>...............] - ETA: 0s - loss: 0.4452 - accuracy: 0.7994\u001b[32m [repeated 30x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=9228)\u001b[0m 223/381 [================>.............] - ETA: 0s - loss: 0.4453 - accuracy: 0.7990\u001b[32m [repeated 43x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=9064)\u001b[0m 245/381 [==================>...........] - ETA: 0s - loss: 0.4440 - accuracy: 0.7971\u001b[32m [repeated 32x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=9064)\u001b[0m 308/381 [=======================>......] - ETA: 0s - loss: 0.4425 - accuracy: 0.7994\u001b[32m [repeated 39x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=9228)\u001b[0m 351/381 [==========================>...] - ETA: 0s - loss: 0.4450 - accuracy: 0.7979\u001b[32m [repeated 44x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m 381/381 [==============================] - 1s 2ms/step - loss: 0.4516 - accuracy: 0.7956\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=9228)\u001b[0m 286/381 [=====================>........] - ETA: 0s - loss: 0.4422 - accuracy: 0.7997\u001b[32m [repeated 29x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=9228)\u001b[0m 318/381 [========================>.....] - ETA: 0s - loss: 0.4441 - accuracy: 0.7981\u001b[32m [repeated 26x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14900)\u001b[0m 381/381 [==============================] - ETA: 0s - loss: 0.4519 - accuracy: 0.7997\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-07-08 18:08:42,078 | server.py:232 | fit_round 1 received 10 results and 0 failures\n",
      "WARNING flwr 2023-07-08 18:08:42,091 | fedavg.py:243 | No fit_metrics_aggregation_fn provided\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=3456)\u001b[0m Client  8 Training complete...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m 129/381 [=========>....................] - ETA: 0s - loss: 0.4356 - accuracy: 0.7992\u001b[32m [repeated 47x across cluster]\u001b[0m\n",
      "Server Evaluating... Evaluation Count:1\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=9064)\u001b[0m 263/381 [===================>..........] - ETA: 0s - loss: 0.4342 - accuracy: 0.8022\u001b[32m [repeated 32x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=9064)\u001b[0m 230/381 [=================>............] - ETA: 0s - loss: 0.4371 - accuracy: 0.7996\u001b[32m [repeated 26x across cluster]\u001b[0m\n",
      "7336/7336 [==============================] - 6s 814us/step - loss: 0.4543 - accuracy: 0.7993\n",
      "7336/7336 [==============================] - 5s 653us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2023-07-08 18:08:54,713 | server.py:119 | fit progress: (1, 0.4543115794658661, {'accuracy': 0.7992630004882812}, 25.72807769999963)\n",
      "DEBUG flwr 2023-07-08 18:08:54,714 | server.py:168 | evaluate_round 1: strategy sampled 5 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  [[3.54392313e-07 7.41136290e-08 6.23691521e-05 ... 4.77474032e-07\n",
      "  8.87353622e-07 2.21363962e-07]\n",
      " [1.04494784e-05 1.64200878e-06 7.41719941e-06 ... 3.53874157e-06\n",
      "  1.60394793e-05 9.89462205e-06]\n",
      " [8.66503629e-04 7.86254997e-04 4.72023705e-04 ... 1.19406504e-04\n",
      "  1.61767122e-04 4.25815262e-04]\n",
      " ...\n",
      " [4.01063801e-07 8.73906600e-08 6.68219509e-05 ... 5.39639871e-07\n",
      "  1.02753927e-06 2.51799946e-07]\n",
      " [1.56322403e-06 9.01555097e-07 1.19123088e-05 ... 7.25231416e-07\n",
      "  1.48773063e-06 4.08742579e-07]\n",
      " [5.41399970e-07 2.90294331e-08 9.99860883e-01 ... 2.71495484e-08\n",
      "  2.72033907e-09 2.42788829e-08]] (234745, 34)\n",
      "\u001b[33mServer evaluation complete - Accuracy: 0.7993, Loss: 0.4543\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=14900)\u001b[0m Client  5 Evaluating...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=9064)\u001b[0m 296/381 [======================>.......] - ETA: 0s - loss: 0.4362 - accuracy: 0.8019\u001b[32m [repeated 23x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=37660)\u001b[0m 331/381 [=========================>....] - ETA: 0s - loss: 0.4417 - accuracy: 0.8000\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=9064)\u001b[0m 364/381 [===========================>..] - ETA: 0s - loss: 0.4358 - accuracy: 0.8020\u001b[32m [repeated 30x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=9064)\u001b[0m 167/381 [============>.................] - ETA: 0s - loss: 0.4355 - accuracy: 0.8033\u001b[32m [repeated 29x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m 369/381 [============================>.] - ETA: 0s - loss: 0.4472 - accuracy: 0.7966\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=37660)\u001b[0m 268/381 [====================>.........] - ETA: 0s - loss: 0.4430 - accuracy: 0.7990\u001b[32m [repeated 29x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m 204/381 [===============>..............] - ETA: 0s - loss: 0.4515 - accuracy: 0.7935\u001b[32m [repeated 25x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m  67/381 [====>.........................] - ETA: 0s - loss: 0.4335 - accuracy: 0.7980\u001b[32m [repeated 23x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=14900)\u001b[0m Client  5 Evaluating...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m Epoch 10/10\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m \u001b[32m [repeated 174x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m   1/381 [..............................] - ETA: 0s - loss: 0.5590 - accuracy: 0.6406\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m  97/381 [======>.......................] - ETA: 0s - loss: 0.4310 - accuracy: 0.8009\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m Client  5 Evaluating...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m 161/381 [===========>..................] - ETA: 0s - loss: 0.4441 - accuracy: 0.7975\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m  34/381 [=>............................] - ETA: 0s - loss: 0.4453 - accuracy: 0.7845\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m 191/381 [==============>...............] - ETA: 0s - loss: 0.4476 - accuracy: 0.7954\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m 222/381 [================>.............] - ETA: 0s - loss: 0.4497 - accuracy: 0.7930\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m Client  5 Evaluating...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=9228)\u001b[0m Client  5 Evaluating...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m 381/381 [==============================] - 1s 1ms/step - loss: 0.4471 - accuracy: 0.7971\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m 285/381 [=====================>........] - ETA: 0s - loss: 0.4457 - accuracy: 0.7967\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m 324/381 [========================>.....] - ETA: 0s - loss: 0.4476 - accuracy: 0.7963\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m Client  6 Training complete...\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=9228)\u001b[0m Client ID: 8\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=9064)\u001b[0m  57/381 [===>..........................] - ETA: 0s - loss: 0.4616 - accuracy: 0.7977  \n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=14900)\u001b[0m 108/381 [=======>......................] - ETA: 0s - loss: 0.4518 - accuracy: 0.8009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-07-08 18:08:55,449 | server.py:182 | evaluate_round 1 received 5 results and 0 failures\n",
      "WARNING flwr 2023-07-08 18:08:55,450 | fedavg.py:274 | No evaluate_metrics_aggregation_fn provided\n",
      "DEBUG flwr 2023-07-08 18:08:55,450 | server.py:218 | fit_round 2: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=14900)\u001b[0m \u001b[33mClient 5 evaluation complete - Accuracy: 0.800246, Loss: 0.448527\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=1336)\u001b[0m Client  5 Training...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=1336)\u001b[0m  40/381 [==>...........................] - ETA: 0s - loss: 0.4485 - accuracy: 0.7980  \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=1336)\u001b[0m 138/381 [=========>....................] - ETA: 0s - loss: 0.4504 - accuracy: 0.7987\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 126/381 [========>.....................] - ETA: 0s - loss: 0.4452 - accuracy: 0.8020\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=33188)\u001b[0m 140/381 [==========>...................] - ETA: 0s - loss: 0.4528 - accuracy: 0.7980\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=1336)\u001b[0m 241/381 [=================>............] - ETA: 0s - loss: 0.4524 - accuracy: 0.7969\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=33188)\u001b[0m 246/381 [==================>...........] - ETA: 0s - loss: 0.4547 - accuracy: 0.7984\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 260/381 [===================>..........] - ETA: 0s - loss: 0.4526 - accuracy: 0.8010\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=1336)\u001b[0m 311/381 [=======================>......] - ETA: 0s - loss: 0.4538 - accuracy: 0.7985\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=1336)\u001b[0m 345/381 [==========================>...] - ETA: 0s - loss: 0.4521 - accuracy: 0.7995\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=33188)\u001b[0m 245/381 [==================>...........] - ETA: 0s - loss: 0.4397 - accuracy: 0.8031\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=33188)\u001b[0m 381/381 [==============================] - ETA: 0s - loss: 0.4385 - accuracy: 0.8038\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=33188)\u001b[0m 381/381 [==============================] - ETA: 0s - loss: 0.4246 - accuracy: 0.8071\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=11364)\u001b[0m Client  1 Evaluating...\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=37660)\u001b[0m 303/381 [======================>.......] - ETA: 0s - loss: 0.4236 - accuracy: 0.8071\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m 342/381 [=========================>....] - ETA: 0s - loss: 0.4295 - accuracy: 0.8034\u001b[32m [repeated 40x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=37660)\u001b[0m 368/381 [===========================>..] - ETA: 0s - loss: 0.4308 - accuracy: 0.8054\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m 173/381 [============>.................] - ETA: 0s - loss: 0.4287 - accuracy: 0.8064\u001b[32m [repeated 54x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m 379/381 [============================>.] - ETA: 0s - loss: 0.4267 - accuracy: 0.8069\u001b[32m [repeated 41x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m 275/381 [====================>.........] - ETA: 0s - loss: 0.4255 - accuracy: 0.8081\u001b[32m [repeated 53x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m 207/381 [===============>..............] - ETA: 0s - loss: 0.4251 - accuracy: 0.8075\u001b[32m [repeated 33x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m  70/381 [====>.........................] - ETA: 0s - loss: 0.4240 - accuracy: 0.8065\u001b[32m [repeated 68x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m Epoch 7/10\u001b[32m [repeated 70x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m \u001b[32m [repeated 784x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m   1/381 [..............................] - ETA: 0s - loss: 0.4890 - accuracy: 0.7969\u001b[32m [repeated 75x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m 101/381 [======>.......................] - ETA: 0s - loss: 0.4411 - accuracy: 0.7975\u001b[32m [repeated 25x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m 164/381 [===========>..................] - ETA: 0s - loss: 0.4458 - accuracy: 0.8007\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m  36/381 [=>............................] - ETA: 0s - loss: 0.4173 - accuracy: 0.8073\u001b[32m [repeated 69x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m 203/381 [==============>...............] - ETA: 0s - loss: 0.4256 - accuracy: 0.8058\u001b[32m [repeated 27x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 226/381 [================>.............] - ETA: 0s - loss: 0.4531 - accuracy: 0.8010\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m 381/381 [==============================] - 1s 1ms/step - loss: 0.4264 - accuracy: 0.8070\u001b[32m [repeated 65x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=37660)\u001b[0m 283/381 [=====================>........] - ETA: 0s - loss: 0.4245 - accuracy: 0.8071\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=1336)\u001b[0m 321/381 [========================>.....] - ETA: 0s - loss: 0.4255 - accuracy: 0.8080\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=37660)\u001b[0m Client ID: 2\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=33188)\u001b[0m 178/381 [=============>................] - ETA: 0s - loss: 0.4211 - accuracy: 0.8082\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m  63/381 [===>..........................] - ETA: 0s - loss: 0.4410 - accuracy: 0.8046\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m 105/381 [=======>......................] - ETA: 0s - loss: 0.4115 - accuracy: 0.8125\u001b[32m [repeated 49x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=1336)\u001b[0m \u001b[33mClient 9 evaluation complete - Accuracy: 0.801921, Loss: 0.446164\u001b[0m\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=3456)\u001b[0m Client  8 Training...\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=9064)\u001b[0m  39/381 [==>...........................] - ETA: 0s - loss: 0.4139 - accuracy: 0.8189\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m 136/381 [=========>....................] - ETA: 0s - loss: 0.4216 - accuracy: 0.8035\u001b[32m [repeated 66x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m 140/381 [==========>...................] - ETA: 0s - loss: 0.4185 - accuracy: 0.8071\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m 240/381 [=================>............] - ETA: 0s - loss: 0.4167 - accuracy: 0.8098\u001b[32m [repeated 57x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=33188)\u001b[0m 245/381 [==================>...........] - ETA: 0s - loss: 0.4005 - accuracy: 0.8177\u001b[32m [repeated 30x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m 266/381 [===================>..........] - ETA: 0s - loss: 0.4398 - accuracy: 0.8041\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m 310/381 [=======================>......] - ETA: 0s - loss: 0.4162 - accuracy: 0.8100\u001b[32m [repeated 66x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m 345/381 [==========================>...] - ETA: 0s - loss: 0.4168 - accuracy: 0.8102\u001b[32m [repeated 47x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-07-08 18:09:01,998 | server.py:232 | fit_round 2 received 10 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=33188)\u001b[0m Client  9 Training complete...\n",
      "Server Evaluating... Evaluation Count:2\n",
      "7336/7336 [==============================] - 6s 759us/step - loss: 0.4231 - accuracy: 0.8090\n",
      "7336/7336 [==============================] - 5s 660us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2023-07-08 18:09:14,250 | server.py:119 | fit progress: (2, 0.42306700348854065, {'accuracy': 0.8089842200279236}, 45.26448090000031)\n",
      "DEBUG flwr 2023-07-08 18:09:14,251 | server.py:168 | evaluate_round 2: strategy sampled 5 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  [[6.56789538e-08 6.42990244e-11 4.66517558e-05 ... 9.68443099e-13\n",
      "  7.07534864e-11 9.82015233e-11]\n",
      " [8.53397125e-07 2.17292726e-08 7.28006853e-07 ... 1.50404689e-11\n",
      "  4.31375424e-09 7.89485455e-09]\n",
      " [7.75871740e-05 1.96010642e-05 1.00470585e-04 ... 5.37583595e-08\n",
      "  4.06124087e-07 2.30482942e-06]\n",
      " ...\n",
      " [7.71995516e-08 9.87171664e-11 5.72102217e-05 ... 1.47870290e-12\n",
      "  1.00048608e-10 1.35573497e-10]\n",
      " [4.70367013e-07 7.46303996e-08 3.35499112e-06 ... 2.50382766e-12\n",
      "  1.87582588e-10 5.20746335e-10]\n",
      " [2.52655017e-08 4.53922360e-12 9.99971390e-01 ... 1.44730588e-14\n",
      "  8.87238687e-14 1.50457121e-12]] (234745, 34)\n",
      "\u001b[33mServer evaluation complete - Accuracy: 0.8090, Loss: 0.4231\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=1336)\u001b[0m 381/381 [==============================] - ETA: 0s - loss: 0.4158 - accuracy: 0.8113\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=11452)\u001b[0m Client  6 Evaluating...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=37660)\u001b[0m 341/381 [=========================>....] - ETA: 0s - loss: 0.4117 - accuracy: 0.8122\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m Client  6 Evaluating...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m 175/381 [============>.................] - ETA: 0s - loss: 0.4054 - accuracy: 0.8130\u001b[32m [repeated 36x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m 380/381 [============================>.] - ETA: 0s - loss: 0.4167 - accuracy: 0.8100\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m 275/381 [====================>.........] - ETA: 0s - loss: 0.4119 - accuracy: 0.8111\u001b[32m [repeated 29x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m 209/381 [===============>..............] - ETA: 0s - loss: 0.4075 - accuracy: 0.8121\u001b[32m [repeated 37x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m  71/381 [====>.........................] - ETA: 0s - loss: 0.4034 - accuracy: 0.8094\u001b[32m [repeated 31x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m Epoch 10/10\u001b[32m [repeated 30x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m \u001b[32m [repeated 448x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m   1/381 [..............................] - ETA: 0s - loss: 0.3367 - accuracy: 0.8438\u001b[32m [repeated 30x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m 101/381 [======>.......................] - ETA: 0s - loss: 0.4172 - accuracy: 0.8093\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m  36/381 [=>............................] - ETA: 0s - loss: 0.4078 - accuracy: 0.8099\u001b[32m [repeated 29x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m 202/381 [==============>...............] - ETA: 0s - loss: 0.4196 - accuracy: 0.8080\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m 381/381 [==============================] - 1s 1ms/step - loss: 0.4174 - accuracy: 0.8080\u001b[32m [repeated 40x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=9228)\u001b[0m 281/381 [=====================>........] - ETA: 0s - loss: 0.4044 - accuracy: 0.8146\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=9064)\u001b[0m 319/381 [========================>.....] - ETA: 0s - loss: 0.4225 - accuracy: 0.8052\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=11452)\u001b[0m Client  6 Evaluating...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 178/381 [=============>................] - ETA: 0s - loss: 0.4223 - accuracy: 0.8067\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m 105/381 [=======>......................] - ETA: 0s - loss: 0.4026 - accuracy: 0.8126\u001b[32m [repeated 27x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m 135/381 [=========>....................] - ETA: 0s - loss: 0.4187 - accuracy: 0.8089\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m 140/381 [==========>...................] - ETA: 0s - loss: 0.4017 - accuracy: 0.8154\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m 236/381 [=================>............] - ETA: 0s - loss: 0.4175 - accuracy: 0.8097\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m 242/381 [==================>...........] - ETA: 0s - loss: 0.4099 - accuracy: 0.8120\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m 313/381 [=======================>......] - ETA: 0s - loss: 0.4130 - accuracy: 0.8111\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=37660)\u001b[0m 347/381 [==========================>...] - ETA: 0s - loss: 0.4085 - accuracy: 0.8137\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m Client  1 Training complete...\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=3456)\u001b[0m Client ID: 2\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=3456)\u001b[0m Client  2 Evaluating...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=11452)\u001b[0m  54/381 [===>..........................] - ETA: 0s - loss: 0.4293 - accuracy: 0.8084  \n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=11364)\u001b[0m 153/381 [===========>..................] - ETA: 0s - loss: 0.4251 - accuracy: 0.8033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-07-08 18:09:15,042 | server.py:182 | evaluate_round 2 received 5 results and 0 failures\n",
      "DEBUG flwr 2023-07-08 18:09:15,043 | server.py:218 | fit_round 3: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=11452)\u001b[0m \u001b[33mClient 6 evaluation complete - Accuracy: 0.805253, Loss: 0.423678\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m Client  5 Training...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=37660)\u001b[0m  86/381 [=====>........................] - ETA: 0s - loss: 0.4153 - accuracy: 0.8118\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 120/381 [========>.....................] - ETA: 0s - loss: 0.4290 - accuracy: 0.8051\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m 225/381 [================>.............] - ETA: 0s - loss: 0.4250 - accuracy: 0.8043\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=3456)\u001b[0m 257/381 [===================>..........] - ETA: 0s - loss: 0.4281 - accuracy: 0.8111\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=37660)\u001b[0m 302/381 [======================>.......] - ETA: 0s - loss: 0.4259 - accuracy: 0.8100\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=3456)\u001b[0m 358/381 [===========================>..] - ETA: 0s - loss: 0.4316 - accuracy: 0.8087\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m 271/381 [====================>.........] - ETA: 0s - loss: 0.3982 - accuracy: 0.8203\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=1336)\u001b[0m 332/381 [=========================>....] - ETA: 0s - loss: 0.4077 - accuracy: 0.8156\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=1336)\u001b[0m 172/381 [============>.................] - ETA: 0s - loss: 0.4058 - accuracy: 0.8171\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 378/381 [============================>.] - ETA: 0s - loss: 0.4068 - accuracy: 0.8190\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 271/381 [====================>.........] - ETA: 0s - loss: 0.3982 - accuracy: 0.8203\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=1336)\u001b[0m 205/381 [===============>..............] - ETA: 0s - loss: 0.4012 - accuracy: 0.8194\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=1336)\u001b[0m  68/381 [====>.........................] - ETA: 0s - loss: 0.4171 - accuracy: 0.8146\u001b[32m [repeated 41x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=1336)\u001b[0m Epoch 6/10\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m \u001b[32m [repeated 773x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=1336)\u001b[0m   1/381 [..............................] - ETA: 0s - loss: 0.3584 - accuracy: 0.8281\u001b[32m [repeated 65x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m  98/381 [======>.......................] - ETA: 0s - loss: 0.4008 - accuracy: 0.8225\u001b[32m [repeated 51x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=1336)\u001b[0m  34/381 [=>............................] - ETA: 0s - loss: 0.4116 - accuracy: 0.8171\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m 200/381 [==============>...............] - ETA: 0s - loss: 0.3975 - accuracy: 0.8235\u001b[32m [repeated 27x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=1336)\u001b[0m 381/381 [==============================] - 1s 2ms/step - loss: 0.4071 - accuracy: 0.8155\u001b[32m [repeated 55x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=1336)\u001b[0m 285/381 [=====================>........] - ETA: 0s - loss: 0.4104 - accuracy: 0.8130\u001b[32m [repeated 34x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=1336)\u001b[0m 318/381 [========================>.....] - ETA: 0s - loss: 0.4100 - accuracy: 0.8142\u001b[32m [repeated 23x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=1336)\u001b[0m 189/381 [=============>................] - ETA: 0s - loss: 0.4043 - accuracy: 0.8143\u001b[32m [repeated 28x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=1336)\u001b[0m 102/381 [=======>......................] - ETA: 0s - loss: 0.4114 - accuracy: 0.8145\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=1336)\u001b[0m 137/381 [=========>....................] - ETA: 0s - loss: 0.4088 - accuracy: 0.8155\u001b[32m [repeated 35x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=1336)\u001b[0m 148/381 [==========>...................] - ETA: 0s - loss: 0.4082 - accuracy: 0.8175\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m 235/381 [=================>............] - ETA: 0s - loss: 0.4000 - accuracy: 0.8201\u001b[32m [repeated 23x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=1336)\u001b[0m 253/381 [==================>...........] - ETA: 0s - loss: 0.4090 - accuracy: 0.8134\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m 317/381 [=======================>......] - ETA: 0s - loss: 0.4026 - accuracy: 0.8180\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=1336)\u001b[0m 354/381 [==========================>...] - ETA: 0s - loss: 0.4089 - accuracy: 0.8143\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m Client ID: 9\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=11364)\u001b[0m Client  1 Evaluating...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=1336)\u001b[0m  63/381 [===>..........................] - ETA: 0s - loss: 0.4051 - accuracy: 0.8175\u001b[32m [repeated 23x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=3456)\u001b[0m 165/381 [===========>..................] - ETA: 0s - loss: 0.3989 - accuracy: 0.8182\u001b[32m [repeated 38x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=11364)\u001b[0m \u001b[33mClient 1 evaluation complete - Accuracy: 0.805171, Loss: 0.420529\u001b[0m\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m 381/381 [==============================] - ETA: 0s - loss: 0.3916 - accuracy: 0.8240\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m Client  9 Training...\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=1336)\u001b[0m  81/381 [=====>........................] - ETA: 0s - loss: 0.4278 - accuracy: 0.7986\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=9064)\u001b[0m 125/381 [========>.....................] - ETA: 0s - loss: 0.4059 - accuracy: 0.8127\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=1336)\u001b[0m 226/381 [================>.............] - ETA: 0s - loss: 0.3956 - accuracy: 0.8256\u001b[32m [repeated 38x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=1336)\u001b[0m 257/381 [===================>..........] - ETA: 0s - loss: 0.3954 - accuracy: 0.8253\u001b[32m [repeated 31x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14900)\u001b[0m 298/381 [======================>.......] - ETA: 0s - loss: 0.3860 - accuracy: 0.8279\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=1336)\u001b[0m 361/381 [===========================>..] - ETA: 0s - loss: 0.3940 - accuracy: 0.8266\u001b[32m [repeated 30x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-07-08 18:09:21,933 | server.py:232 | fit_round 3 received 10 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=3456)\u001b[0m Client  8 Training complete...\n",
      "Server Evaluating... Evaluation Count:3\n",
      "7336/7336 [==============================] - 6s 794us/step - loss: 0.3997 - accuracy: 0.8420\n",
      "7336/7336 [==============================] - 5s 708us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2023-07-08 18:09:34,839 | server.py:119 | fit progress: (3, 0.39969688653945923, {'accuracy': 0.8420498967170715}, 65.85475880000013)\n",
      "DEBUG flwr 2023-07-08 18:09:34,840 | server.py:168 | evaluate_round 3: strategy sampled 5 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  [[4.31677982e-08 7.18224135e-12 1.06611205e-05 ... 4.14919698e-16\n",
      "  7.09137556e-13 1.10318167e-12]\n",
      " [5.78043512e-07 3.24448468e-09 1.77654471e-07 ... 4.29914918e-15\n",
      "  6.71186023e-12 3.94892348e-11]\n",
      " [4.65584817e-05 6.37764515e-06 4.16275434e-05 ... 1.20057381e-10\n",
      "  4.36947856e-09 1.02254425e-07]\n",
      " ...\n",
      " [5.04453581e-08 1.69655782e-11 1.75960486e-05 ... 9.60516198e-16\n",
      "  1.29520038e-12 2.02463849e-12]\n",
      " [2.42749252e-07 4.22500825e-08 2.18826827e-07 ... 2.69777241e-15\n",
      "  1.02022915e-12 1.20470882e-11]\n",
      " [7.22234628e-09 2.11770807e-14 9.99986768e-01 ... 1.50132661e-19\n",
      "  5.71100252e-17 6.44444107e-16]] (234745, 34)\n",
      "\u001b[33mServer evaluation complete - Accuracy: 0.8420, Loss: 0.3997\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=1336)\u001b[0m 342/381 [=========================>....] - ETA: 0s - loss: 0.3848 - accuracy: 0.8303\u001b[32m [repeated 26x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=1336)\u001b[0m 176/381 [============>.................] - ETA: 0s - loss: 0.3878 - accuracy: 0.8265\u001b[32m [repeated 27x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m 374/381 [============================>.] - ETA: 0s - loss: 0.3804 - accuracy: 0.8345\u001b[32m [repeated 23x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=1336)\u001b[0m 275/381 [====================>.........] - ETA: 0s - loss: 0.3860 - accuracy: 0.8284\u001b[32m [repeated 29x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=1336)\u001b[0m 210/381 [===============>..............] - ETA: 0s - loss: 0.3860 - accuracy: 0.8281\u001b[32m [repeated 30x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=1336)\u001b[0m  71/381 [====>.........................] - ETA: 0s - loss: 0.3940 - accuracy: 0.8200\u001b[32m [repeated 40x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=1336)\u001b[0m Epoch 10/10\u001b[32m [repeated 40x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=1336)\u001b[0m \u001b[32m [repeated 545x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=1336)\u001b[0m   1/381 [..............................] - ETA: 0s - loss: 0.3586 - accuracy: 0.7656\u001b[32m [repeated 40x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=1336)\u001b[0m  98/381 [======>.......................] - ETA: 0s - loss: 0.3947 - accuracy: 0.8256\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m  35/381 [=>............................] - ETA: 0s - loss: 0.3821 - accuracy: 0.8429\u001b[32m [repeated 40x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=1336)\u001b[0m 196/381 [==============>...............] - ETA: 0s - loss: 0.3956 - accuracy: 0.8258\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=1336)\u001b[0m 381/381 [==============================] - 1s 1ms/step - loss: 0.3862 - accuracy: 0.8307\u001b[32m [repeated 50x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14900)\u001b[0m 280/381 [=====================>........] - ETA: 0s - loss: 0.3825 - accuracy: 0.8326\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=1336)\u001b[0m 325/381 [========================>.....] - ETA: 0s - loss: 0.3926 - accuracy: 0.8273\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14900)\u001b[0m 180/381 [=============>................] - ETA: 0s - loss: 0.3909 - accuracy: 0.8276\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=1336)\u001b[0m 107/381 [=======>......................] - ETA: 0s - loss: 0.3946 - accuracy: 0.8202\u001b[32m [repeated 31x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m 138/381 [=========>....................] - ETA: 0s - loss: 0.3739 - accuracy: 0.8374\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=1336)\u001b[0m 141/381 [==========>...................] - ETA: 0s - loss: 0.3943 - accuracy: 0.8235\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m 238/381 [=================>............] - ETA: 0s - loss: 0.3782 - accuracy: 0.8354\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=1336)\u001b[0m 242/381 [==================>...........] - ETA: 0s - loss: 0.3852 - accuracy: 0.8292\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=1336)\u001b[0m 309/381 [=======================>......] - ETA: 0s - loss: 0.3861 - accuracy: 0.8294\u001b[32m [repeated 28x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=9064)\u001b[0m 344/381 [==========================>...] - ETA: 0s - loss: 0.3991 - accuracy: 0.8218\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=33188)\u001b[0m Client  4 Evaluating...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=33188)\u001b[0m Client  4 Evaluating...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=1336)\u001b[0m 163/381 [===========>..................] - ETA: 0s - loss: 0.3945 - accuracy: 0.8274\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=9064)\u001b[0m Client  4 Evaluating...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m 302/381 [======================>.......] - ETA: 0s - loss: 0.3775 - accuracy: 0.8354\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=1336)\u001b[0m Client  4 Training complete...\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=9064)\u001b[0m Client ID: 8\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=9064)\u001b[0m Client  8 Evaluating...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=33188)\u001b[0m  51/381 [===>..........................] - ETA: 0s - loss: 0.4073 - accuracy: 0.8272  \n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=9064)\u001b[0m  50/381 [==>...........................] - ETA: 0s - loss: 0.3757 - accuracy: 0.8441  \n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=1336)\u001b[0m 259/381 [===================>..........] - ETA: 0s - loss: 0.3904 - accuracy: 0.8365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-07-08 18:09:35,621 | server.py:182 | evaluate_round 3 received 5 results and 0 failures\n",
      "DEBUG flwr 2023-07-08 18:09:35,622 | server.py:218 | fit_round 4: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=33188)\u001b[0m 368/381 [===========================>..] - ETA: 0s - loss: 0.3903 - accuracy: 0.8332\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=9064)\u001b[0m \u001b[33mClient 8 evaluation complete - Accuracy: 0.834476, Loss: 0.396305\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m Client  4 Training...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=9064)\u001b[0m  77/381 [=====>........................] - ETA: 0s - loss: 0.4106 - accuracy: 0.8328\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=3456)\u001b[0m 122/381 [========>.....................] - ETA: 0s - loss: 0.3978 - accuracy: 0.8308\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=9064)\u001b[0m 221/381 [================>.............] - ETA: 0s - loss: 0.4073 - accuracy: 0.8290\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14900)\u001b[0m 381/381 [==============================] - ETA: 0s - loss: 0.3834 - accuracy: 0.8387\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=9064)\u001b[0m 334/381 [=========================>....] - ETA: 0s - loss: 0.3768 - accuracy: 0.8416\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 170/381 [============>.................] - ETA: 0s - loss: 0.3741 - accuracy: 0.8469\u001b[32m [repeated 34x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=33188)\u001b[0m 379/381 [============================>.] - ETA: 0s - loss: 0.3653 - accuracy: 0.8473\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 270/381 [====================>.........] - ETA: 0s - loss: 0.3730 - accuracy: 0.8459\u001b[32m [repeated 28x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14900)\u001b[0m 212/381 [===============>..............] - ETA: 0s - loss: 0.3703 - accuracy: 0.8451\u001b[32m [repeated 23x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m  75/381 [====>.........................] - ETA: 0s - loss: 0.3712 - accuracy: 0.8454\u001b[32m [repeated 50x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=33188)\u001b[0m Epoch 7/10\u001b[32m [repeated 61x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=9228)\u001b[0m \u001b[32m [repeated 772x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=33188)\u001b[0m   1/381 [..............................] - ETA: 0s - loss: 0.4419 - accuracy: 0.7812\u001b[32m [repeated 66x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m  94/381 [======>.......................] - ETA: 0s - loss: 0.3711 - accuracy: 0.8384\u001b[32m [repeated 33x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=33188)\u001b[0m  35/381 [=>............................] - ETA: 0s - loss: 0.3483 - accuracy: 0.8536\u001b[32m [repeated 57x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 202/381 [==============>...............] - ETA: 0s - loss: 0.3745 - accuracy: 0.8460\u001b[32m [repeated 30x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=33188)\u001b[0m 381/381 [==============================] - 1s 2ms/step - loss: 0.3653 - accuracy: 0.8473\u001b[32m [repeated 56x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m 287/381 [=====================>........] - ETA: 0s - loss: 0.3772 - accuracy: 0.8414\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m 320/381 [========================>.....] - ETA: 0s - loss: 0.3768 - accuracy: 0.8419\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14900)\u001b[0m 180/381 [=============>................] - ETA: 0s - loss: 0.3720 - accuracy: 0.8440\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 107/381 [=======>......................] - ETA: 0s - loss: 0.3692 - accuracy: 0.8505\u001b[32m [repeated 31x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 138/381 [=========>....................] - ETA: 0s - loss: 0.3694 - accuracy: 0.8488\u001b[32m [repeated 44x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14900)\u001b[0m 148/381 [==========>...................] - ETA: 0s - loss: 0.3683 - accuracy: 0.8455\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 236/381 [=================>............] - ETA: 0s - loss: 0.3754 - accuracy: 0.8446\u001b[32m [repeated 30x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14900)\u001b[0m 246/381 [==================>...........] - ETA: 0s - loss: 0.3721 - accuracy: 0.8434\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14900)\u001b[0m 315/381 [=======================>......] - ETA: 0s - loss: 0.3738 - accuracy: 0.8426\u001b[32m [repeated 29x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=9228)\u001b[0m 353/381 [==========================>...] - ETA: 0s - loss: 0.3668 - accuracy: 0.8450\u001b[32m [repeated 25x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m 156/381 [===========>..................] - ETA: 0s - loss: 0.3765 - accuracy: 0.8384\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=37660)\u001b[0m 300/381 [======================>.......] - ETA: 0s - loss: 0.3804 - accuracy: 0.8375\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m Client ID: 6\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=11364)\u001b[0m Client  6 Evaluating...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14900)\u001b[0m  57/381 [===>..........................] - ETA: 0s - loss: 0.3683 - accuracy: 0.8421\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m  47/381 [==>...........................] - ETA: 0s - loss: 0.3694 - accuracy: 0.8454\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=37660)\u001b[0m 266/381 [===================>..........] - ETA: 0s - loss: 0.3813 - accuracy: 0.8375\u001b[32m [repeated 25x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=33188)\u001b[0m 363/381 [===========================>..] - ETA: 0s - loss: 0.3610 - accuracy: 0.8511\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=33188)\u001b[0m \u001b[33mClient 4 evaluation complete - Accuracy: 0.833573, Loss: 0.389702\u001b[0m\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m Client  6 Training...\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14900)\u001b[0m  88/381 [=====>........................] - ETA: 0s - loss: 0.3698 - accuracy: 0.8478\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 126/381 [========>.....................] - ETA: 0s - loss: 0.3643 - accuracy: 0.8441\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 219/381 [================>.............] - ETA: 0s - loss: 0.3573 - accuracy: 0.8466\u001b[32m [repeated 43x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=33188)\u001b[0m Client  3 Training complete...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-07-08 18:09:42,620 | server.py:232 | fit_round 4 received 10 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server Evaluating... Evaluation Count:4\n",
      "7336/7336 [==============================] - 6s 779us/step - loss: 0.3826 - accuracy: 0.8481\n",
      "7336/7336 [==============================] - 5s 657us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2023-07-08 18:09:54,996 | server.py:119 | fit progress: (4, 0.38259148597717285, {'accuracy': 0.8480777144432068}, 86.01100020000013)\n",
      "DEBUG flwr 2023-07-08 18:09:54,997 | server.py:168 | evaluate_round 4: strategy sampled 5 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  [[6.89923212e-08 5.67550998e-12 6.67375798e-06 ... 7.83922541e-18\n",
      "  1.08413190e-13 2.72977187e-14]\n",
      " [2.54599826e-07 2.73846668e-10 3.05546699e-08 ... 4.51241872e-18\n",
      "  3.52627405e-14 1.27423218e-13]\n",
      " [1.87986298e-05 2.55172490e-05 2.66925435e-05 ... 4.93781827e-13\n",
      "  1.06648745e-10 6.22223206e-09]\n",
      " ...\n",
      " [5.45118368e-08 1.66100276e-11 1.22982656e-05 ... 2.27953060e-17\n",
      "  1.80564263e-13 5.40985984e-14]\n",
      " [1.17447854e-07 4.86978422e-08 2.75728311e-08 ... 6.21431611e-17\n",
      "  5.19643431e-14 3.78551411e-13]\n",
      " [2.92065838e-09 9.65246454e-16 9.99990463e-01 ... 1.06198569e-23\n",
      "  2.22991556e-19 1.04086773e-18]] (234745, 34)\n",
      "\u001b[33mServer evaluation complete - Accuracy: 0.8481, Loss: 0.3826\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=9064)\u001b[0m 381/381 [==============================] - ETA: 0s - loss: 0.3730 - accuracy: 0.8429\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 331/381 [=========================>....] - ETA: 0s - loss: 0.3570 - accuracy: 0.8491\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=1336)\u001b[0m 169/381 [============>.................] - ETA: 0s - loss: 0.3573 - accuracy: 0.8518\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 371/381 [============================>.] - ETA: 0s - loss: 0.3596 - accuracy: 0.8477\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 278/381 [====================>.........] - ETA: 0s - loss: 0.3556 - accuracy: 0.8476\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=37660)\u001b[0m 215/381 [===============>..............] - ETA: 0s - loss: 0.3671 - accuracy: 0.8451\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m  64/381 [====>.........................] - ETA: 0s - loss: 0.3504 - accuracy: 0.8523\u001b[32m [repeated 26x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m Epoch 10/10\u001b[32m [repeated 39x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m \u001b[32m [repeated 549x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m   1/381 [..............................] - ETA: 0s - loss: 0.3868 - accuracy: 0.8438\u001b[32m [repeated 39x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m  97/381 [======>.......................] - ETA: 0s - loss: 0.3585 - accuracy: 0.8486\u001b[32m [repeated 33x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m  32/381 [=>............................] - ETA: 0s - loss: 0.3481 - accuracy: 0.8545\u001b[32m [repeated 39x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14900)\u001b[0m 196/381 [==============>...............] - ETA: 0s - loss: 0.3520 - accuracy: 0.8565\u001b[32m [repeated 23x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 381/381 [==============================] - 1s 1ms/step - loss: 0.3561 - accuracy: 0.8495\u001b[32m [repeated 49x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 290/381 [=====================>........] - ETA: 0s - loss: 0.3573 - accuracy: 0.8486\u001b[32m [repeated 28x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14900)\u001b[0m 327/381 [========================>.....] - ETA: 0s - loss: 0.3563 - accuracy: 0.8540\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 189/381 [=============>................] - ETA: 0s - loss: 0.3560 - accuracy: 0.8496\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=1336)\u001b[0m 104/381 [=======>......................] - ETA: 0s - loss: 0.3581 - accuracy: 0.8550\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 129/381 [=========>....................] - ETA: 0s - loss: 0.3590 - accuracy: 0.8476\u001b[32m [repeated 25x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14900)\u001b[0m 148/381 [==========>...................] - ETA: 0s - loss: 0.3722 - accuracy: 0.8470\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=3456)\u001b[0m 230/381 [=================>............] - ETA: 0s - loss: 0.3461 - accuracy: 0.8560\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 249/381 [==================>...........] - ETA: 0s - loss: 0.3580 - accuracy: 0.8458\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 308/381 [=======================>......] - ETA: 0s - loss: 0.3605 - accuracy: 0.8462\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m 354/381 [==========================>...] - ETA: 0s - loss: 0.3661 - accuracy: 0.8457\u001b[32m [repeated 25x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 159/381 [===========>..................] - ETA: 0s - loss: 0.3610 - accuracy: 0.8482\u001b[32m [repeated 29x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14900)\u001b[0m 293/381 [======================>.......] - ETA: 0s - loss: 0.3559 - accuracy: 0.8545\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=11452)\u001b[0m Client  0 Evaluating...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=11452)\u001b[0m Client  0 Evaluating...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=33188)\u001b[0m  63/381 [===>..........................] - ETA: 0s - loss: 0.3582 - accuracy: 0.8492\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 255/381 [===================>..........] - ETA: 0s - loss: 0.3572 - accuracy: 0.8483\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14900)\u001b[0m 364/381 [===========================>..] - ETA: 0s - loss: 0.3561 - accuracy: 0.8547\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=33188)\u001b[0m Client  0 Evaluating...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 222/381 [================>.............] - ETA: 0s - loss: 0.3545 - accuracy: 0.8492\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m Client  4 Training complete...\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=14900)\u001b[0m Client ID: 6\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=14900)\u001b[0m Client  6 Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-07-08 18:09:55,721 | server.py:182 | evaluate_round 4 received 5 results and 0 failures\n",
      "DEBUG flwr 2023-07-08 18:09:55,722 | server.py:218 | fit_round 5: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=11452)\u001b[0m \u001b[33mClient 0 evaluation complete - Accuracy: 0.856228, Loss: 0.358382\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=9064)\u001b[0m Client  9 Training...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=9064)\u001b[0m  43/381 [==>...........................] - ETA: 0s - loss: 0.3648 - accuracy: 0.8477  \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=9064)\u001b[0m  80/381 [=====>........................] - ETA: 0s - loss: 0.3562 - accuracy: 0.8486\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=33188)\u001b[0m 381/381 [==============================] - ETA: 0s - loss: 0.3462 - accuracy: 0.8562\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m 341/381 [=========================>....] - ETA: 0s - loss: 0.3505 - accuracy: 0.8509\u001b[32m [repeated 31x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14900)\u001b[0m 175/381 [============>.................] - ETA: 0s - loss: 0.3311 - accuracy: 0.8616\u001b[32m [repeated 53x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m 375/381 [============================>.] - ETA: 0s - loss: 0.3513 - accuracy: 0.8512\u001b[32m [repeated 38x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m 271/381 [====================>.........] - ETA: 0s - loss: 0.3522 - accuracy: 0.8512\u001b[32m [repeated 48x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=3456)\u001b[0m 205/381 [===============>..............] - ETA: 0s - loss: 0.3579 - accuracy: 0.8492\u001b[32m [repeated 40x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m  71/381 [====>.........................] - ETA: 0s - loss: 0.3334 - accuracy: 0.8576\u001b[32m [repeated 69x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m Epoch 7/10\u001b[32m [repeated 70x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=3456)\u001b[0m \u001b[32m [repeated 805x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m   1/381 [..............................] - ETA: 0s - loss: 0.4291 - accuracy: 0.8125\u001b[32m [repeated 75x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=37660)\u001b[0m 101/381 [======>.......................] - ETA: 0s - loss: 0.3514 - accuracy: 0.8547\u001b[32m [repeated 26x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m  35/381 [=>............................] - ETA: 0s - loss: 0.3610 - accuracy: 0.8647\u001b[32m [repeated 68x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m 203/381 [==============>...............] - ETA: 0s - loss: 0.3512 - accuracy: 0.8505\u001b[32m [repeated 25x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m 381/381 [==============================] - 1s 1ms/step - loss: 0.3486 - accuracy: 0.8532\u001b[32m [repeated 65x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14900)\u001b[0m 281/381 [=====================>........] - ETA: 0s - loss: 0.3483 - accuracy: 0.8555\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m 325/381 [========================>.....] - ETA: 0s - loss: 0.3686 - accuracy: 0.8477\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=3456)\u001b[0m 103/381 [=======>......................] - ETA: 0s - loss: 0.3493 - accuracy: 0.8506\u001b[32m [repeated 47x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=3456)\u001b[0m 136/381 [=========>....................] - ETA: 0s - loss: 0.3567 - accuracy: 0.8509\u001b[32m [repeated 54x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 140/381 [==========>...................] - ETA: 0s - loss: 0.3420 - accuracy: 0.8593\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m 233/381 [=================>............] - ETA: 0s - loss: 0.3515 - accuracy: 0.8507\u001b[32m [repeated 36x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14900)\u001b[0m 246/381 [==================>...........] - ETA: 0s - loss: 0.3473 - accuracy: 0.8561\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m 307/381 [=======================>......] - ETA: 0s - loss: 0.3522 - accuracy: 0.8505\u001b[32m [repeated 40x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14900)\u001b[0m 347/381 [==========================>...] - ETA: 0s - loss: 0.3487 - accuracy: 0.8535\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=33188)\u001b[0m 164/381 [===========>..................] - ETA: 0s - loss: 0.3345 - accuracy: 0.8635\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m 302/381 [======================>.......] - ETA: 0s - loss: 0.3468 - accuracy: 0.8523\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=37660)\u001b[0m  54/381 [===>..........................] - ETA: 0s - loss: 0.3629 - accuracy: 0.8513 \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=33188)\u001b[0m 266/381 [===================>..........] - ETA: 0s - loss: 0.3370 - accuracy: 0.8609\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m 367/381 [===========================>..] - ETA: 0s - loss: 0.3560 - accuracy: 0.8502\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m 225/381 [================>.............] - ETA: 0s - loss: 0.3687 - accuracy: 0.8460\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=33188)\u001b[0m Client ID: 2\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=37660)\u001b[0m Client  9 Evaluating...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=37660)\u001b[0m \u001b[33mClient 9 evaluation complete - Accuracy: 0.857372, Loss: 0.352621\u001b[0m\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=3456)\u001b[0m 190/381 [=============>................] - ETA: 0s - loss: 0.3526 - accuracy: 0.8530\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m Client  4 Training...\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=1336)\u001b[0m   1/381 [..............................] - ETA: 0s - loss: 0.4107 - accuracy: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-07-08 18:10:02,324 | server.py:232 | fit_round 5 received 10 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=14900)\u001b[0m Client  0 Training complete...\n",
      "Server Evaluating... Evaluation Count:5\n",
      "7336/7336 [==============================] - 6s 782us/step - loss: 0.3588 - accuracy: 0.8534\n",
      "7336/7336 [==============================] - 5s 656us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2023-07-08 18:10:14,697 | server.py:119 | fit progress: (5, 0.35876625776290894, {'accuracy': 0.8534026145935059}, 105.71260569999959)\n",
      "DEBUG flwr 2023-07-08 18:10:14,698 | server.py:168 | evaluate_round 5: strategy sampled 5 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  [[8.7156657e-08 3.2115348e-12 5.0409753e-06 ... 2.1936220e-19\n",
      "  1.9639750e-14 9.9245950e-16]\n",
      " [1.2665745e-07 3.6249729e-11 6.1155641e-09 ... 1.2624106e-20\n",
      "  1.9155737e-16 4.2900702e-16]\n",
      " [5.9954023e-06 5.7738798e-05 9.9302515e-06 ... 6.7607002e-15\n",
      "  2.4608622e-12 2.3583802e-10]\n",
      " ...\n",
      " [4.4865740e-08 1.0390947e-11 9.8997216e-06 ... 7.5750424e-19\n",
      "  2.8380864e-14 2.0769180e-15]\n",
      " [9.4747627e-08 4.3330996e-08 5.5127756e-09 ... 4.9768699e-18\n",
      "  2.3843090e-15 1.9070173e-14]\n",
      " [1.4171506e-09 2.2611653e-16 9.9999332e-01 ... 2.6630796e-27\n",
      "  2.9028658e-21 3.5695780e-21]] (234745, 34)\n",
      "\u001b[33mServer evaluation complete - Accuracy: 0.8534, Loss: 0.3588\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=33188)\u001b[0m 381/381 [==============================] - ETA: 0s - loss: 0.3320 - accuracy: 0.8611\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=37660)\u001b[0m 340/381 [=========================>....] - ETA: 0s - loss: 0.3277 - accuracy: 0.8618\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m 174/381 [============>.................] - ETA: 0s - loss: 0.3308 - accuracy: 0.8602\u001b[32m [repeated 26x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=37660)\u001b[0m 377/381 [============================>.] - ETA: 0s - loss: 0.3282 - accuracy: 0.8616\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m 271/381 [====================>.........] - ETA: 0s - loss: 0.3434 - accuracy: 0.8540\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m 204/381 [===============>..............] - ETA: 0s - loss: 0.3475 - accuracy: 0.8519\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m  68/381 [====>.........................] - ETA: 0s - loss: 0.3348 - accuracy: 0.8555\u001b[32m [repeated 28x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m Epoch 10/10\u001b[32m [repeated 30x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m \u001b[32m [repeated 459x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m   1/381 [..............................] - ETA: 0s - loss: 0.3636 - accuracy: 0.8281\u001b[32m [repeated 30x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=9064)\u001b[0m 101/381 [======>.......................] - ETA: 0s - loss: 0.3339 - accuracy: 0.8550\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m  35/381 [=>............................] - ETA: 0s - loss: 0.3391 - accuracy: 0.8585\u001b[32m [repeated 30x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=37660)\u001b[0m 203/381 [==============>...............] - ETA: 0s - loss: 0.3332 - accuracy: 0.8596\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m 381/381 [==============================] - 1s 1ms/step - loss: 0.3418 - accuracy: 0.8542\u001b[32m [repeated 40x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=9228)\u001b[0m 281/381 [=====================>........] - ETA: 0s - loss: 0.3446 - accuracy: 0.8559\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m 328/381 [========================>.....] - ETA: 0s - loss: 0.3407 - accuracy: 0.8578\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m 102/381 [=======>......................] - ETA: 0s - loss: 0.3454 - accuracy: 0.8528\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m 135/381 [=========>....................] - ETA: 0s - loss: 0.3451 - accuracy: 0.8532\u001b[32m [repeated 27x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=9228)\u001b[0m 141/381 [==========>...................] - ETA: 0s - loss: 0.3436 - accuracy: 0.8534\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m 238/381 [=================>............] - ETA: 0s - loss: 0.3458 - accuracy: 0.8533\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m 242/381 [==================>...........] - ETA: 0s - loss: 0.3403 - accuracy: 0.8592\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m 312/381 [=======================>......] - ETA: 0s - loss: 0.3373 - accuracy: 0.8591\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m 346/381 [==========================>...] - ETA: 0s - loss: 0.3432 - accuracy: 0.8529\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m 160/381 [===========>..................] - ETA: 0s - loss: 0.3444 - accuracy: 0.8529\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=9064)\u001b[0m 300/381 [======================>.......] - ETA: 0s - loss: 0.3252 - accuracy: 0.8621\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=3456)\u001b[0m  63/381 [===>..........................] - ETA: 0s - loss: 0.3557 - accuracy: 0.8571\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m 258/381 [===================>..........] - ETA: 0s - loss: 0.3393 - accuracy: 0.8597\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m 361/381 [===========================>..] - ETA: 0s - loss: 0.3468 - accuracy: 0.8533\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m 224/381 [================>.............] - ETA: 0s - loss: 0.3488 - accuracy: 0.8526\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=35448)\u001b[0m Client ID: 4\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=9228)\u001b[0m Client ID: 4\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m Client  8 Training complete...\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=11364)\u001b[0m Client ID: 7\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=35448)\u001b[0m Client  4 Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-07-08 18:10:15,432 | server.py:182 | evaluate_round 5 received 5 results and 0 failures\n",
      "DEBUG flwr 2023-07-08 18:10:15,432 | server.py:218 | fit_round 6: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=3456)\u001b[0m \u001b[33mClient 6 evaluation complete - Accuracy: 0.851221, Loss: 0.350390\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=3456)\u001b[0m Client  3 Training...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=9064)\u001b[0m  42/381 [==>...........................] - ETA: 0s - loss: 0.3347 - accuracy: 0.8631  \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=9064)\u001b[0m  77/381 [=====>........................] - ETA: 0s - loss: 0.3311 - accuracy: 0.8657\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14900)\u001b[0m 381/381 [==============================] - ETA: 0s - loss: 0.3330 - accuracy: 0.8617\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 339/381 [=========================>....] - ETA: 0s - loss: 0.3212 - accuracy: 0.8664\u001b[32m [repeated 28x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 172/381 [============>.................] - ETA: 0s - loss: 0.3180 - accuracy: 0.8703\u001b[32m [repeated 54x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m 371/381 [============================>.] - ETA: 0s - loss: 0.3318 - accuracy: 0.8599\u001b[32m [repeated 43x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 275/381 [====================>.........] - ETA: 0s - loss: 0.3231 - accuracy: 0.8670\u001b[32m [repeated 50x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m 206/381 [===============>..............] - ETA: 0s - loss: 0.3284 - accuracy: 0.8596\u001b[32m [repeated 40x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m  65/381 [====>.........................] - ETA: 0s - loss: 0.3357 - accuracy: 0.8534\u001b[32m [repeated 64x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m Epoch 7/10\u001b[32m [repeated 70x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m \u001b[32m [repeated 797x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m   1/381 [..............................] - ETA: 0s - loss: 0.2528 - accuracy: 0.9062\u001b[32m [repeated 75x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=9064)\u001b[0m  98/381 [======>.......................] - ETA: 0s - loss: 0.3111 - accuracy: 0.8688\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m  32/381 [=>............................] - ETA: 0s - loss: 0.3157 - accuracy: 0.8755\u001b[32m [repeated 69x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=9228)\u001b[0m 201/381 [==============>...............] - ETA: 0s - loss: 0.3341 - accuracy: 0.8599\u001b[32m [repeated 25x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m 381/381 [==============================] - 1s 2ms/step - loss: 0.3322 - accuracy: 0.8599\u001b[32m [repeated 65x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m 280/381 [=====================>........] - ETA: 0s - loss: 0.3365 - accuracy: 0.8570\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=33188)\u001b[0m 318/381 [========================>.....] - ETA: 0s - loss: 0.3494 - accuracy: 0.8543\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 103/381 [=======>......................] - ETA: 0s - loss: 0.3144 - accuracy: 0.8721\u001b[32m [repeated 45x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m 136/381 [=========>....................] - ETA: 0s - loss: 0.3306 - accuracy: 0.8580\u001b[32m [repeated 52x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 140/381 [==========>...................] - ETA: 0s - loss: 0.3268 - accuracy: 0.8596\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m 239/381 [=================>............] - ETA: 0s - loss: 0.3316 - accuracy: 0.8589\u001b[32m [repeated 41x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 242/381 [==================>...........] - ETA: 0s - loss: 0.3238 - accuracy: 0.8680\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 308/381 [=======================>......] - ETA: 0s - loss: 0.3219 - accuracy: 0.8663\u001b[32m [repeated 48x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=37660)\u001b[0m 343/381 [==========================>...] - ETA: 0s - loss: 0.3286 - accuracy: 0.8622\u001b[32m [repeated 31x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=37660)\u001b[0m 164/381 [===========>..................] - ETA: 0s - loss: 0.3354 - accuracy: 0.8619\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14900)\u001b[0m 304/381 [======================>.......] - ETA: 0s - loss: 0.3254 - accuracy: 0.8627\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m  62/381 [===>..........................] - ETA: 0s - loss: 0.3410 - accuracy: 0.8667\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m 266/381 [===================>..........] - ETA: 0s - loss: 0.3387 - accuracy: 0.8597\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m 365/381 [===========================>..] - ETA: 0s - loss: 0.3367 - accuracy: 0.8588\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m  32/381 [=>............................] - ETA: 0s - loss: 0.3157 - accuracy: 0.8755\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m Client ID: 8\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=37660)\u001b[0m Client  1 Evaluating...\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=33188)\u001b[0m 178/381 [=============>................] - ETA: 0s - loss: 0.3346 - accuracy: 0.8600\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=11364)\u001b[0m \u001b[33mClient 7 evaluation complete - Accuracy: 0.855161, Loss: 0.342978\u001b[0m\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14900)\u001b[0m Client  5 Training...\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=3456)\u001b[0m 223/381 [================>.............] - ETA: 0s - loss: 0.3114 - accuracy: 0.8682\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=33188)\u001b[0m Client  6 Training complete...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-07-08 18:10:22,017 | server.py:232 | fit_round 6 received 10 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server Evaluating... Evaluation Count:6\n",
      "7336/7336 [==============================] - 6s 768us/step - loss: 0.3428 - accuracy: 0.8658\n",
      "7336/7336 [==============================] - 5s 661us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2023-07-08 18:10:34,343 | server.py:119 | fit progress: (6, 0.3427808880805969, {'accuracy': 0.8658459186553955}, 125.3574351999996)\n",
      "DEBUG flwr 2023-07-08 18:10:34,344 | server.py:168 | evaluate_round 6: strategy sampled 5 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  [[6.54590337e-08 8.45046418e-13 2.51123697e-06 ... 1.69690468e-21\n",
      "  6.74510494e-16 1.57926845e-17]\n",
      " [8.03138391e-08 5.03835949e-12 1.40075951e-09 ... 1.67433746e-22\n",
      "  4.66911899e-18 4.13744658e-18]\n",
      " [1.91366689e-06 9.64383580e-05 2.23889128e-06 ... 3.87787089e-16\n",
      "  1.08800433e-13 1.49244922e-11]\n",
      " ...\n",
      " [1.92003231e-08 2.53316638e-12 3.94082645e-06 ... 4.51021562e-21\n",
      "  6.19655476e-16 2.48351483e-17]\n",
      " [7.10634751e-08 2.78911880e-08 1.05342679e-09 ... 3.39441423e-19\n",
      "  1.13641130e-16 9.34672905e-16]\n",
      " [9.56647206e-10 1.47309564e-16 9.99995470e-01 ... 7.88596936e-31\n",
      "  1.56338395e-23 2.28465872e-23]] (234745, 34)\n",
      "\u001b[33mServer evaluation complete - Accuracy: 0.8658, Loss: 0.3428\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=33188)\u001b[0m 336/381 [=========================>....] - ETA: 0s - loss: 0.3236 - accuracy: 0.8595\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=37660)\u001b[0m 166/381 [============>.................] - ETA: 0s - loss: 0.3217 - accuracy: 0.8661\u001b[32m [repeated 31x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m 369/381 [============================>.] - ETA: 0s - loss: 0.3233 - accuracy: 0.8640\u001b[32m [repeated 25x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=33188)\u001b[0m 270/381 [====================>.........] - ETA: 0s - loss: 0.3224 - accuracy: 0.8601\u001b[32m [repeated 25x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=33188)\u001b[0m 205/381 [===============>..............] - ETA: 0s - loss: 0.3213 - accuracy: 0.8604\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m  67/381 [====>.........................] - ETA: 0s - loss: 0.3241 - accuracy: 0.8631\u001b[32m [repeated 34x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m Epoch 10/10\u001b[32m [repeated 30x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m \u001b[32m [repeated 440x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m   1/381 [..............................] - ETA: 0s - loss: 0.3745 - accuracy: 0.8594\u001b[32m [repeated 30x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m  98/381 [======>.......................] - ETA: 0s - loss: 0.3208 - accuracy: 0.8670\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m  35/381 [=>............................] - ETA: 0s - loss: 0.3219 - accuracy: 0.8585\u001b[32m [repeated 30x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m 194/381 [==============>...............] - ETA: 0s - loss: 0.3223 - accuracy: 0.8649\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m 381/381 [==============================] - 1s 1ms/step - loss: 0.3231 - accuracy: 0.8639\u001b[32m [repeated 40x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 288/381 [=====================>........] - ETA: 0s - loss: 0.3094 - accuracy: 0.8748\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m 325/381 [========================>.....] - ETA: 0s - loss: 0.3211 - accuracy: 0.8650\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=9064)\u001b[0m 103/381 [=======>......................] - ETA: 0s - loss: 0.3249 - accuracy: 0.8665\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m 130/381 [=========>....................] - ETA: 0s - loss: 0.3220 - accuracy: 0.8653\u001b[32m [repeated 32x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=33188)\u001b[0m 140/381 [==========>...................] - ETA: 0s - loss: 0.3197 - accuracy: 0.8586\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=37660)\u001b[0m 231/381 [=================>............] - ETA: 0s - loss: 0.3234 - accuracy: 0.8636\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=3456)\u001b[0m 253/381 [==================>...........] - ETA: 0s - loss: 0.3117 - accuracy: 0.8682\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m 306/381 [=======================>......] - ETA: 0s - loss: 0.3252 - accuracy: 0.8661\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=1336)\u001b[0m 352/381 [==========================>...] - ETA: 0s - loss: 0.3141 - accuracy: 0.8667\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m 162/381 [===========>..................] - ETA: 0s - loss: 0.3245 - accuracy: 0.8644\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=37660)\u001b[0m 295/381 [======================>.......] - ETA: 0s - loss: 0.3197 - accuracy: 0.8650\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m 257/381 [===================>..........] - ETA: 0s - loss: 0.3250 - accuracy: 0.8641\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=9228)\u001b[0m 357/381 [===========================>..] - ETA: 0s - loss: 0.3230 - accuracy: 0.8615\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=11452)\u001b[0m Client  7 Evaluating...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=11452)\u001b[0m Client  7 Evaluating...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 224/381 [================>.............] - ETA: 0s - loss: 0.3095 - accuracy: 0.8746\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m Client  1 Training complete...\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=14900)\u001b[0m Client ID: 6\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=14900)\u001b[0m Client  6 Evaluating...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=11452)\u001b[0m  56/381 [===>..........................] - ETA: 0s - loss: 0.3268 - accuracy: 0.8630 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-07-08 18:10:35,043 | server.py:182 | evaluate_round 6 received 5 results and 0 failures\n",
      "DEBUG flwr 2023-07-08 18:10:35,044 | server.py:218 | fit_round 7: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=11452)\u001b[0m \u001b[33mClient 7 evaluation complete - Accuracy: 0.863944, Loss: 0.326525\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14900)\u001b[0m Client  2 Training...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14900)\u001b[0m  40/381 [==>...........................] - ETA: 0s - loss: 0.3248 - accuracy: 0.8605  \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14900)\u001b[0m  78/381 [=====>........................] - ETA: 0s - loss: 0.3248 - accuracy: 0.8666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14900)\u001b[0m 118/381 [========>.....................] - ETA: 0s - loss: 0.3180 - accuracy: 0.8722\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=9228)\u001b[0m 189/381 [=============>................] - ETA: 0s - loss: 0.3480 - accuracy: 0.8683\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m 381/381 [==============================] - ETA: 0s - loss: 0.3357 - accuracy: 0.8635\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=37660)\u001b[0m 342/381 [=========================>....] - ETA: 0s - loss: 0.3091 - accuracy: 0.8747\u001b[32m [repeated 29x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14900)\u001b[0m 172/381 [============>.................] - ETA: 0s - loss: 0.2907 - accuracy: 0.8744\u001b[32m [repeated 53x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m 379/381 [============================>.] - ETA: 0s - loss: 0.3239 - accuracy: 0.8638\u001b[32m [repeated 28x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=37660)\u001b[0m 274/381 [====================>.........] - ETA: 0s - loss: 0.3053 - accuracy: 0.8750\u001b[32m [repeated 37x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=3456)\u001b[0m 204/381 [===============>..............] - ETA: 0s - loss: 0.3090 - accuracy: 0.8678\u001b[32m [repeated 32x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m  67/381 [====>.........................] - ETA: 0s - loss: 0.3192 - accuracy: 0.8587\u001b[32m [repeated 57x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m Epoch 7/10\u001b[32m [repeated 62x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=33188)\u001b[0m \u001b[32m [repeated 702x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m   1/381 [..............................] - ETA: 0s - loss: 0.1882 - accuracy: 0.9375\u001b[32m [repeated 67x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m  99/381 [======>.......................] - ETA: 0s - loss: 0.3126 - accuracy: 0.8630\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m  34/381 [=>............................] - ETA: 0s - loss: 0.3065 - accuracy: 0.8644\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=1336)\u001b[0m 202/381 [==============>...............] - ETA: 0s - loss: 0.3050 - accuracy: 0.8764\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m 381/381 [==============================] - 1s 1ms/step - loss: 0.3240 - accuracy: 0.8637\u001b[32m [repeated 57x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=9228)\u001b[0m 281/381 [=====================>........] - ETA: 0s - loss: 0.2998 - accuracy: 0.8768\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=37660)\u001b[0m 325/381 [========================>.....] - ETA: 0s - loss: 0.3131 - accuracy: 0.8708\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=9228)\u001b[0m 103/381 [=======>......................] - ETA: 0s - loss: 0.2944 - accuracy: 0.8789\u001b[32m [repeated 42x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m 131/381 [=========>....................] - ETA: 0s - loss: 0.3133 - accuracy: 0.8658\u001b[32m [repeated 42x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=37660)\u001b[0m 141/381 [==========>...................] - ETA: 0s - loss: 0.3012 - accuracy: 0.8751\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=33188)\u001b[0m 241/381 [=================>............] - ETA: 0s - loss: 0.3188 - accuracy: 0.8679\u001b[32m [repeated 29x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m 245/381 [==================>...........] - ETA: 0s - loss: 0.3296 - accuracy: 0.8617\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=37660)\u001b[0m 309/381 [=======================>......] - ETA: 0s - loss: 0.3049 - accuracy: 0.8748\u001b[32m [repeated 36x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m 346/381 [==========================>...] - ETA: 0s - loss: 0.3235 - accuracy: 0.8639\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=37660)\u001b[0m 157/381 [===========>..................] - ETA: 0s - loss: 0.3131 - accuracy: 0.8696\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=9228)\u001b[0m 301/381 [======================>.......] - ETA: 0s - loss: 0.3146 - accuracy: 0.8706\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=37660)\u001b[0m 259/381 [===================>..........] - ETA: 0s - loss: 0.3137 - accuracy: 0.8694\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=37660)\u001b[0m 359/381 [===========================>..] - ETA: 0s - loss: 0.3114 - accuracy: 0.8715\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=37660)\u001b[0m 226/381 [================>.............] - ETA: 0s - loss: 0.3168 - accuracy: 0.8675\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=37660)\u001b[0m Client ID: 9\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=11364)\u001b[0m Client  0 Evaluating...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=37660)\u001b[0m  63/381 [===>..........................] - ETA: 0s - loss: 0.3354 - accuracy: 0.8638\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=11364)\u001b[0m \u001b[33mClient 0 evaluation complete - Accuracy: 0.868705, Loss: 0.316178\u001b[0m\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m Client  8 Training...\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=9228)\u001b[0m  67/381 [====>.........................] - ETA: 0s - loss: 0.3003 - accuracy: 0.8881\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m  88/381 [=====>........................] - ETA: 0s - loss: 0.3295 - accuracy: 0.8601\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=37660)\u001b[0m 124/381 [========>.....................] - ETA: 0s - loss: 0.3207 - accuracy: 0.8661\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=1336)\u001b[0m 178/381 [=============>................] - ETA: 0s - loss: 0.3029 - accuracy: 0.8712\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14900)\u001b[0m Client  2 Training complete...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=37660)\u001b[0m  41/381 [==>...........................] - ETA: 0s - loss: 0.2790 - accuracy: 0.8773\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 381/381 [==============================] - ETA: 0s - loss: 0.3060 - accuracy: 0.8738\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-07-08 18:10:42,144 | server.py:232 | fit_round 7 received 10 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server Evaluating... Evaluation Count:7\n",
      "7336/7336 [==============================] - 6s 766us/step - loss: 0.3231 - accuracy: 0.8713\n",
      "7336/7336 [==============================] - 5s 684us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2023-07-08 18:10:54,627 | server.py:119 | fit progress: (7, 0.32311421632766724, {'accuracy': 0.8713455200195312}, 145.64284270000007)\n",
      "DEBUG flwr 2023-07-08 18:10:54,629 | server.py:168 | evaluate_round 7: strategy sampled 5 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  [[4.64853116e-08 1.80461847e-13 1.17594163e-06 ... 1.18869734e-23\n",
      "  2.34055817e-17 4.20881205e-19]\n",
      " [6.79567691e-08 7.11806915e-13 3.31757816e-10 ... 4.74370106e-24\n",
      "  4.18291200e-19 1.14876052e-19]\n",
      " [5.32974695e-07 9.67128799e-05 7.38539427e-07 ... 3.71051021e-17\n",
      "  4.20823798e-15 6.55738105e-13]\n",
      " ...\n",
      " [1.11401812e-08 6.15781514e-13 1.77223296e-06 ... 2.71397781e-23\n",
      "  1.64254644e-17 5.53237677e-19]\n",
      " [5.08222193e-08 1.11845360e-08 2.51883736e-10 ... 6.38047704e-21\n",
      "  3.73602907e-18 3.40240860e-17]\n",
      " [8.67406647e-10 7.71455241e-17 9.99995828e-01 ... 4.66769843e-34\n",
      "  1.39352834e-25 2.74330965e-25]] (234745, 34)\n",
      "\u001b[33mServer evaluation complete - Accuracy: 0.8713, Loss: 0.3231\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=37660)\u001b[0m 336/381 [=========================>....] - ETA: 0s - loss: 0.2892 - accuracy: 0.8813\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=37660)\u001b[0m 167/381 [============>.................] - ETA: 0s - loss: 0.2843 - accuracy: 0.8804\u001b[32m [repeated 29x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=37660)\u001b[0m 372/381 [============================>.] - ETA: 0s - loss: 0.2944 - accuracy: 0.8781\u001b[32m [repeated 26x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=37660)\u001b[0m 279/381 [====================>.........] - ETA: 0s - loss: 0.2883 - accuracy: 0.8807\u001b[32m [repeated 35x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=37660)\u001b[0m 215/381 [===============>..............] - ETA: 0s - loss: 0.2939 - accuracy: 0.8790\u001b[32m [repeated 23x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=9064)\u001b[0m  75/381 [====>.........................] - ETA: 0s - loss: 0.3032 - accuracy: 0.8806\u001b[32m [repeated 36x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=37660)\u001b[0m Epoch 10/10\u001b[32m [repeated 38x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=37660)\u001b[0m \u001b[32m [repeated 518x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=37660)\u001b[0m   1/381 [..............................] - ETA: 0s - loss: 0.1952 - accuracy: 0.9688\u001b[32m [repeated 38x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=9228)\u001b[0m 101/381 [======>.......................] - ETA: 0s - loss: 0.2964 - accuracy: 0.8855\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=9064)\u001b[0m  37/381 [=>............................] - ETA: 0s - loss: 0.3229 - accuracy: 0.8775\u001b[32m [repeated 37x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=9064)\u001b[0m 192/381 [==============>...............] - ETA: 0s - loss: 0.2981 - accuracy: 0.8794\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=37660)\u001b[0m 381/381 [==============================] - 0s 1ms/step - loss: 0.2879 - accuracy: 0.8813\u001b[32m [repeated 48x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=1336)\u001b[0m 282/381 [=====================>........] - ETA: 0s - loss: 0.2972 - accuracy: 0.8753\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=3456)\u001b[0m 328/381 [========================>.....] - ETA: 0s - loss: 0.3134 - accuracy: 0.8691\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=1336)\u001b[0m 113/381 [=======>......................] - ETA: 0s - loss: 0.2824 - accuracy: 0.8830\u001b[32m [repeated 28x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m 138/381 [=========>....................] - ETA: 0s - loss: 0.3099 - accuracy: 0.8722\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m 147/381 [==========>...................] - ETA: 0s - loss: 0.3056 - accuracy: 0.8754\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=9064)\u001b[0m 233/381 [=================>............] - ETA: 0s - loss: 0.3009 - accuracy: 0.8790\u001b[32m [repeated 30x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=37660)\u001b[0m 253/381 [==================>...........] - ETA: 0s - loss: 0.2978 - accuracy: 0.8791\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=9064)\u001b[0m 315/381 [=======================>......] - ETA: 0s - loss: 0.3008 - accuracy: 0.8772\u001b[32m [repeated 32x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=3456)\u001b[0m 352/381 [==========================>...] - ETA: 0s - loss: 0.3018 - accuracy: 0.8727\u001b[32m [repeated 23x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=9064)\u001b[0m 153/381 [===========>..................] - ETA: 0s - loss: 0.2941 - accuracy: 0.8800\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=37660)\u001b[0m 293/381 [======================>.......] - ETA: 0s - loss: 0.2940 - accuracy: 0.8791\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m 266/381 [===================>..........] - ETA: 0s - loss: 0.3052 - accuracy: 0.8728\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=9064)\u001b[0m 360/381 [===========================>..] - ETA: 0s - loss: 0.2990 - accuracy: 0.8773\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=37660)\u001b[0m 220/381 [================>.............] - ETA: 0s - loss: 0.2910 - accuracy: 0.8798\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=3456)\u001b[0m Client ID: 9\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=37660)\u001b[0m  80/381 [=====>........................] - ETA: 0s - loss: 0.2798 - accuracy: 0.8785\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=37660)\u001b[0m 119/381 [========>.....................] - ETA: 0s - loss: 0.2767 - accuracy: 0.8813\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=1336)\u001b[0m 190/381 [=============>................] - ETA: 0s - loss: 0.2810 - accuracy: 0.8832\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=37660)\u001b[0m Client  9 Training complete...\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=9064)\u001b[0m Client ID: 6\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=37660)\u001b[0m Client  5 Evaluating...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=37660)\u001b[0m  58/381 [===>..........................] - ETA: 0s - loss: 0.3171 - accuracy: 0.8809  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-07-08 18:10:55,341 | server.py:182 | evaluate_round 7 received 5 results and 0 failures\n",
      "DEBUG flwr 2023-07-08 18:10:55,341 | server.py:218 | fit_round 8: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=11452)\u001b[0m \u001b[33mClient 0 evaluation complete - Accuracy: 0.885902, Loss: 0.293816\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=3456)\u001b[0m Client  8 Training...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14900)\u001b[0m 381/381 [==============================] - ETA: 0s - loss: 0.3001 - accuracy: 0.8784\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=9228)\u001b[0m 341/381 [=========================>....] - ETA: 0s - loss: 0.2829 - accuracy: 0.8874\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14900)\u001b[0m 175/381 [============>.................] - ETA: 0s - loss: 0.2928 - accuracy: 0.8811\u001b[32m [repeated 44x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=3456)\u001b[0m 369/381 [============================>.] - ETA: 0s - loss: 0.3029 - accuracy: 0.8808\u001b[32m [repeated 26x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14900)\u001b[0m 277/381 [====================>.........] - ETA: 0s - loss: 0.2936 - accuracy: 0.8824\u001b[32m [repeated 44x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14900)\u001b[0m 209/381 [===============>..............] - ETA: 0s - loss: 0.2984 - accuracy: 0.8837\u001b[32m [repeated 35x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=3456)\u001b[0m  68/381 [====>.........................] - ETA: 0s - loss: 0.2834 - accuracy: 0.8764\u001b[32m [repeated 56x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=3456)\u001b[0m Epoch 6/10\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=1336)\u001b[0m \u001b[32m [repeated 696x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=3456)\u001b[0m   1/381 [..............................] - ETA: 0s - loss: 0.4718 - accuracy: 0.7344\u001b[32m [repeated 65x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=37660)\u001b[0m 101/381 [======>.......................] - ETA: 0s - loss: 0.2932 - accuracy: 0.8847\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=3456)\u001b[0m  35/381 [=>............................] - ETA: 0s - loss: 0.3016 - accuracy: 0.8656\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=37660)\u001b[0m 203/381 [==============>...............] - ETA: 0s - loss: 0.2943 - accuracy: 0.8799\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=3456)\u001b[0m 381/381 [==============================] - 1s 2ms/step - loss: 0.3032 - accuracy: 0.8804\u001b[32m [repeated 55x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=33188)\u001b[0m 282/381 [=====================>........] - ETA: 0s - loss: 0.2933 - accuracy: 0.8834\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m 326/381 [========================>.....] - ETA: 0s - loss: 0.3001 - accuracy: 0.8780\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=9064)\u001b[0m 105/381 [=======>......................] - ETA: 0s - loss: 0.2812 - accuracy: 0.8818\u001b[32m [repeated 42x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=9064)\u001b[0m 139/381 [=========>....................] - ETA: 0s - loss: 0.2838 - accuracy: 0.8817\u001b[32m [repeated 45x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=1336)\u001b[0m 140/381 [==========>...................] - ETA: 0s - loss: 0.2880 - accuracy: 0.8835\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=37660)\u001b[0m 235/381 [=================>............] - ETA: 0s - loss: 0.2948 - accuracy: 0.8793\u001b[32m [repeated 30x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14900)\u001b[0m 243/381 [==================>...........] - ETA: 0s - loss: 0.2953 - accuracy: 0.8837\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=1336)\u001b[0m 311/381 [=======================>......] - ETA: 0s - loss: 0.2902 - accuracy: 0.8832\u001b[32m [repeated 35x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=1336)\u001b[0m 344/381 [==========================>...] - ETA: 0s - loss: 0.2894 - accuracy: 0.8835\u001b[32m [repeated 29x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=3456)\u001b[0m 165/381 [===========>..................] - ETA: 0s - loss: 0.2887 - accuracy: 0.8783\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=3456)\u001b[0m 303/381 [======================>.......] - ETA: 0s - loss: 0.3032 - accuracy: 0.8811\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m 266/381 [===================>..........] - ETA: 0s - loss: 0.3166 - accuracy: 0.8731\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=3456)\u001b[0m 367/381 [===========================>..] - ETA: 0s - loss: 0.3046 - accuracy: 0.8793\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m 223/381 [================>.............] - ETA: 0s - loss: 0.3041 - accuracy: 0.8798\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m 125/381 [========>.....................] - ETA: 0s - loss: 0.2941 - accuracy: 0.8817\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=33188)\u001b[0m 178/381 [=============>................] - ETA: 0s - loss: 0.2909 - accuracy: 0.8844\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m Client ID: 6\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=1336)\u001b[0m Client  7 Evaluating...\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14900)\u001b[0m  63/381 [===>..........................] - ETA: 0s - loss: 0.3007 - accuracy: 0.8817\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=3456)\u001b[0m \u001b[33mClient 9 evaluation complete - Accuracy: 0.887662, Loss: 0.292378\u001b[0m\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14900)\u001b[0m Client  7 Training...\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=33188)\u001b[0m Client  1 Training complete...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-07-08 18:11:02,365 | server.py:232 | fit_round 8 received 10 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server Evaluating... Evaluation Count:8\n",
      "7336/7336 [==============================] - 6s 768us/step - loss: 0.3012 - accuracy: 0.9019\n",
      "7336/7336 [==============================] - 5s 670us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2023-07-08 18:11:14,759 | server.py:119 | fit progress: (8, 0.301243394613266, {'accuracy': 0.9018509387969971}, 165.77427739999985)\n",
      "DEBUG flwr 2023-07-08 18:11:14,760 | server.py:168 | evaluate_round 8: strategy sampled 5 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  [[3.1767794e-08 2.1593680e-14 8.2990596e-07 ... 1.3945679e-25\n",
      "  1.0071320e-18 4.0182580e-21]\n",
      " [4.7832611e-08 1.4160281e-13 1.2137062e-10 ... 1.1085692e-25\n",
      "  1.7096177e-20 2.3858956e-21]\n",
      " [2.1698050e-07 1.7497697e-04 1.0454516e-07 ... 1.0498724e-17\n",
      "  5.8023552e-16 6.3973932e-14]\n",
      " ...\n",
      " [7.3271522e-09 7.3228295e-14 1.0855538e-06 ... 2.5703447e-25\n",
      "  6.1924736e-19 4.6354495e-21]\n",
      " [3.9969645e-08 2.5211413e-09 6.6615755e-11 ... 2.4648612e-22\n",
      "  1.5293079e-19 2.3620618e-18]\n",
      " [4.8837029e-10 3.5469068e-17 9.9999797e-01 ... 1.3427527e-37\n",
      "  4.7165148e-28 1.2012063e-27]] (234745, 34)\n",
      "\u001b[33mServer evaluation complete - Accuracy: 0.9019, Loss: 0.3012\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 381/381 [==============================] - ETA: 0s - loss: 0.2741 - accuracy: 0.8914\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=37660)\u001b[0m 340/381 [=========================>....] - ETA: 0s - loss: 0.2768 - accuracy: 0.8884\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=9064)\u001b[0m 175/381 [============>.................] - ETA: 0s - loss: 0.2794 - accuracy: 0.8874\u001b[32m [repeated 33x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m 380/381 [============================>.] - ETA: 0s - loss: 0.2868 - accuracy: 0.8844\u001b[32m [repeated 28x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=37660)\u001b[0m 275/381 [====================>.........] - ETA: 0s - loss: 0.2778 - accuracy: 0.8879\u001b[32m [repeated 28x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=9064)\u001b[0m 213/381 [===============>..............] - ETA: 0s - loss: 0.2746 - accuracy: 0.8880\u001b[32m [repeated 27x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=3456)\u001b[0m  69/381 [====>.........................] - ETA: 0s - loss: 0.2665 - accuracy: 0.8881\u001b[32m [repeated 40x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=3456)\u001b[0m Epoch 10/10\u001b[32m [repeated 40x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=9064)\u001b[0m \u001b[32m [repeated 528x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=3456)\u001b[0m   1/381 [..............................] - ETA: 0s - loss: 0.2149 - accuracy: 0.9062\u001b[32m [repeated 40x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=37660)\u001b[0m 101/381 [======>.......................] - ETA: 0s - loss: 0.2847 - accuracy: 0.8878\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=3456)\u001b[0m  35/381 [=>............................] - ETA: 0s - loss: 0.2837 - accuracy: 0.8826\u001b[32m [repeated 40x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=3456)\u001b[0m 194/381 [==============>...............] - ETA: 0s - loss: 0.2721 - accuracy: 0.8876\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=9064)\u001b[0m 381/381 [==============================] - 0s 1ms/step - loss: 0.2677 - accuracy: 0.8919\u001b[32m [repeated 50x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14900)\u001b[0m 280/381 [=====================>........] - ETA: 0s - loss: 0.2774 - accuracy: 0.8852\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 328/381 [========================>.....] - ETA: 0s - loss: 0.2670 - accuracy: 0.8916\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=3456)\u001b[0m 104/381 [=======>......................] - ETA: 0s - loss: 0.2669 - accuracy: 0.8887\u001b[32m [repeated 29x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=37660)\u001b[0m 138/381 [=========>....................] - ETA: 0s - loss: 0.2795 - accuracy: 0.8870\u001b[32m [repeated 34x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=3456)\u001b[0m 143/381 [==========>...................] - ETA: 0s - loss: 0.2714 - accuracy: 0.8889\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=37660)\u001b[0m 241/381 [=================>............] - ETA: 0s - loss: 0.2777 - accuracy: 0.8869\u001b[32m [repeated 26x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=3456)\u001b[0m 245/381 [==================>...........] - ETA: 0s - loss: 0.2736 - accuracy: 0.8857\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=9064)\u001b[0m 305/381 [=======================>......] - ETA: 0s - loss: 0.2713 - accuracy: 0.8900\u001b[32m [repeated 29x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=3456)\u001b[0m 346/381 [==========================>...] - ETA: 0s - loss: 0.2818 - accuracy: 0.8854\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m 164/381 [===========>..................] - ETA: 0s - loss: 0.2673 - accuracy: 0.8935\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=3456)\u001b[0m 293/381 [======================>.......] - ETA: 0s - loss: 0.2792 - accuracy: 0.8860\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=9064)\u001b[0m 255/381 [===================>..........] - ETA: 0s - loss: 0.2731 - accuracy: 0.8879\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=9064)\u001b[0m 356/381 [===========================>..] - ETA: 0s - loss: 0.2701 - accuracy: 0.8909\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=3456)\u001b[0m 228/381 [================>.............] - ETA: 0s - loss: 0.2879 - accuracy: 0.8823\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=1336)\u001b[0m Client  5 Evaluating...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=11452)\u001b[0m Client  5 Evaluating...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=11452)\u001b[0m Client  5 Evaluating...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=9064)\u001b[0m Client  0 Training complete...\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=3456)\u001b[0m Client ID: 2\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=3456)\u001b[0m Client  2 Evaluating...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=11452)\u001b[0m  56/381 [===>..........................] - ETA: 0s - loss: 0.2989 - accuracy: 0.8850  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-07-08 18:11:15,480 | server.py:182 | evaluate_round 8 received 5 results and 0 failures\n",
      "DEBUG flwr 2023-07-08 18:11:15,481 | server.py:218 | fit_round 9: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=11452)\u001b[0m \u001b[33mClient 5 evaluation complete - Accuracy: 0.888323, Loss: 0.281792\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m Client  2 Training...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m  44/381 [==>...........................] - ETA: 0s - loss: 0.2843 - accuracy: 0.8857  \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m  80/381 [=====>........................] - ETA: 0s - loss: 0.2809 - accuracy: 0.8908\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 118/381 [========>.....................] - ETA: 0s - loss: 0.2772 - accuracy: 0.8896\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=3456)\u001b[0m 187/381 [=============>................] - ETA: 0s - loss: 0.3040 - accuracy: 0.8877\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m  25/381 [>.............................] - ETA: 0s - loss: 0.3011 - accuracy: 0.8775  \n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=3456)\u001b[0m  99/381 [======>.......................] - ETA: 0s - loss: 0.2406 - accuracy: 0.9050\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=3456)\u001b[0m 333/381 [=========================>....] - ETA: 0s - loss: 0.2653 - accuracy: 0.8939\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=33188)\u001b[0m 166/381 [============>.................] - ETA: 0s - loss: 0.2659 - accuracy: 0.9007\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=9064)\u001b[0m 370/381 [============================>.] - ETA: 0s - loss: 0.2778 - accuracy: 0.8906\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=3456)\u001b[0m 268/381 [====================>.........] - ETA: 0s - loss: 0.2624 - accuracy: 0.8946\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=9064)\u001b[0m 204/381 [===============>..............] - ETA: 0s - loss: 0.2700 - accuracy: 0.8895\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=37660)\u001b[0m  65/381 [====>.........................] - ETA: 0s - loss: 0.2825 - accuracy: 0.8947\u001b[32m [repeated 52x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=3456)\u001b[0m Epoch 7/10\u001b[32m [repeated 64x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m \u001b[32m [repeated 698x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=3456)\u001b[0m   1/381 [..............................] - ETA: 0s - loss: 0.2487 - accuracy: 0.9219\u001b[32m [repeated 69x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m  99/381 [======>.......................] - ETA: 0s - loss: 0.2406 - accuracy: 0.9050\u001b[32m [repeated 45x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=3456)\u001b[0m  33/381 [=>............................] - ETA: 0s - loss: 0.2339 - accuracy: 0.9048\u001b[32m [repeated 62x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14900)\u001b[0m 195/381 [==============>...............] - ETA: 0s - loss: 0.2644 - accuracy: 0.8945\u001b[32m [repeated 44x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=3456)\u001b[0m 381/381 [==============================] - 1s 2ms/step - loss: 0.2627 - accuracy: 0.9007\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=3456)\u001b[0m 290/381 [=====================>........] - ETA: 0s - loss: 0.2603 - accuracy: 0.9006\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=3456)\u001b[0m 323/381 [========================>.....] - ETA: 0s - loss: 0.2630 - accuracy: 0.9019\u001b[32m [repeated 37x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m 104/381 [=======>......................] - ETA: 0s - loss: 0.2850 - accuracy: 0.8857\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14900)\u001b[0m 130/381 [=========>....................] - ETA: 0s - loss: 0.2649 - accuracy: 0.8954\u001b[32m [repeated 49x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=37660)\u001b[0m 140/381 [==========>...................] - ETA: 0s - loss: 0.2876 - accuracy: 0.8931\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=1336)\u001b[0m 230/381 [=================>............] - ETA: 0s - loss: 0.2696 - accuracy: 0.8937\u001b[32m [repeated 29x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 251/381 [==================>...........] - ETA: 0s - loss: 0.2563 - accuracy: 0.8982\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 317/381 [=======================>......] - ETA: 0s - loss: 0.2522 - accuracy: 0.8996\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=37660)\u001b[0m 355/381 [==========================>...] - ETA: 0s - loss: 0.2725 - accuracy: 0.8919\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m 164/381 [===========>..................] - ETA: 0s - loss: 0.2617 - accuracy: 0.9053\u001b[32m [repeated 43x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m 296/381 [======================>.......] - ETA: 0s - loss: 0.2654 - accuracy: 0.8953\u001b[32m [repeated 26x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m 260/381 [===================>..........] - ETA: 0s - loss: 0.2784 - accuracy: 0.8954\u001b[32m [repeated 36x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=3456)\u001b[0m 356/381 [===========================>..] - ETA: 0s - loss: 0.2640 - accuracy: 0.9010\u001b[32m [repeated 34x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m 228/381 [================>.............] - ETA: 0s - loss: 0.2815 - accuracy: 0.8958\u001b[32m [repeated 29x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=1336)\u001b[0m Client ID: 5\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=37660)\u001b[0m Client  8 Evaluating...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=37660)\u001b[0m  63/381 [===>..........................] - ETA: 0s - loss: 0.2651 - accuracy: 0.8976\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=37660)\u001b[0m \u001b[33mClient 8 evaluation complete - Accuracy: 0.887215, Loss: 0.298982\u001b[0m\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m Client  8 Training...\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m  85/381 [=====>........................] - ETA: 0s - loss: 0.3068 - accuracy: 0.8855\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=37660)\u001b[0m 125/381 [========>.....................] - ETA: 0s - loss: 0.2797 - accuracy: 0.8951\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=37660)\u001b[0m 190/381 [=============>................] - ETA: 0s - loss: 0.2742 - accuracy: 0.8943\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m Client  2 Training complete...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=3456)\u001b[0m 381/381 [==============================] - ETA: 0s - loss: 0.2459 - accuracy: 0.9072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-07-08 18:11:22,456 | server.py:232 | fit_round 9 received 10 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server Evaluating... Evaluation Count:9\n",
      "7336/7336 [==============================] - 6s 773us/step - loss: 0.2823 - accuracy: 0.9061\n",
      "7336/7336 [==============================] - 5s 664us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2023-07-08 18:11:34,867 | server.py:119 | fit progress: (9, 0.2822905480861664, {'accuracy': 0.9060853123664856}, 185.88188329999957)\n",
      "DEBUG flwr 2023-07-08 18:11:34,868 | server.py:168 | evaluate_round 9: strategy sampled 5 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  [[2.4357652e-08 4.0801204e-15 7.0983373e-07 ... 7.8026091e-28\n",
      "  2.4757130e-20 2.5835878e-23]\n",
      " [4.4807592e-08 1.2101476e-13 1.5985555e-10 ... 1.0570860e-26\n",
      "  8.0735054e-22 6.4889729e-23]\n",
      " [2.3330927e-07 1.8430666e-04 1.3153334e-08 ... 6.0120806e-18\n",
      "  3.5933239e-16 1.9018104e-14]\n",
      " ...\n",
      " [4.1027040e-09 9.1678357e-15 6.1519034e-07 ... 6.6168164e-28\n",
      "  7.9668317e-21 1.7364862e-23]\n",
      " [5.4969984e-08 8.5227808e-10 3.6379625e-11 ... 4.0590040e-23\n",
      "  1.3732337e-20 3.4055235e-19]\n",
      " [1.8362836e-10 3.8187426e-18 9.9999893e-01 ... 0.0000000e+00\n",
      "  1.9246010e-31 5.1758681e-31]] (234745, 34)\n",
      "\u001b[33mServer evaluation complete - Accuracy: 0.9061, Loss: 0.2823\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=1336)\u001b[0m 342/381 [=========================>....] - ETA: 0s - loss: 0.2571 - accuracy: 0.9033\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=1336)\u001b[0m 176/381 [============>.................] - ETA: 0s - loss: 0.2600 - accuracy: 0.9041\u001b[32m [repeated 25x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m 373/381 [============================>.] - ETA: 0s - loss: 0.2536 - accuracy: 0.9025\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=3456)\u001b[0m 276/381 [====================>.........] - ETA: 0s - loss: 0.2475 - accuracy: 0.9051\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=33188)\u001b[0m 209/381 [===============>..............] - ETA: 0s - loss: 0.2287 - accuracy: 0.9106\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14900)\u001b[0m  67/381 [====>.........................] - ETA: 0s - loss: 0.2324 - accuracy: 0.9088\u001b[32m [repeated 37x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14900)\u001b[0m Epoch 10/10\u001b[32m [repeated 36x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14900)\u001b[0m \u001b[32m [repeated 510x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14900)\u001b[0m   1/381 [..............................] - ETA: 0s - loss: 0.2282 - accuracy: 0.8750\u001b[32m [repeated 36x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14900)\u001b[0m 101/381 [======>.......................] - ETA: 0s - loss: 0.2320 - accuracy: 0.9100\u001b[32m [repeated 23x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14900)\u001b[0m  35/381 [=>............................] - ETA: 0s - loss: 0.2335 - accuracy: 0.9027\u001b[32m [repeated 36x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14900)\u001b[0m 203/381 [==============>...............] - ETA: 0s - loss: 0.2342 - accuracy: 0.9073\u001b[32m [repeated 23x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14900)\u001b[0m 381/381 [==============================] - 0s 1ms/step - loss: 0.2368 - accuracy: 0.9089\u001b[32m [repeated 46x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=33188)\u001b[0m 291/381 [=====================>........] - ETA: 0s - loss: 0.2329 - accuracy: 0.9107\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m 330/381 [========================>.....] - ETA: 0s - loss: 0.2451 - accuracy: 0.9041\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m 105/381 [=======>......................] - ETA: 0s - loss: 0.2427 - accuracy: 0.9064\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m 139/381 [=========>....................] - ETA: 0s - loss: 0.2445 - accuracy: 0.9058\u001b[32m [repeated 35x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14900)\u001b[0m 141/381 [==========>...................] - ETA: 0s - loss: 0.2377 - accuracy: 0.9070\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=3456)\u001b[0m 240/381 [=================>............] - ETA: 0s - loss: 0.2480 - accuracy: 0.9051\u001b[32m [repeated 28x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=33188)\u001b[0m 251/381 [==================>...........] - ETA: 0s - loss: 0.2336 - accuracy: 0.9102\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14900)\u001b[0m 309/381 [=======================>......] - ETA: 0s - loss: 0.2336 - accuracy: 0.9093\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m 346/381 [==========================>...] - ETA: 0s - loss: 0.2427 - accuracy: 0.9060\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=33188)\u001b[0m 165/381 [===========>..................] - ETA: 0s - loss: 0.2500 - accuracy: 0.9054\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m 301/381 [======================>.......] - ETA: 0s - loss: 0.2424 - accuracy: 0.9064\u001b[32m [repeated 26x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14900)\u001b[0m 264/381 [===================>..........] - ETA: 0s - loss: 0.2339 - accuracy: 0.9082\u001b[32m [repeated 26x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14900)\u001b[0m 359/381 [===========================>..] - ETA: 0s - loss: 0.2348 - accuracy: 0.9093\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14900)\u001b[0m 224/381 [================>.............] - ETA: 0s - loss: 0.2328 - accuracy: 0.9085\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=33188)\u001b[0m Client  3 Evaluating...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=33188)\u001b[0m Client  3 Evaluating...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14900)\u001b[0m 183/381 [=============>................] - ETA: 0s - loss: 0.2353 - accuracy: 0.9069\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14900)\u001b[0m Client  0 Training complete...\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=9228)\u001b[0m Client  3 Evaluating...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=14900)\u001b[0m Client ID: 7\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=14900)\u001b[0m Client  7 Evaluating...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=33188)\u001b[0m  55/381 [===>..........................] - ETA: 0s - loss: 0.2183 - accuracy: 0.9278 \n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=14900)\u001b[0m 115/381 [========>.....................] - ETA: 0s - loss: 0.2585 - accuracy: 0.9147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-07-08 18:11:35,573 | server.py:182 | evaluate_round 9 received 5 results and 0 failures\n",
      "DEBUG flwr 2023-07-08 18:11:35,573 | server.py:218 | fit_round 10: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=14900)\u001b[0m \u001b[33mClient 7 evaluation complete - Accuracy: 0.917176, Loss: 0.259579\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=33188)\u001b[0m Client  7 Training...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m  21/381 [>.............................] - ETA: 0s - loss: 0.2849 - accuracy: 0.9085\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14900)\u001b[0m  42/381 [==>...........................] - ETA: 0s - loss: 0.2615 - accuracy: 0.8891\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=33188)\u001b[0m  86/381 [=====>........................] - ETA: 0s - loss: 0.2530 - accuracy: 0.9050\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=9228)\u001b[0m 381/381 [==============================] - ETA: 0s - loss: 0.2503 - accuracy: 0.9095\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=1336)\u001b[0m 339/381 [=========================>....] - ETA: 0s - loss: 0.2361 - accuracy: 0.9147\u001b[32m [repeated 31x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=1336)\u001b[0m 169/381 [============>.................] - ETA: 0s - loss: 0.2396 - accuracy: 0.9131\u001b[32m [repeated 30x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=1336)\u001b[0m 373/381 [============================>.] - ETA: 0s - loss: 0.2337 - accuracy: 0.9155\u001b[32m [repeated 31x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=1336)\u001b[0m 270/381 [====================>.........] - ETA: 0s - loss: 0.2402 - accuracy: 0.9137\u001b[32m [repeated 29x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m 204/381 [===============>..............] - ETA: 0s - loss: 0.2176 - accuracy: 0.9172\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=9064)\u001b[0m  69/381 [====>.........................] - ETA: 0s - loss: 0.2342 - accuracy: 0.9149\u001b[32m [repeated 45x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m Epoch 7/10\u001b[32m [repeated 63x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=9064)\u001b[0m \u001b[32m [repeated 758x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m   1/381 [..............................] - ETA: 0s - loss: 0.2660 - accuracy: 0.9375\u001b[32m [repeated 68x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 101/381 [======>.......................] - ETA: 0s - loss: 0.2465 - accuracy: 0.9101\u001b[32m [repeated 38x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14900)\u001b[0m  36/381 [=>............................] - ETA: 0s - loss: 0.2397 - accuracy: 0.9102\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=1336)\u001b[0m 202/381 [==============>...............] - ETA: 0s - loss: 0.2398 - accuracy: 0.9117\u001b[32m [repeated 26x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=1336)\u001b[0m 381/381 [==============================] - 1s 1ms/step - loss: 0.2340 - accuracy: 0.9161\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=1336)\u001b[0m 292/381 [=====================>........] - ETA: 0s - loss: 0.2376 - accuracy: 0.9141\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=1336)\u001b[0m 326/381 [========================>.....] - ETA: 0s - loss: 0.2388 - accuracy: 0.9138\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=33188)\u001b[0m 102/381 [=======>......................] - ETA: 0s - loss: 0.2354 - accuracy: 0.9107\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=1336)\u001b[0m 135/381 [=========>....................] - ETA: 0s - loss: 0.2410 - accuracy: 0.9102\u001b[32m [repeated 37x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=9064)\u001b[0m 140/381 [==========>...................] - ETA: 0s - loss: 0.2619 - accuracy: 0.9131\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=1336)\u001b[0m 236/381 [=================>............] - ETA: 0s - loss: 0.2422 - accuracy: 0.9131\u001b[32m [repeated 36x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m 253/381 [==================>...........] - ETA: 0s - loss: 0.2334 - accuracy: 0.9091\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m 305/381 [=======================>......] - ETA: 0s - loss: 0.2272 - accuracy: 0.9156\u001b[32m [repeated 23x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=37660)\u001b[0m 343/381 [==========================>...] - ETA: 0s - loss: 0.2250 - accuracy: 0.9191\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=1336)\u001b[0m 163/381 [===========>..................] - ETA: 0s - loss: 0.2376 - accuracy: 0.9157\u001b[32m [repeated 25x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=1336)\u001b[0m 304/381 [======================>.......] - ETA: 0s - loss: 0.2380 - accuracy: 0.9144\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=1336)\u001b[0m 263/381 [===================>..........] - ETA: 0s - loss: 0.2402 - accuracy: 0.9136\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m 367/381 [===========================>..] - ETA: 0s - loss: 0.2305 - accuracy: 0.9162\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m 222/381 [================>.............] - ETA: 0s - loss: 0.2331 - accuracy: 0.9093\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m 190/381 [=============>................] - ETA: 0s - loss: 0.2292 - accuracy: 0.9119\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=37660)\u001b[0m Client ID: 0\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=11364)\u001b[0m Client  0 Evaluating...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m  52/381 [===>..........................] - ETA: 0s - loss: 0.2296 - accuracy: 0.9141\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 124/381 [========>.....................] - ETA: 0s - loss: 0.2566 - accuracy: 0.9046\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=9228)\u001b[0m \u001b[33mClient 1 evaluation complete - Accuracy: 0.918613, Loss: 0.258828\u001b[0m\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=37660)\u001b[0m Client  0 Training...\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=33188)\u001b[0m Client  7 Training complete...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-07-08 18:11:42,765 | server.py:232 | fit_round 10 received 10 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=1336)\u001b[0m 316/381 [=======================>......] - ETA: 0s - loss: 0.2109 - accuracy: 0.9278\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14900)\u001b[0m  40/381 [==>...........................] - ETA: 0s - loss: 0.2477 - accuracy: 0.9207\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14900)\u001b[0m  80/381 [=====>........................] - ETA: 0s - loss: 0.2240 - accuracy: 0.9270\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "Server Evaluating... Evaluation Count:10\n",
      "7336/7336 [==============================] - 6s 784us/step - loss: 0.2517 - accuracy: 0.9470\n",
      "7336/7336 [==============================] - 5s 692us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2023-07-08 18:11:55,485 | server.py:119 | fit progress: (10, 0.2516759932041168, {'accuracy': 0.947019100189209}, 206.4999181000003)\n",
      "DEBUG flwr 2023-07-08 18:11:55,486 | server.py:168 | evaluate_round 10: strategy sampled 5 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  [[7.6719315e-09 5.0311269e-16 3.7394358e-07 ... 2.2753245e-30\n",
      "  2.2319377e-22 4.1434787e-26]\n",
      " [2.8162866e-08 4.8906659e-14 7.1425130e-11 ... 8.8916035e-28\n",
      "  1.5755419e-23 1.4679720e-24]\n",
      " [6.3082403e-08 1.4264050e-03 1.9314557e-09 ... 1.8353800e-18\n",
      "  8.2982838e-17 8.2105942e-16]\n",
      " ...\n",
      " [8.7163304e-10 7.5723650e-16 2.3160020e-07 ... 8.1196548e-31\n",
      "  3.4276685e-23 1.5974264e-26]\n",
      " [1.1154936e-07 6.5868871e-10 1.7200784e-11 ... 1.5774367e-22\n",
      "  6.4321185e-21 2.9614015e-19]\n",
      " [2.2104615e-11 1.4375551e-18 9.9999976e-01 ... 0.0000000e+00\n",
      "  4.3925962e-35 1.8618102e-34]] (234745, 34)\n",
      "\u001b[33mServer evaluation complete - Accuracy: 0.9470, Loss: 0.2517\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=1336)\u001b[0m 339/381 [=========================>....] - ETA: 0s - loss: 0.2133 - accuracy: 0.9271\u001b[32m [repeated 27x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=1336)\u001b[0m 168/381 [============>.................] - ETA: 0s - loss: 0.2089 - accuracy: 0.9300\u001b[32m [repeated 28x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14900)\u001b[0m 369/381 [============================>.] - ETA: 0s - loss: 0.2095 - accuracy: 0.9301\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14900)\u001b[0m 276/381 [====================>.........] - ETA: 0s - loss: 0.2143 - accuracy: 0.9301\u001b[32m [repeated 29x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m 207/381 [===============>..............] - ETA: 0s - loss: 0.2107 - accuracy: 0.9293\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=37660)\u001b[0m  75/381 [====>.........................] - ETA: 0s - loss: 0.1889 - accuracy: 0.9335\u001b[32m [repeated 37x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14900)\u001b[0m Epoch 10/10\u001b[32m [repeated 37x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14900)\u001b[0m \u001b[32m [repeated 547x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14900)\u001b[0m   1/381 [..............................] - ETA: 0s - loss: 0.2365 - accuracy: 0.9375\u001b[32m [repeated 37x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=1336)\u001b[0m 101/381 [======>.......................] - ETA: 0s - loss: 0.2097 - accuracy: 0.9291\u001b[32m [repeated 28x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m  38/381 [=>............................] - ETA: 0s - loss: 0.1974 - accuracy: 0.9387\u001b[32m [repeated 35x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14900)\u001b[0m 195/381 [==============>...............] - ETA: 0s - loss: 0.2060 - accuracy: 0.9318\u001b[32m [repeated 37x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14900)\u001b[0m 381/381 [==============================] - 0s 1ms/step - loss: 0.2101 - accuracy: 0.9294\u001b[32m [repeated 46x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14900)\u001b[0m Client ID: 3\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14900)\u001b[0m 318/381 [========================>.....] - ETA: 0s - loss: 0.2116 - accuracy: 0.9304\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=37660)\u001b[0m 114/381 [=======>......................] - ETA: 0s - loss: 0.1881 - accuracy: 0.9342\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11364)\u001b[0m 136/381 [=========>....................] - ETA: 0s - loss: 0.2030 - accuracy: 0.9270\u001b[32m [repeated 38x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=37660)\u001b[0m 140/381 [==========>...................] - ETA: 0s - loss: 0.2032 - accuracy: 0.9277\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14900)\u001b[0m 235/381 [=================>............] - ETA: 0s - loss: 0.2078 - accuracy: 0.9309\u001b[32m [repeated 40x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35448)\u001b[0m 244/381 [==================>...........] - ETA: 0s - loss: 0.2106 - accuracy: 0.9271\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=11452)\u001b[0m 316/381 [=======================>......] - ETA: 0s - loss: 0.2277 - accuracy: 0.9217\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=37660)\u001b[0m 351/381 [==========================>...] - ETA: 0s - loss: 0.1991 - accuracy: 0.9348\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=37660)\u001b[0m 154/381 [===========>..................] - ETA: 0s - loss: 0.1930 - accuracy: 0.9356\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=1336)\u001b[0m 303/381 [======================>.......] - ETA: 0s - loss: 0.2141 - accuracy: 0.9276\u001b[32m [repeated 32x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14900)\u001b[0m 264/381 [===================>..........] - ETA: 0s - loss: 0.2168 - accuracy: 0.9283\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=3456)\u001b[0m 362/381 [===========================>..] - ETA: 0s - loss: 0.2153 - accuracy: 0.9246\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14900)\u001b[0m 226/381 [================>.............] - ETA: 0s - loss: 0.2207 - accuracy: 0.9228\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=37660)\u001b[0m Client ID: 3\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=11452)\u001b[0m Client ID: 3\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14900)\u001b[0m Client ID: 3\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14900)\u001b[0m 116/381 [========>.....................] - ETA: 0s - loss: 0.2180 - accuracy: 0.9270\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14900)\u001b[0m Client  4 Training complete...\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=3456)\u001b[0m Client ID: 1\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=11452)\u001b[0m Client  3 Evaluating...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=11452)\u001b[0m  44/381 [==>...........................] - ETA: 0s - loss: 0.1890 - accuracy: 0.9400  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-07-08 18:11:56,219 | server.py:182 | evaluate_round 10 received 5 results and 0 failures\n",
      "INFO flwr 2023-07-08 18:11:56,220 | server.py:147 | FL finished in 207.2351546\n",
      "INFO flwr 2023-07-08 18:11:56,221 | app.py:218 | app_fit: losses_distributed [(1, 0.45155642882487557), (2, 0.41725539138928613), (3, 0.39083029344210185), (4, 0.3630958344092109), (5, 0.3422653079032898), (6, 0.32378795742988586), (7, 0.3013587437185041), (8, 0.2821817932286431), (9, 0.2539467602968216), (10, 0.22407538652317788)]\n",
      "INFO flwr 2023-07-08 18:11:56,221 | app.py:219 | app_fit: metrics_distributed_fit {}\n",
      "INFO flwr 2023-07-08 18:11:56,222 | app.py:220 | app_fit: metrics_distributed {}\n",
      "INFO flwr 2023-07-08 18:11:56,223 | app.py:221 | app_fit: losses_centralized [(0, 3.6029906272888184), (1, 0.4543115794658661), (2, 0.42306700348854065), (3, 0.39969688653945923), (4, 0.38259148597717285), (5, 0.35876625776290894), (6, 0.3427808880805969), (7, 0.32311421632766724), (8, 0.301243394613266), (9, 0.2822905480861664), (10, 0.2516759932041168)]\n",
      "INFO flwr 2023-07-08 18:11:56,223 | app.py:222 | app_fit: metrics_centralized {'accuracy': [(0, 0.00281156157143414), (1, 0.7992630004882812), (2, 0.8089842200279236), (3, 0.8420498967170715), (4, 0.8480777144432068), (5, 0.8534026145935059), (6, 0.8658459186553955), (7, 0.8713455200195312), (8, 0.9018509387969971), (9, 0.9060853123664856), (10, 0.947019100189209)]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken:  0:03:57.726124\n",
      "CPU times: total: 3min 24s\n",
      "Wall time: 3min 57s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=11452)\u001b[0m \u001b[33mClient 3 evaluation complete - Accuracy: 0.938108, Loss: 0.221519\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print (f\"\\n{Colours.YELLOW.value} Deploy simulation... {class_size_map[len(label.unique())]} ({class_size}) Classifier\\n{Colours.NORMAL.value}\")\n",
    "\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "# Start simulation\n",
    "fl.simulation.start_simulation(\n",
    "    client_fn=client_fn,\n",
    "    num_clients=NUM_OF_CLIENTS,\n",
    "    config=fl.server.ServerConfig(num_rounds=NUM_OF_ROUNDS),\n",
    "    strategy=strategy,\n",
    ")\n",
    "\n",
    "end_time = datetime.datetime.now()\n",
    "print(\"Total time taken: \", end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
