{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 - Federated Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the available types of federated learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### THIS SECTION NEEDS TO BE SET TO DETERMINE WHICH CONFIGURATION METHOD TO UTILISE\n",
    "\n",
    "SPLIT_AVAILABLE_METHODS = ['INDIVIDUAL_ATTACK', 'ATTACK_GROUP', 'STRATIFIED']\n",
    "METHOD = 'STRATIFIED'\n",
    "NUM_OF_STRATIFIED_CLIENTS = 10 # only applies to stratified method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Include the defines for the dataframe columns and the attack labels and their mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from includes import X_columns, y_column, dict_34_classes, dict_8_classes, dict_2_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install flwr[simulation] torch torchvision matplotlib sklearn openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import flwr as fl\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "#warnings.filterwarnings('ignore')\n",
    "\n",
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from flwr.common import Metrics\n",
    "from torch.utils.data import DataLoader, random_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flwr 1.4.0\n",
      "numpy 1.24.2\n",
      "torch 1.13.1\n",
      "Training on cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(\"flwr\", fl.__version__)\n",
    "print(\"numpy\", np.__version__)\n",
    "print(\"torch\", torch.__version__)\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Training on {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIRECTORY = '../datasets/CICIoT2023/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Either read the training pickle file if it exists, or process the dataset from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training sets: 135\n",
      "Test sets: 34\n",
      "HACK TO REPLICATE ORIGINAL AUTHORS CODE WITH ONE FILE TRAIN - ['part-00134-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv']\n",
      "Reading training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing training data to pickle file...\n",
      "Training data size: (243649, 47)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Check to see if the file 'training_data.pkl' exists in the directory. If it does, load it. If not, print an error.\n",
    "if os.path.isfile('training_data.pkl'):\n",
    "    print(\"File exists, loading data...\")\n",
    "    train_df = pd.read_pickle('training_data.pkl')\n",
    "    print(\"Training data loaded from pickle file.\")\n",
    "\n",
    "else:\n",
    "    df_sets = [k for k in os.listdir(DATASET_DIRECTORY) if k.endswith('.csv')]\n",
    "    df_sets.sort()\n",
    "    training_sets = df_sets[:int(len(df_sets)*.8)]\n",
    "    test_sets = df_sets[int(len(df_sets)*.8):]\n",
    "\n",
    "    # Print the number of files in each set\n",
    "    print('Training sets: {}'.format(len(training_sets)))\n",
    "    print('Test sets: {}'.format(len(test_sets)))\n",
    "\n",
    "    ######################\n",
    "    # HACK TEMP CODE\n",
    "    ######################\n",
    "    # Set training_sets to the last entry of training_sets\n",
    "    training_sets = training_sets[-1:]\n",
    "    print(f\"HACK TO REPLICATE ORIGINAL AUTHORS CODE WITH ONE FILE TRAIN - {training_sets}\")\n",
    "    ######################\n",
    "    # HACK END TEMP CODE\n",
    "    ######################\n",
    "\n",
    "    # Concatenate all training sets into one dataframe\n",
    "    dfs = []\n",
    "    print(\"Reading training data...\")\n",
    "    for train_set in tqdm(training_sets):\n",
    "        df_new = pd.read_csv(DATASET_DIRECTORY + train_set)\n",
    "        dfs.append(df_new)\n",
    "    train_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    # Map y column to the dict_34_classes values - The pickle file already has this done.\n",
    "    train_df['label'] = train_df['label'].map(dict_34_classes)\n",
    "\n",
    "    # Save the output to a pickle file\n",
    "    print(\"Writing training data to pickle file...\")\n",
    "    train_df.to_pickle('training_data.pkl')\n",
    "\n",
    "print(\"Training data size: {}\".format(train_df.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flow_duration</th>\n",
       "      <th>Header_Length</th>\n",
       "      <th>Protocol Type</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Rate</th>\n",
       "      <th>Srate</th>\n",
       "      <th>Drate</th>\n",
       "      <th>fin_flag_number</th>\n",
       "      <th>syn_flag_number</th>\n",
       "      <th>rst_flag_number</th>\n",
       "      <th>...</th>\n",
       "      <th>Std</th>\n",
       "      <th>Tot size</th>\n",
       "      <th>IAT</th>\n",
       "      <th>Number</th>\n",
       "      <th>Magnitue</th>\n",
       "      <th>Radius</th>\n",
       "      <th>Covariance</th>\n",
       "      <th>Variance</th>\n",
       "      <th>Weight</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000838</td>\n",
       "      <td>54.62</td>\n",
       "      <td>6.05</td>\n",
       "      <td>64.00</td>\n",
       "      <td>11.961779</td>\n",
       "      <td>11.961779</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111473</td>\n",
       "      <td>54.45</td>\n",
       "      <td>8.307598e+07</td>\n",
       "      <td>9.5</td>\n",
       "      <td>10.392912</td>\n",
       "      <td>0.037895</td>\n",
       "      <td>0.035900</td>\n",
       "      <td>0.02</td>\n",
       "      <td>141.55</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.005486</td>\n",
       "      <td>75.88</td>\n",
       "      <td>6.00</td>\n",
       "      <td>64.00</td>\n",
       "      <td>29.502125</td>\n",
       "      <td>29.502125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100314</td>\n",
       "      <td>54.24</td>\n",
       "      <td>8.309325e+07</td>\n",
       "      <td>9.5</td>\n",
       "      <td>10.395361</td>\n",
       "      <td>0.143036</td>\n",
       "      <td>0.346802</td>\n",
       "      <td>0.03</td>\n",
       "      <td>141.55</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>45.61</td>\n",
       "      <td>65.81</td>\n",
       "      <td>151.517376</td>\n",
       "      <td>151.517376</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>57.165223</td>\n",
       "      <td>576.80</td>\n",
       "      <td>8.369379e+07</td>\n",
       "      <td>9.5</td>\n",
       "      <td>33.783684</td>\n",
       "      <td>80.958879</td>\n",
       "      <td>8638.780727</td>\n",
       "      <td>0.40</td>\n",
       "      <td>141.55</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>54.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>64.00</td>\n",
       "      <td>1.500542</td>\n",
       "      <td>1.500542</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54.00</td>\n",
       "      <td>8.309408e+07</td>\n",
       "      <td>9.5</td>\n",
       "      <td>10.392305</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>141.55</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.004568</td>\n",
       "      <td>745.42</td>\n",
       "      <td>5.95</td>\n",
       "      <td>65.13</td>\n",
       "      <td>8.082100</td>\n",
       "      <td>8.082100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>549.190629</td>\n",
       "      <td>927.04</td>\n",
       "      <td>8.333561e+07</td>\n",
       "      <td>9.5</td>\n",
       "      <td>41.550978</td>\n",
       "      <td>776.661367</td>\n",
       "      <td>318084.344439</td>\n",
       "      <td>0.95</td>\n",
       "      <td>141.55</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243644</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>54.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>64.00</td>\n",
       "      <td>19.582485</td>\n",
       "      <td>19.582485</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54.00</td>\n",
       "      <td>8.331443e+07</td>\n",
       "      <td>9.5</td>\n",
       "      <td>10.392305</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>141.55</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243645</th>\n",
       "      <td>0.037146</td>\n",
       "      <td>78.22</td>\n",
       "      <td>36.21</td>\n",
       "      <td>63.18</td>\n",
       "      <td>24.542045</td>\n",
       "      <td>24.542045</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>110.233513</td>\n",
       "      <td>453.78</td>\n",
       "      <td>8.358187e+07</td>\n",
       "      <td>9.5</td>\n",
       "      <td>30.338676</td>\n",
       "      <td>154.660856</td>\n",
       "      <td>23401.960226</td>\n",
       "      <td>0.53</td>\n",
       "      <td>141.55</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243646</th>\n",
       "      <td>3.293075</td>\n",
       "      <td>1025996.92</td>\n",
       "      <td>17.00</td>\n",
       "      <td>64.00</td>\n",
       "      <td>572.160392</td>\n",
       "      <td>572.160392</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>554.00</td>\n",
       "      <td>8.378910e+07</td>\n",
       "      <td>9.5</td>\n",
       "      <td>33.286634</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>141.55</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243647</th>\n",
       "      <td>0.047343</td>\n",
       "      <td>35223.00</td>\n",
       "      <td>17.00</td>\n",
       "      <td>64.00</td>\n",
       "      <td>15083.107398</td>\n",
       "      <td>15083.107398</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.00</td>\n",
       "      <td>8.309852e+07</td>\n",
       "      <td>9.5</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>141.55</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243648</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>64.00</td>\n",
       "      <td>9.308130</td>\n",
       "      <td>9.308130</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>536.729102</td>\n",
       "      <td>949.52</td>\n",
       "      <td>8.324966e+07</td>\n",
       "      <td>9.5</td>\n",
       "      <td>45.017352</td>\n",
       "      <td>759.033957</td>\n",
       "      <td>306570.231772</td>\n",
       "      <td>0.94</td>\n",
       "      <td>141.55</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>243649 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        flow_duration  Header_Length  Protocol Type  Duration          Rate  \\\n",
       "0            0.000838          54.62           6.05     64.00     11.961779   \n",
       "1            0.005486          75.88           6.00     64.00     29.502125   \n",
       "2            0.000000           0.00          45.61     65.81    151.517376   \n",
       "3            0.000000          54.00           6.00     64.00      1.500542   \n",
       "4            0.004568         745.42           5.95     65.13      8.082100   \n",
       "...               ...            ...            ...       ...           ...   \n",
       "243644       0.000000          54.00           6.00     64.00     19.582485   \n",
       "243645       0.037146          78.22          36.21     63.18     24.542045   \n",
       "243646       3.293075     1025996.92          17.00     64.00    572.160392   \n",
       "243647       0.047343       35223.00          17.00     64.00  15083.107398   \n",
       "243648       0.000000           0.00           1.00     64.00      9.308130   \n",
       "\n",
       "               Srate  Drate  fin_flag_number  syn_flag_number  \\\n",
       "0          11.961779    0.0              0.0              0.0   \n",
       "1          29.502125    0.0              0.0              1.0   \n",
       "2         151.517376    0.0              0.0              0.0   \n",
       "3           1.500542    0.0              0.0              1.0   \n",
       "4           8.082100    0.0              0.0              0.0   \n",
       "...              ...    ...              ...              ...   \n",
       "243644     19.582485    0.0              0.0              0.0   \n",
       "243645     24.542045    0.0              0.0              0.0   \n",
       "243646    572.160392    0.0              0.0              0.0   \n",
       "243647  15083.107398    0.0              0.0              0.0   \n",
       "243648      9.308130    0.0              0.0              0.0   \n",
       "\n",
       "        rst_flag_number  ...         Std  Tot size           IAT  Number  \\\n",
       "0                   0.0  ...    0.111473     54.45  8.307598e+07     9.5   \n",
       "1                   0.0  ...    0.100314     54.24  8.309325e+07     9.5   \n",
       "2                   0.0  ...   57.165223    576.80  8.369379e+07     9.5   \n",
       "3                   0.0  ...    0.000000     54.00  8.309408e+07     9.5   \n",
       "4                   0.0  ...  549.190629    927.04  8.333561e+07     9.5   \n",
       "...                 ...  ...         ...       ...           ...     ...   \n",
       "243644              0.0  ...    0.000000     54.00  8.331443e+07     9.5   \n",
       "243645              0.0  ...  110.233513    453.78  8.358187e+07     9.5   \n",
       "243646              0.0  ...    0.000000    554.00  8.378910e+07     9.5   \n",
       "243647              0.0  ...    0.000000     50.00  8.309852e+07     9.5   \n",
       "243648              0.0  ...  536.729102    949.52  8.324966e+07     9.5   \n",
       "\n",
       "         Magnitue      Radius     Covariance  Variance  Weight  label  \n",
       "0       10.392912    0.037895       0.035900      0.02  141.55      5  \n",
       "1       10.395361    0.143036       0.346802      0.03  141.55      3  \n",
       "2       33.783684   80.958879    8638.780727      0.40  141.55     17  \n",
       "3       10.392305    0.000000       0.000000      0.00  141.55      3  \n",
       "4       41.550978  776.661367  318084.344439      0.95  141.55      8  \n",
       "...           ...         ...            ...       ...     ...    ...  \n",
       "243644  10.392305    0.000000       0.000000      0.00  141.55      2  \n",
       "243645  30.338676  154.660856   23401.960226      0.53  141.55     18  \n",
       "243646  33.286634    0.000000       0.000000      0.00  141.55     19  \n",
       "243647  10.000000    0.000000       0.000000      0.00  141.55      4  \n",
       "243648  45.017352  759.033957  306570.231772      0.94  141.55     10  \n",
       "\n",
       "[243649 rows x 47 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale the training data input features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "train_df[X_columns] = scaler.fit_transform(train_df[X_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Test Data\n",
    "Concat the test data into a single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File testing_data.pkl does not exist, constructing data...\n",
      "Test sets: 1\n",
      "Reading test data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing test data to pickle file testing_data.pkl...\n",
      "Testing data size: (234745, 47)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Check to see if the file 'test_data.pkl' exists in the directory. If it does, load it. If not, print an error.\n",
    "testing_data_pickle_file = 'testing_data.pkl'\n",
    "\n",
    "if os.path.isfile(testing_data_pickle_file):\n",
    "    print(f\"File {testing_data_pickle_file} exists, loading data...\")\n",
    "    test_df = pd.read_pickle(testing_data_pickle_file)\n",
    "    print(\"Test data loaded from pickle file.\")\n",
    "\n",
    "else:\n",
    "    print(f\"File {testing_data_pickle_file} does not exist, constructing data...\")\n",
    "\n",
    "    df_sets = [k for k in os.listdir(DATASET_DIRECTORY) if k.endswith('.csv')]\n",
    "    df_sets.sort()\n",
    "    training_sets = df_sets[:int(len(df_sets)*.8)]\n",
    "    test_sets = df_sets[int(len(df_sets)*.8):]\n",
    "\n",
    "    ############################################\n",
    "    ############################################\n",
    "    # HACK - Make things quicker for now\n",
    "    ############################################\n",
    "    ############################################\n",
    "\n",
    "    test_sets = df_sets[int(len(df_sets)*.95):]\n",
    "    \n",
    "    # Set training_sets to the last entry of training_sets\n",
    "    test_sets = test_sets[-1:]\n",
    "    \n",
    "    ############################################\n",
    "    ############################################\n",
    "    # END HACK \n",
    "    ############################################\n",
    "    ############################################\n",
    "\n",
    "    # Print the number of files in each set\n",
    "    print('Test sets: {}'.format(len(test_sets)))\n",
    "    \n",
    "    # Concatenate all testing sets into one dataframe\n",
    "    dfs = []\n",
    "    print(\"Reading test data...\")\n",
    "    for test_set in tqdm(test_sets):\n",
    "        df_new = pd.read_csv(DATASET_DIRECTORY + test_set)\n",
    "        dfs.append(df_new)\n",
    "    test_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    # Map y column to the dict_34_classes values - The pickle file already has this done.\n",
    "    test_df['label'] = test_df['label'].map(dict_34_classes)\n",
    "\n",
    "    # Save the output to a pickle file\n",
    "    print(f\"Writing test data to pickle file {testing_data_pickle_file}...\")\n",
    "    test_df.to_pickle(testing_data_pickle_file)\n",
    "\n",
    "print(\"Testing data size: {}\".format(test_df.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale the testing data input features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "test_df[X_columns] = scaler.fit_transform(test_df[X_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size: (243649, 47)\n",
      "Testing data size: (234745, 47)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training data size: {}\".format(train_df.shape))\n",
    "print(\"Testing data size: {}\".format(test_df.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratify the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jon\\anaconda3\\envs\\py310copy\\lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 5 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define fl_X_train and fl_y_train\n",
    "fl_X_train = []\n",
    "fl_y_train = []\n",
    "\n",
    "# take the train_df[X_columns] and split them into 10 smaller groups in the fl_X_train list using  StratifiedKFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=NUM_OF_STRATIFIED_CLIENTS, shuffle=True, random_state=42)\n",
    "for train_index, test_index in skf.split(train_df[X_columns], train_df[y_column]):\n",
    "    fl_X_train.append(train_df[X_columns].iloc[test_index])\n",
    "    fl_y_train.append(train_df[y_column].iloc[test_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the testing daya to X_test and y_test ndarrays\n",
    "X_test = test_df[X_columns].to_numpy()\n",
    "y_test = test_df[y_column].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM_CLIENTS: 10\n",
      "NUM_ROUNDS: 10\n",
      "\n",
      "Original train_df size: (243649, 47)\n",
      "Checking training data split groups\n",
      "0 : X Shape (24365, 46) Y Shape (24365,)\n",
      "1 : X Shape (24365, 46) Y Shape (24365,)\n",
      "2 : X Shape (24365, 46) Y Shape (24365,)\n",
      "3 : X Shape (24365, 46) Y Shape (24365,)\n",
      "4 : X Shape (24365, 46) Y Shape (24365,)\n",
      "5 : X Shape (24365, 46) Y Shape (24365,)\n",
      "6 : X Shape (24365, 46) Y Shape (24365,)\n",
      "7 : X Shape (24365, 46) Y Shape (24365,)\n",
      "8 : X Shape (24365, 46) Y Shape (24365,)\n",
      "9 : X Shape (24364, 46) Y Shape (24364,)\n",
      "\n",
      "Checking testing data\n",
      "X_test size: (234745, 46)\n",
      "y_test size: (234745,)\n",
      "\n",
      "Deploy Simulation\n"
     ]
    }
   ],
   "source": [
    "NUM_OF_CLIENTS = len(fl_X_train)\n",
    "print(\"NUM_CLIENTS:\", NUM_OF_CLIENTS)\n",
    "\n",
    "NUM_OF_ROUNDS = 10\n",
    "print(\"NUM_ROUNDS:\", NUM_OF_ROUNDS)\n",
    "print()\n",
    "print(\"Original train_df size: {}\".format(train_df.shape))\n",
    "\n",
    "print(\"Checking training data split groups\")\n",
    "for i in range(len(fl_X_train)):\n",
    "    print(i, \":\", \"X Shape\", fl_X_train[i].shape, \"Y Shape\", fl_y_train[i].shape)\n",
    "\n",
    "\n",
    "# Print the sizes of X_test and y_test\n",
    "print(\"\\nChecking testing data\")\n",
    "print(\"X_test size: {}\".format(X_test.shape))\n",
    "print(\"y_test size: {}\".format(y_test.shape))\n",
    "\n",
    "print(\"\\nDeploy Simulation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scikit-learn 1.2.0.\n",
      "flwr 1.4.0\n",
      "numpy 1.24.2\n",
      "tf 2.11.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import flwr as fl\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "print('scikit-learn {}.'.format(sklearn.__version__))\n",
    "print(\"flwr\", fl.__version__)\n",
    "print(\"numpy\", np.__version__)\n",
    "print(\"tf\", tf.__version__)\n",
    "# Make TensorFlow log less verbose\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "label = train_df[y_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2023-07-08 15:18:42,827 | app.py:146 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scikit-learn 1.2.0.\n",
      "flwr 1.4.0\n",
      "numpy 1.24.2\n",
      "tf 2.11.0\n",
      "Deploy simulation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-08 15:18:48,299\tINFO worker.py:1636 -- Started a local Ray instance.\n",
      "INFO flwr 2023-07-08 15:18:52,892 | app.py:180 | Flower VCE: Ray initialized with resources: {'object_store_memory': 6860022988.0, 'memory': 13720045979.0, 'node:127.0.0.1': 1.0, 'GPU': 1.0, 'CPU': 24.0}\n",
      "INFO flwr 2023-07-08 15:18:52,893 | server.py:86 | Initializing global parameters\n",
      "INFO flwr 2023-07-08 15:18:52,893 | server.py:273 | Requesting initial parameters from one random client\n",
      "INFO flwr 2023-07-08 15:18:57,417 | server.py:277 | Received initial parameters from one random client\n",
      "INFO flwr 2023-07-08 15:18:57,418 | server.py:88 | Evaluating initial parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_get_parameters pid=27348)\u001b[0m Client ID: 0\n",
      "Server Evaluating... 0\n",
      "7336/7336 [==============================] - 7s 859us/step - loss: 3.5127 - accuracy: 0.0139\n",
      "7336/7336 [==============================] - 5s 738us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2023-07-08 15:19:12,358 | server.py:91 | initial parameters (loss, other metrics): 3.512744188308716, {'accuracy': 0.013934269547462463}\n",
      "INFO flwr 2023-07-08 15:19:12,359 | server.py:101 | FL starting\n",
      "DEBUG flwr 2023-07-08 15:19:12,360 | server.py:218 | fit_round 1: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  [[0.04399142 0.03285323 0.022268   ... 0.02198555 0.02794883 0.03142716]\n",
      " [0.03304889 0.03387224 0.02687915 ... 0.02460237 0.03231393 0.03241945]\n",
      " [0.06455815 0.07422164 0.00952974 ... 0.0339473  0.02146625 0.04614651]\n",
      " ...\n",
      " [0.04451308 0.0327598  0.02237261 ... 0.02172144 0.02820656 0.03132477]\n",
      " [0.02850394 0.03753914 0.02848002 ... 0.02364259 0.03116714 0.03350698]\n",
      " [0.0372074  0.06278017 0.02784516 ... 0.01462823 0.02989636 0.05174119]] (234745, 34)\n",
      "Server Evaluating complete... 0.013934269547462463 3.512744188308716\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m Client ID: 2\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m Client  2 Training...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m Epoch 1/10\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m   1/381 [..............................] - ETA: 4:21 - loss: 3.5123 - accuracy: 0.0156\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m  35/381 [=>............................] - ETA: 0s - loss: 3.0769 - accuracy: 0.2339  \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m  70/381 [====>.........................] - ETA: 0s - loss: 2.6911 - accuracy: 0.3266\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 107/381 [=======>......................] - ETA: 0s - loss: 2.3351 - accuracy: 0.4301\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 131/381 [=========>....................] - ETA: 0s - loss: 2.1201 - accuracy: 0.4837\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 167/381 [============>.................] - ETA: 0s - loss: 1.8490 - accuracy: 0.5410\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 203/381 [==============>...............] - ETA: 0s - loss: 1.6472 - accuracy: 0.5792\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 238/381 [=================>............] - ETA: 0s - loss: 1.4991 - accuracy: 0.6058\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 273/381 [====================>.........] - ETA: 0s - loss: 1.3842 - accuracy: 0.6273\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 312/381 [=======================>......] - ETA: 0s - loss: 1.2846 - accuracy: 0.6439\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 347/381 [==========================>...] - ETA: 0s - loss: 1.2134 - accuracy: 0.6547\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 381/381 [==============================] - 1s 1ms/step - loss: 1.1558 - accuracy: 0.6648\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m Epoch 2/10\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m   1/381 [..............................] - ETA: 0s - loss: 0.6498 - accuracy: 0.7031\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m  34/381 [=>............................] - ETA: 0s - loss: 0.5369 - accuracy: 0.7707\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m  70/381 [====>.........................] - ETA: 0s - loss: 0.5313 - accuracy: 0.7719\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 108/381 [=======>......................] - ETA: 0s - loss: 0.5291 - accuracy: 0.7752\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 144/381 [==========>...................] - ETA: 0s - loss: 0.5275 - accuracy: 0.7766\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 181/381 [=============>................] - ETA: 0s - loss: 0.5246 - accuracy: 0.7782\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 218/381 [================>.............] - ETA: 0s - loss: 0.5237 - accuracy: 0.7769\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 254/381 [===================>..........] - ETA: 0s - loss: 0.5229 - accuracy: 0.7766\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 291/381 [=====================>........] - ETA: 0s - loss: 0.5205 - accuracy: 0.7782\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 330/381 [========================>.....] - ETA: 0s - loss: 0.5177 - accuracy: 0.7799\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 367/381 [===========================>..] - ETA: 0s - loss: 0.5169 - accuracy: 0.7802\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 381/381 [==============================] - 1s 1ms/step - loss: 0.5171 - accuracy: 0.7809\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m Epoch 3/10\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m   1/381 [..............................] - ETA: 0s - loss: 0.5956 - accuracy: 0.6875\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m  35/381 [=>............................] - ETA: 0s - loss: 0.5047 - accuracy: 0.7799\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m  73/381 [====>.........................] - ETA: 0s - loss: 0.4966 - accuracy: 0.7804\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 108/381 [=======>......................] - ETA: 0s - loss: 0.4869 - accuracy: 0.7853\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 144/381 [==========>...................] - ETA: 0s - loss: 0.4824 - accuracy: 0.7896\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 179/381 [=============>................] - ETA: 0s - loss: 0.4851 - accuracy: 0.7889\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 215/381 [===============>..............] - ETA: 0s - loss: 0.4825 - accuracy: 0.7908\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 246/381 [==================>...........] - ETA: 0s - loss: 0.4850 - accuracy: 0.7906\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 274/381 [====================>.........] - ETA: 0s - loss: 0.4856 - accuracy: 0.7892\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 308/381 [=======================>......] - ETA: 0s - loss: 0.4872 - accuracy: 0.7881\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 345/381 [==========================>...] - ETA: 0s - loss: 0.4868 - accuracy: 0.7887\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 381/381 [==============================] - 1s 1ms/step - loss: 0.4871 - accuracy: 0.7879\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m Epoch 4/10\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m   1/381 [..............................] - ETA: 0s - loss: 0.4310 - accuracy: 0.8750\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m  37/381 [=>............................] - ETA: 0s - loss: 0.4827 - accuracy: 0.8066\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m  70/381 [====>.........................] - ETA: 0s - loss: 0.4694 - accuracy: 0.8049\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 105/381 [=======>......................] - ETA: 0s - loss: 0.4734 - accuracy: 0.7970\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 138/381 [=========>....................] - ETA: 0s - loss: 0.4711 - accuracy: 0.7971\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 171/381 [============>.................] - ETA: 0s - loss: 0.4723 - accuracy: 0.7947\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 205/381 [===============>..............] - ETA: 0s - loss: 0.4749 - accuracy: 0.7931\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 242/381 [==================>...........] - ETA: 0s - loss: 0.4749 - accuracy: 0.7954\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 276/381 [====================>.........] - ETA: 0s - loss: 0.4743 - accuracy: 0.7941\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 310/381 [=======================>......] - ETA: 0s - loss: 0.4733 - accuracy: 0.7945\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 344/381 [==========================>...] - ETA: 0s - loss: 0.4718 - accuracy: 0.7941\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 381/381 [==============================] - 1s 1ms/step - loss: 0.4717 - accuracy: 0.7941\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m Epoch 5/10\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m   1/381 [..............................] - ETA: 0s - loss: 0.3986 - accuracy: 0.7812\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m  38/381 [=>............................] - ETA: 0s - loss: 0.4663 - accuracy: 0.7841\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m  78/381 [=====>........................] - ETA: 0s - loss: 0.4637 - accuracy: 0.7907\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 116/381 [========>.....................] - ETA: 0s - loss: 0.4649 - accuracy: 0.7927\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 154/381 [===========>..................] - ETA: 0s - loss: 0.4654 - accuracy: 0.7950\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 192/381 [==============>...............] - ETA: 0s - loss: 0.4624 - accuracy: 0.7962\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 230/381 [=================>............] - ETA: 0s - loss: 0.4648 - accuracy: 0.7955\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 268/381 [====================>.........] - ETA: 0s - loss: 0.4656 - accuracy: 0.7953\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 306/381 [=======================>......] - ETA: 0s - loss: 0.4631 - accuracy: 0.7965\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 344/381 [==========================>...] - ETA: 0s - loss: 0.4644 - accuracy: 0.7951\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 379/381 [============================>.] - ETA: 0s - loss: 0.4638 - accuracy: 0.7951\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 381/381 [==============================] - 1s 1ms/step - loss: 0.4639 - accuracy: 0.7951\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m Epoch 6/10\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m   1/381 [..............................] - ETA: 0s - loss: 0.3650 - accuracy: 0.8281\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m  38/381 [=>............................] - ETA: 0s - loss: 0.4591 - accuracy: 0.7911\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m  75/381 [====>.........................] - ETA: 0s - loss: 0.4613 - accuracy: 0.7894\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 115/381 [========>.....................] - ETA: 0s - loss: 0.4615 - accuracy: 0.7921\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 152/381 [==========>...................] - ETA: 0s - loss: 0.4610 - accuracy: 0.7930\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 187/381 [=============>................] - ETA: 0s - loss: 0.4596 - accuracy: 0.7945\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 222/381 [================>.............] - ETA: 0s - loss: 0.4565 - accuracy: 0.7962\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 256/381 [===================>..........] - ETA: 0s - loss: 0.4541 - accuracy: 0.7974\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 289/381 [=====================>........] - ETA: 0s - loss: 0.4556 - accuracy: 0.7978\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 328/381 [========================>.....] - ETA: 0s - loss: 0.4542 - accuracy: 0.7985\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 367/381 [===========================>..] - ETA: 0s - loss: 0.4565 - accuracy: 0.7970\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 381/381 [==============================] - 1s 1ms/step - loss: 0.4545 - accuracy: 0.7981\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m Epoch 7/10\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m   1/381 [..............................] - ETA: 0s - loss: 0.5696 - accuracy: 0.7344\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m  39/381 [==>...........................] - ETA: 0s - loss: 0.4477 - accuracy: 0.7985\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m  78/381 [=====>........................] - ETA: 0s - loss: 0.4532 - accuracy: 0.8035\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 115/381 [========>.....................] - ETA: 0s - loss: 0.4481 - accuracy: 0.8015\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 153/381 [===========>..................] - ETA: 0s - loss: 0.4509 - accuracy: 0.7997\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 188/381 [=============>................] - ETA: 0s - loss: 0.4481 - accuracy: 0.8015\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 224/381 [================>.............] - ETA: 0s - loss: 0.4480 - accuracy: 0.8014\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 258/381 [===================>..........] - ETA: 0s - loss: 0.4502 - accuracy: 0.8001\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 292/381 [=====================>........] - ETA: 0s - loss: 0.4489 - accuracy: 0.8012\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 326/381 [========================>.....] - ETA: 0s - loss: 0.4493 - accuracy: 0.8004\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 360/381 [===========================>..] - ETA: 0s - loss: 0.4498 - accuracy: 0.7998\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 381/381 [==============================] - 1s 1ms/step - loss: 0.4492 - accuracy: 0.8005\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m Epoch 8/10\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m   1/381 [..............................] - ETA: 0s - loss: 0.4723 - accuracy: 0.8281\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m  38/381 [=>............................] - ETA: 0s - loss: 0.4356 - accuracy: 0.8039\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m  75/381 [====>.........................] - ETA: 0s - loss: 0.4427 - accuracy: 0.8017\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 113/381 [=======>......................] - ETA: 0s - loss: 0.4369 - accuracy: 0.8056\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 151/381 [==========>...................] - ETA: 0s - loss: 0.4354 - accuracy: 0.8050\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 187/381 [=============>................] - ETA: 0s - loss: 0.4350 - accuracy: 0.8067\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 223/381 [================>.............] - ETA: 0s - loss: 0.4388 - accuracy: 0.8056\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 260/381 [===================>..........] - ETA: 0s - loss: 0.4407 - accuracy: 0.8051\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 298/381 [======================>.......] - ETA: 0s - loss: 0.4433 - accuracy: 0.8036\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 334/381 [=========================>....] - ETA: 0s - loss: 0.4435 - accuracy: 0.8031\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 368/381 [===========================>..] - ETA: 0s - loss: 0.4445 - accuracy: 0.8018\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 381/381 [==============================] - 1s 1ms/step - loss: 0.4438 - accuracy: 0.8017\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m Epoch 9/10\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m   1/381 [..............................] - ETA: 0s - loss: 0.6746 - accuracy: 0.7188\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m  39/381 [==>...........................] - ETA: 0s - loss: 0.4371 - accuracy: 0.7929\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m  76/381 [====>.........................] - ETA: 0s - loss: 0.4363 - accuracy: 0.8000\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 113/381 [=======>......................] - ETA: 0s - loss: 0.4419 - accuracy: 0.7955\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 151/381 [==========>...................] - ETA: 0s - loss: 0.4383 - accuracy: 0.7989\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 189/381 [=============>................] - ETA: 0s - loss: 0.4366 - accuracy: 0.8005\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 226/381 [================>.............] - ETA: 0s - loss: 0.4391 - accuracy: 0.8002\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 263/381 [===================>..........] - ETA: 0s - loss: 0.4402 - accuracy: 0.7994\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 302/381 [======================>.......] - ETA: 0s - loss: 0.4405 - accuracy: 0.7999\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 339/381 [=========================>....] - ETA: 0s - loss: 0.4409 - accuracy: 0.8006\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 379/381 [============================>.] - ETA: 0s - loss: 0.4406 - accuracy: 0.8007\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 381/381 [==============================] - 1s 1ms/step - loss: 0.4409 - accuracy: 0.8004\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m Epoch 10/10\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m   1/381 [..............................] - ETA: 0s - loss: 0.5583 - accuracy: 0.7344\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m  37/381 [=>............................] - ETA: 0s - loss: 0.4504 - accuracy: 0.7905\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m Client ID: 5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m  72/381 [====>.........................] - ETA: 0s - loss: 0.4497 - accuracy: 0.7923\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 108/381 [=======>......................] - ETA: 0s - loss: 0.4470 - accuracy: 0.7962\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 143/381 [==========>...................] - ETA: 0s - loss: 0.4427 - accuracy: 0.7999\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m Client  5 Training...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 178/381 [=============>................] - ETA: 0s - loss: 0.4407 - accuracy: 0.7999\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 212/381 [===============>..............] - ETA: 0s - loss: 0.4380 - accuracy: 0.8017\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35088)\u001b[0m Client  \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35088)\u001b[0m  Training...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 246/381 [==================>...........] - ETA: 0s - loss: 0.4385 - accuracy: 0.8019\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 283/381 [=====================>........] - ETA: 0s - loss: 0.4398 - accuracy: 0.8005\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 316/381 [=======================>......] - ETA: 0s - loss: 0.4404 - accuracy: 0.7998\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 347/381 [==========================>...] - ETA: 0s - loss: 0.4378 - accuracy: 0.8010\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 379/381 [============================>.] - ETA: 0s - loss: 0.4367 - accuracy: 0.8019\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 381/381 [==============================] - 1s 1ms/step - loss: 0.4363 - accuracy: 0.8019\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m Client  2 Training complete...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m   1/381 [..............................] - ETA: 4:21 - loss: 3.5324 - accuracy: 0.0000e+00\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m  34/381 [=>............................] - ETA: 0s - loss: 3.1245 - accuracy: 0.2325  \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=4504)\u001b[0m  66/381 [====>.........................] - ETA: 0s - loss: 2.7611 - accuracy: 0.3042\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m 111/381 [=======>......................] - ETA: 0s - loss: 2.2918 - accuracy: 0.4314\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m 142/381 [==========>...................] - ETA: 0s - loss: 2.0143 - accuracy: 0.4969\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=4504)\u001b[0m  97/381 [======>.......................] - ETA: 0s - loss: 2.4424 - accuracy: 0.4072\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28804)\u001b[0m 138/381 [=========>....................] - ETA: 0s - loss: 2.0764 - accuracy: 0.4888\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29032)\u001b[0m  59/381 [===>..........................] - ETA: 0s - loss: 2.8103 - accuracy: 0.2871\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28804)\u001b[0m 167/381 [============>.................] - ETA: 0s - loss: 1.8602 - accuracy: 0.5314\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m 194/381 [==============>...............] - ETA: 0s - loss: 1.6802 - accuracy: 0.5623\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m 226/381 [================>.............] - ETA: 0s - loss: 1.5381 - accuracy: 0.5890\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28804)\u001b[0m 229/381 [=================>............] - ETA: 0s - loss: 1.5527 - accuracy: 0.5888\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m 259/381 [===================>..........] - ETA: 0s - loss: 1.4234 - accuracy: 0.6114\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m 189/381 [=============>................] - ETA: 0s - loss: 1.7326 - accuracy: 0.5600\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m 207/381 [===============>..............] - ETA: 0s - loss: 1.6547 - accuracy: 0.5723\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m 290/381 [=====================>........] - ETA: 0s - loss: 1.3354 - accuracy: 0.6288\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m 314/381 [=======================>......] - ETA: 0s - loss: 1.2782 - accuracy: 0.6395\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m 277/381 [====================>.........] - ETA: 0s - loss: 1.3980 - accuracy: 0.6192\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35088)\u001b[0m 247/381 [==================>...........] - ETA: 0s - loss: 1.4802 - accuracy: 0.6110\u001b[32m [repeated 4x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m 345/381 [==========================>...] - ETA: 0s - loss: 1.2176 - accuracy: 0.6480\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m 381/381 [==============================] - 1s 2ms/step - loss: 1.1550 - accuracy: 0.6604\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m 330/381 [========================>.....] - ETA: 0s - loss: 1.2578 - accuracy: 0.6442\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m  24/381 [>.............................] - ETA: 0s - loss: 0.5161 - accuracy: 0.7852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=4504)\u001b[0m 359/381 [===========================>..] - ETA: 0s - loss: 1.2059 - accuracy: 0.6547\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m  83/381 [=====>........................] - ETA: 0s - loss: 0.5136 - accuracy: 0.7912\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28804)\u001b[0m 123/381 [========>.....................] - ETA: 0s - loss: 0.5454 - accuracy: 0.7735\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=4504)\u001b[0m 162/381 [===========>..................] - ETA: 0s - loss: 0.5320 - accuracy: 0.7759\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30560)\u001b[0m 369/381 [============================>.] - ETA: 0s - loss: 0.5286 - accuracy: 0.7731\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28804)\u001b[0m  39/381 [==>...........................] - ETA: 0s - loss: 3.0328 - accuracy: 0.2524  \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29032)\u001b[0m 297/381 [======================>.......] - ETA: 0s - loss: 0.4775 - accuracy: 0.7867\u001b[32m [repeated 23x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35088)\u001b[0m 338/381 [=========================>....] - ETA: 0s - loss: 0.4609 - accuracy: 0.7965\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m 381/381 [==============================] - ETA: 0s - loss: 0.4529 - accuracy: 0.7998\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35088)\u001b[0m Epoch 7/10\u001b[32m [repeated 63x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m Client ID: 8\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30560)\u001b[0m Client  6 Training...\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35088)\u001b[0m \u001b[32m [repeated 691x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35088)\u001b[0m   1/381 [..............................] - ETA: 0s - loss: 0.5049 - accuracy: 0.7344\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m  36/381 [=>............................] - ETA: 0s - loss: 0.4309 - accuracy: 0.8073\u001b[32m [repeated 78x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m  73/381 [====>.........................] - ETA: 0s - loss: 0.4286 - accuracy: 0.8127\u001b[32m [repeated 69x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29032)\u001b[0m 103/381 [=======>......................] - ETA: 0s - loss: 0.4484 - accuracy: 0.7899\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m 140/381 [==========>...................] - ETA: 0s - loss: 0.4300 - accuracy: 0.8048\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35088)\u001b[0m 101/381 [======>.......................] - ETA: 0s - loss: 0.4285 - accuracy: 0.8055\u001b[32m [repeated 54x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35088)\u001b[0m 135/381 [=========>....................] - ETA: 0s - loss: 0.4327 - accuracy: 0.8032\u001b[32m [repeated 57x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28804)\u001b[0m  61/381 [===>..........................] - ETA: 0s - loss: 0.4481 - accuracy: 0.8005\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=4504)\u001b[0m 169/381 [============>.................] - ETA: 0s - loss: 0.4424 - accuracy: 0.7993\u001b[32m [repeated 35x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30560)\u001b[0m 192/381 [==============>...............] - ETA: 0s - loss: 0.4472 - accuracy: 0.7989\u001b[32m [repeated 54x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29032)\u001b[0m 226/381 [================>.............] - ETA: 0s - loss: 0.4440 - accuracy: 0.7920\u001b[32m [repeated 28x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28804)\u001b[0m 232/381 [=================>............] - ETA: 0s - loss: 0.4368 - accuracy: 0.8027\u001b[32m [repeated 37x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m 255/381 [===================>..........] - ETA: 0s - loss: 0.4319 - accuracy: 0.8074\u001b[32m [repeated 43x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m 184/381 [=============>................] - ETA: 0s - loss: 0.4309 - accuracy: 0.8083\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35088)\u001b[0m 213/381 [===============>..............] - ETA: 0s - loss: 0.4351 - accuracy: 0.8020\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35088)\u001b[0m 283/381 [=====================>........] - ETA: 0s - loss: 0.4377 - accuracy: 0.8007\u001b[32m [repeated 31x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35088)\u001b[0m 315/381 [=======================>......] - ETA: 0s - loss: 0.4356 - accuracy: 0.8016\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m 278/381 [====================>.........] - ETA: 0s - loss: 0.4378 - accuracy: 0.8008\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35088)\u001b[0m 249/381 [==================>...........] - ETA: 0s - loss: 0.4359 - accuracy: 0.8020\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35088)\u001b[0m 349/381 [==========================>...] - ETA: 0s - loss: 0.4378 - accuracy: 0.8016\u001b[32m [repeated 28x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m Client  3 Training complete...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m 381/381 [==============================] - 1s 1ms/step - loss: 0.4326 - accuracy: 0.8051\u001b[32m [repeated 81x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m 326/381 [========================>.....] - ETA: 0s - loss: 0.4328 - accuracy: 0.8055\u001b[32m [repeated 36x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m 360/381 [===========================>..] - ETA: 0s - loss: 0.4328 - accuracy: 0.8053\u001b[32m [repeated 37x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-07-08 15:19:25,647 | server.py:232 | fit_round 1 received 10 results and 0 failures\n",
      "WARNING flwr 2023-07-08 15:19:25,660 | fedavg.py:243 | No fit_metrics_aggregation_fn provided\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server Evaluating... 1\n",
      "7336/7336 [==============================] - 6s 869us/step - loss: 0.4517 - accuracy: 0.7999\n",
      "7336/7336 [==============================] - 6s 753us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2023-07-08 15:19:39,509 | server.py:119 | fit progress: (1, 0.45169058442115784, {'accuracy': 0.7998551726341248}, 27.149088900001516)\n",
      "DEBUG flwr 2023-07-08 15:19:39,510 | server.py:168 | evaluate_round 1: strategy sampled 5 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  [[1.33207138e-07 6.36114555e-06 1.47746206e-04 ... 8.68022099e-10\n",
      "  2.14931912e-08 6.61047350e-09]\n",
      " [3.86401007e-05 6.65221523e-05 2.06606146e-05 ... 2.53733798e-08\n",
      "  4.66289748e-06 5.01470095e-06]\n",
      " [1.23347458e-03 1.16350739e-05 1.41297063e-08 ... 2.51707879e-05\n",
      "  9.26569828e-06 1.19678385e-04]\n",
      " ...\n",
      " [1.55874147e-07 6.52775134e-06 1.43857411e-04 ... 1.07060050e-09\n",
      "  2.61017057e-08 7.62508989e-09]\n",
      " [1.68666168e-06 2.64449918e-05 3.93006558e-05 ... 1.33897227e-09\n",
      "  2.04505454e-07 1.88243703e-07]\n",
      " [5.25859548e-07 2.64985124e-06 9.99716938e-01 ... 4.95545756e-08\n",
      "  4.88766467e-08 1.61638025e-06]] (234745, 34)\n",
      "Server Evaluating complete... 0.7998551726341248 0.45169058442115784\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=29032)\u001b[0m Client  3 Evaluating...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35088)\u001b[0m 120/381 [========>.....................] - ETA: 0s - loss: 0.4459 - accuracy: 0.8008\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35088)\u001b[0m 162/381 [===========>..................] - ETA: 0s - loss: 0.4383 - accuracy: 0.7955\u001b[32m [repeated 36x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35088)\u001b[0m 380/381 [============================>.] - ETA: 0s - loss: 0.4360 - accuracy: 0.8006\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35088)\u001b[0m 299/381 [======================>.......] - ETA: 0s - loss: 0.4365 - accuracy: 0.8001\u001b[32m [repeated 23x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35088)\u001b[0m 337/381 [=========================>....] - ETA: 0s - loss: 0.4368 - accuracy: 0.7997\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m 381/381 [==============================] - ETA: 0s - loss: 0.4366 - accuracy: 0.8014\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35088)\u001b[0m Epoch 10/10\u001b[32m [repeated 27x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=29032)\u001b[0m Client  3 Evaluating...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35088)\u001b[0m \u001b[32m [repeated 392x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35088)\u001b[0m   1/381 [..............................] - ETA: 0s - loss: 0.3668 - accuracy: 0.8438\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35088)\u001b[0m  31/381 [=>............................] - ETA: 0s - loss: 0.4354 - accuracy: 0.7918\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m  64/381 [====>.........................] - ETA: 0s - loss: 0.4465 - accuracy: 0.7998\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m Client  3 Evaluating...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m Client  3 Evaluating...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35088)\u001b[0m  95/381 [======>.......................] - ETA: 0s - loss: 0.4438 - accuracy: 0.7893\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35088)\u001b[0m 127/381 [=========>....................] - ETA: 0s - loss: 0.4421 - accuracy: 0.7952\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35088)\u001b[0m  62/381 [===>..........................] - ETA: 0s - loss: 0.4417 - accuracy: 0.7931\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m Client  3 Evaluating...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35088)\u001b[0m 197/381 [==============>...............] - ETA: 0s - loss: 0.4398 - accuracy: 0.7965\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=4504)\u001b[0m 226/381 [================>.............] - ETA: 0s - loss: 0.4336 - accuracy: 0.8051\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35088)\u001b[0m 231/381 [=================>............] - ETA: 0s - loss: 0.4400 - accuracy: 0.7965\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35088)\u001b[0m 264/381 [===================>..........] - ETA: 0s - loss: 0.4391 - accuracy: 0.7979\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m Client  3 Evaluating...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29032)\u001b[0m 306/381 [=======================>......] - ETA: 0s - loss: 0.4386 - accuracy: 0.7988\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m 270/381 [====================>.........] - ETA: 0s - loss: 0.4379 - accuracy: 0.8013\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29032)\u001b[0m Client  3 Evaluating...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35088)\u001b[0m Client  9 Training complete...\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35088)\u001b[0m 381/381 [==============================] - 1s 1ms/step - loss: 0.4359 - accuracy: 0.8007\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=4504)\u001b[0m 330/381 [========================>.....] - ETA: 0s - loss: 0.4375 - accuracy: 0.8028\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=4504)\u001b[0m 367/381 [===========================>..] - ETA: 0s - loss: 0.4389 - accuracy: 0.8025\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=35088)\u001b[0m Client ID: 1\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=29032)\u001b[0m  50/381 [==>...........................] - ETA: 0s - loss: 0.4373 - accuracy: 0.8025  \n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=35088)\u001b[0m 103/381 [=======>......................] - ETA: 0s - loss: 0.4530 - accuracy: 0.7925\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=35088)\u001b[0m 207/381 [===============>..............] - ETA: 0s - loss: 0.4524 - accuracy: 0.7952\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=15636)\u001b[0m 152/381 [==========>...................] - ETA: 0s - loss: 0.4563 - accuracy: 0.7969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-07-08 15:19:40,314 | server.py:182 | evaluate_round 1 received 5 results and 0 failures\n",
      "WARNING flwr 2023-07-08 15:19:40,315 | fedavg.py:274 | No evaluate_metrics_aggregation_fn provided\n",
      "DEBUG flwr 2023-07-08 15:19:40,316 | server.py:218 | fit_round 2: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=15636)\u001b[0m 253/381 [==================>...........] - ETA: 0s - loss: 0.4554 - accuracy: 0.7969\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=15636)\u001b[0m 355/381 [==========================>...] - ETA: 0s - loss: 0.4576 - accuracy: 0.7960\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=35088)\u001b[0m Client  1 Evaluating complete... 0.7961419820785522 0.4519489109516144\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=4504)\u001b[0m Client \n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=4504)\u001b[0m  0 Evaluating complete... 0.7993433475494385 0.4542098343372345\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29032)\u001b[0m Client  8 Training...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=4504)\u001b[0m  81/381 [=====>........................] - ETA: 0s - loss: 0.4417 - accuracy: 0.7957\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29032)\u001b[0m 188/381 [=============>................] - ETA: 0s - loss: 0.4554 - accuracy: 0.7943\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m 166/381 [============>.................] - ETA: 0s - loss: 0.4549 - accuracy: 0.8017\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29032)\u001b[0m 280/381 [=====================>........] - ETA: 0s - loss: 0.4506 - accuracy: 0.7983\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=15636)\u001b[0m Client  6 Evaluating...\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29032)\u001b[0m 126/381 [========>.....................] - ETA: 0s - loss: 0.4274 - accuracy: 0.8027\u001b[32m [repeated 37x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=31244)\u001b[0m 160/381 [===========>..................] - ETA: 0s - loss: 0.4248 - accuracy: 0.8034\u001b[32m [repeated 29x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m 378/381 [============================>.] - ETA: 0s - loss: 0.4174 - accuracy: 0.8109\u001b[32m [repeated 23x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 302/381 [======================>.......] - ETA: 0s - loss: 0.4276 - accuracy: 0.8068\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m 342/381 [=========================>....] - ETA: 0s - loss: 0.4181 - accuracy: 0.8103\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m  62/381 [===>..........................] - ETA: 0s - loss: 0.4207 - accuracy: 0.8092\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m Epoch 7/10\u001b[32m [repeated 61x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m \u001b[32m [repeated 763x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m   1/381 [..............................] - ETA: 0s - loss: 0.5027 - accuracy: 0.7812\u001b[32m [repeated 66x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m  32/381 [=>............................] - ETA: 0s - loss: 0.4226 - accuracy: 0.8140\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30560)\u001b[0m  65/381 [====>.........................] - ETA: 0s - loss: 0.4131 - accuracy: 0.8106\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28804)\u001b[0m  91/381 [======>.......................] - ETA: 0s - loss: 0.4286 - accuracy: 0.8067\u001b[32m [repeated 45x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=31244)\u001b[0m 128/381 [=========>....................] - ETA: 0s - loss: 0.4221 - accuracy: 0.8058\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m  62/381 [===>..........................] - ETA: 0s - loss: 0.4207 - accuracy: 0.8092\u001b[32m [repeated 49x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30560)\u001b[0m 192/381 [==============>...............] - ETA: 0s - loss: 0.4122 - accuracy: 0.8125\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29032)\u001b[0m 223/381 [================>.............] - ETA: 0s - loss: 0.4255 - accuracy: 0.8040\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m 235/381 [=================>............] - ETA: 0s - loss: 0.4163 - accuracy: 0.8110\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=31244)\u001b[0m 255/381 [===================>..........] - ETA: 0s - loss: 0.4310 - accuracy: 0.8026\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m 306/381 [=======================>......] - ETA: 0s - loss: 0.4171 - accuracy: 0.8104\u001b[32m [repeated 26x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m 272/381 [====================>.........] - ETA: 0s - loss: 0.4177 - accuracy: 0.8100\u001b[32m [repeated 29x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m 381/381 [==============================] - 1s 1ms/step - loss: 0.4171 - accuracy: 0.8108\u001b[32m [repeated 56x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=31244)\u001b[0m 318/381 [========================>.....] - ETA: 0s - loss: 0.4315 - accuracy: 0.8034\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m 366/381 [===========================>..] - ETA: 0s - loss: 0.4262 - accuracy: 0.8060\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m Client ID: 5\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=15636)\u001b[0m  50/381 [==>...........................] - ETA: 0s - loss: 0.4686 - accuracy: 0.7944  \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m 105/381 [=======>......................] - ETA: 0s - loss: 0.4149 - accuracy: 0.8100\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m 207/381 [===============>..............] - ETA: 0s - loss: 0.4126 - accuracy: 0.8105\u001b[32m [repeated 37x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m 148/381 [==========>...................] - ETA: 0s - loss: 0.4248 - accuracy: 0.8043\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m 246/381 [==================>...........] - ETA: 0s - loss: 0.4138 - accuracy: 0.8121\u001b[32m [repeated 32x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m 343/381 [==========================>...] - ETA: 0s - loss: 0.4170 - accuracy: 0.8095\u001b[32m [repeated 31x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=29032)\u001b[0m Client  3 Evaluating complete... 0.8025446534156799 0.4531075656414032\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m Client  2 Training...\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m  87/381 [=====>........................] - ETA: 0s - loss: 0.4074 - accuracy: 0.8114\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30560)\u001b[0m 186/381 [=============>................] - ETA: 0s - loss: 0.4111 - accuracy: 0.8140\u001b[32m [repeated 50x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m 381/381 [==============================] - ETA: 0s - loss: 0.4086 - accuracy: 0.8124\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m 170/381 [============>.................] - ETA: 0s - loss: 0.4003 - accuracy: 0.8183\u001b[32m [repeated 26x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30560)\u001b[0m 281/381 [=====================>........] - ETA: 0s - loss: 0.4095 - accuracy: 0.8124\u001b[32m [repeated 32x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m Client  2 Training complete...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-07-08 15:19:47,704 | server.py:232 | fit_round 2 received 10 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server Evaluating... 2\n",
      "7336/7336 [==============================] - 6s 876us/step - loss: 0.4181 - accuracy: 0.8191\n",
      "7336/7336 [==============================] - 5s 743us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2023-07-08 15:20:01,593 | server.py:119 | fit progress: (2, 0.418056458234787, {'accuracy': 0.8190845251083374}, 49.23296950000076)\n",
      "DEBUG flwr 2023-07-08 15:20:01,594 | server.py:168 | evaluate_round 2: strategy sampled 5 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  [[1.4154866e-09 1.0771752e-07 1.4821270e-04 ... 1.4639911e-17\n",
      "  2.0124669e-14 1.2622938e-14]\n",
      " [1.3598310e-05 3.4371551e-06 1.2332155e-05 ... 1.9840640e-12\n",
      "  4.3642427e-09 2.4693586e-08]\n",
      " [6.2355032e-04 9.5327476e-07 3.1151757e-09 ... 9.9590420e-07\n",
      "  8.8074250e-07 3.7734924e-05]\n",
      " ...\n",
      " [1.8750119e-09 1.1297869e-07 1.4742334e-04 ... 2.6926004e-17\n",
      "  3.3263946e-14 2.0326863e-14]\n",
      " [9.0510966e-08 6.6883655e-07 2.2043463e-05 ... 9.0716136e-15\n",
      "  7.0279503e-12 6.0395078e-11]\n",
      " [1.0317311e-08 4.0075694e-08 9.9995196e-01 ... 4.9194496e-11\n",
      "  3.7595760e-11 2.3098614e-09]] (234745, 34)\n",
      "Server Evaluating complete... 0.8190845251083374 0.418056458234787\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=27348)\u001b[0m Client  8 Evaluating...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m 125/381 [========>.....................] - ETA: 0s - loss: 0.4049 - accuracy: 0.8185\u001b[32m [repeated 27x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m 161/381 [===========>..................] - ETA: 0s - loss: 0.4018 - accuracy: 0.8145\u001b[32m [repeated 23x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 375/381 [============================>.] - ETA: 0s - loss: 0.4081 - accuracy: 0.8129\u001b[32m [repeated 25x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=4504)\u001b[0m 295/381 [======================>.......] - ETA: 0s - loss: 0.4143 - accuracy: 0.8095\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 333/381 [=========================>....] - ETA: 0s - loss: 0.4072 - accuracy: 0.8135\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m Epoch 10/10\u001b[32m [repeated 39x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m \u001b[32m [repeated 613x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m   1/381 [..............................] - ETA: 0s - loss: 0.3727 - accuracy: 0.8438\u001b[32m [repeated 39x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m  36/381 [=>............................] - ETA: 0s - loss: 0.3769 - accuracy: 0.8255\u001b[32m [repeated 40x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m  66/381 [====>.........................] - ETA: 0s - loss: 0.3885 - accuracy: 0.8149\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m  98/381 [======>.......................] - ETA: 0s - loss: 0.3948 - accuracy: 0.8151\u001b[32m [repeated 30x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m 128/381 [=========>....................] - ETA: 0s - loss: 0.3965 - accuracy: 0.8159\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m  60/381 [===>..........................] - ETA: 0s - loss: 0.4120 - accuracy: 0.8133\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m 195/381 [==============>...............] - ETA: 0s - loss: 0.4067 - accuracy: 0.8139\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 220/381 [================>.............] - ETA: 0s - loss: 0.4060 - accuracy: 0.8139\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m 230/381 [=================>............] - ETA: 0s - loss: 0.4074 - accuracy: 0.8135\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 257/381 [===================>..........] - ETA: 0s - loss: 0.4074 - accuracy: 0.8148\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m 305/381 [=======================>......] - ETA: 0s - loss: 0.4041 - accuracy: 0.8153\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m 269/381 [====================>.........] - ETA: 0s - loss: 0.4063 - accuracy: 0.8145\u001b[32m [repeated 23x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m 381/381 [==============================] - 1s 1ms/step - loss: 0.4029 - accuracy: 0.8164\u001b[32m [repeated 49x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35088)\u001b[0m 330/381 [========================>.....] - ETA: 0s - loss: 0.4126 - accuracy: 0.8117\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35088)\u001b[0m 368/381 [===========================>..] - ETA: 0s - loss: 0.4133 - accuracy: 0.8113\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=27348)\u001b[0m Client  8 Evaluating...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m 103/381 [=======>......................] - ETA: 0s - loss: 0.3994 - accuracy: 0.8174\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m 213/381 [===============>..............] - ETA: 0s - loss: 0.4027 - accuracy: 0.8162\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m 151/381 [==========>...................] - ETA: 0s - loss: 0.4070 - accuracy: 0.8133\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m 243/381 [==================>...........] - ETA: 0s - loss: 0.4030 - accuracy: 0.8157\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m 345/381 [==========================>...] - ETA: 0s - loss: 0.4028 - accuracy: 0.8164\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=4504)\u001b[0m 186/381 [=============>................] - ETA: 0s - loss: 0.4110 - accuracy: 0.8099\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=31244)\u001b[0m 166/381 [============>.................] - ETA: 0s - loss: 0.4120 - accuracy: 0.8109\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35088)\u001b[0m 291/381 [=====================>........] - ETA: 0s - loss: 0.4121 - accuracy: 0.8129\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m Client  9 Training complete...\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=4504)\u001b[0m Client ID: 6\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=4504)\u001b[0m Client  6 Evaluating...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=27348)\u001b[0m  45/381 [==>...........................] - ETA: 0s - loss: 0.3952 - accuracy: 0.8243  \n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=30332)\u001b[0m  86/381 [=====>........................] - ETA: 0s - loss: 0.4411 - accuracy: 0.8130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-07-08 15:20:02,414 | server.py:182 | evaluate_round 2 received 5 results and 0 failures\n",
      "DEBUG flwr 2023-07-08 15:20:02,415 | server.py:218 | fit_round 3: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=15636)\u001b[0m Client  4 Evaluating complete... 0.8084547519683838 0.41579654812812805\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m Client  9 Training...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30560)\u001b[0m  23/381 [>.............................] - ETA: 0s - loss: 0.4124 - accuracy: 0.8003  \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 120/381 [========>.....................] - ETA: 0s - loss: 0.3934 - accuracy: 0.8189\u001b[32m [repeated 30x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m 155/381 [===========>..................] - ETA: 0s - loss: 0.4051 - accuracy: 0.8181\u001b[32m [repeated 33x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30560)\u001b[0m 373/381 [============================>.] - ETA: 0s - loss: 0.4068 - accuracy: 0.8161\u001b[32m [repeated 25x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28804)\u001b[0m 298/381 [======================>.......] - ETA: 0s - loss: 0.3998 - accuracy: 0.8189\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m 335/381 [=========================>....] - ETA: 0s - loss: 0.4069 - accuracy: 0.8162\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m Epoch 7/10\u001b[32m [repeated 61x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m \u001b[32m [repeated 763x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m   1/381 [..............................] - ETA: 0s - loss: 0.4004 - accuracy: 0.7812\u001b[32m [repeated 66x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m  30/381 [=>............................] - ETA: 0s - loss: 0.3946 - accuracy: 0.8219\u001b[32m [repeated 57x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30560)\u001b[0m  64/381 [====>.........................] - ETA: 0s - loss: 0.3919 - accuracy: 0.8198\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30560)\u001b[0m  95/381 [======>.......................] - ETA: 0s - loss: 0.3954 - accuracy: 0.8189\u001b[32m [repeated 42x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29032)\u001b[0m 128/381 [=========>....................] - ETA: 0s - loss: 0.3998 - accuracy: 0.8186\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28804)\u001b[0m  61/381 [===>..........................] - ETA: 0s - loss: 0.3888 - accuracy: 0.8289\u001b[32m [repeated 41x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29032)\u001b[0m 193/381 [==============>...............] - ETA: 0s - loss: 0.3959 - accuracy: 0.8204\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m 216/381 [================>.............] - ETA: 0s - loss: 0.4055 - accuracy: 0.8183\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=4504)\u001b[0m 241/381 [=================>............] - ETA: 0s - loss: 0.4065 - accuracy: 0.8187\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29032)\u001b[0m 256/381 [===================>..........] - ETA: 0s - loss: 0.4038 - accuracy: 0.8171\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m 315/381 [=======================>......] - ETA: 0s - loss: 0.4042 - accuracy: 0.8173\u001b[32m [repeated 29x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m 279/381 [====================>.........] - ETA: 0s - loss: 0.4027 - accuracy: 0.8180\u001b[32m [repeated 27x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m 381/381 [==============================] - 1s 1ms/step - loss: 0.4029 - accuracy: 0.8170\u001b[32m [repeated 56x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29032)\u001b[0m 320/381 [========================>.....] - ETA: 0s - loss: 0.4018 - accuracy: 0.8191\u001b[32m [repeated 23x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m 365/381 [===========================>..] - ETA: 0s - loss: 0.4074 - accuracy: 0.8150\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m 107/381 [=======>......................] - ETA: 0s - loss: 0.4034 - accuracy: 0.8213\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m 211/381 [===============>..............] - ETA: 0s - loss: 0.4091 - accuracy: 0.8169\u001b[32m [repeated 26x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m 142/381 [==========>...................] - ETA: 0s - loss: 0.4028 - accuracy: 0.8192\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m 245/381 [==================>...........] - ETA: 0s - loss: 0.4045 - accuracy: 0.8178\u001b[32m [repeated 35x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m 351/381 [==========================>...] - ETA: 0s - loss: 0.4038 - accuracy: 0.8173\u001b[32m [repeated 25x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m 185/381 [=============>................] - ETA: 0s - loss: 0.4054 - accuracy: 0.8177\u001b[32m [repeated 40x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m 177/381 [============>.................] - ETA: 0s - loss: 0.4062 - accuracy: 0.8181\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=4504)\u001b[0m 282/381 [=====================>........] - ETA: 0s - loss: 0.4020 - accuracy: 0.8188\u001b[32m [repeated 25x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m Client ID: 7\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=15636)\u001b[0m Client  4 Evaluating...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m  48/381 [==>...........................] - ETA: 0s - loss: 0.4066 - accuracy: 0.8148\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35088)\u001b[0m  87/381 [=====>........................] - ETA: 0s - loss: 0.4040 - accuracy: 0.8188\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28804)\u001b[0m Client  0 Evaluating complete... 0.8119844198226929 0.4167107939720154\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m Client  7 Training...\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=31244)\u001b[0m  25/381 [>.............................] - ETA: 0s - loss: 0.4612 - accuracy: 0.7831  \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m Client  8 Training complete...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-07-08 15:20:09,832 | server.py:232 | fit_round 3 received 10 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server Evaluating... 3\n",
      "7336/7336 [==============================] - 6s 865us/step - loss: 0.3982 - accuracy: 0.8268\n",
      "7336/7336 [==============================] - 6s 748us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2023-07-08 15:20:23,651 | server.py:119 | fit progress: (3, 0.39816784858703613, {'accuracy': 0.8267609477043152}, 71.29012159999911)\n",
      "DEBUG flwr 2023-07-08 15:20:23,652 | server.py:168 | evaluate_round 3: strategy sampled 5 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  [[6.7863448e-10 3.0206234e-08 1.6489545e-04 ... 4.6643465e-23\n",
      "  7.0273443e-18 6.4220189e-18]\n",
      " [1.1709427e-05 1.0378672e-06 5.0430581e-06 ... 2.0839840e-16\n",
      "  1.9394783e-11 1.6069036e-10]\n",
      " [4.1783910e-04 3.2134429e-07 1.4090330e-09 ... 4.5104390e-08\n",
      "  1.3465299e-07 1.4965204e-05]\n",
      " ...\n",
      " [1.0305804e-09 3.4934462e-08 2.0018978e-04 ... 1.6515766e-22\n",
      "  1.7830823e-17 1.7043391e-17]\n",
      " [4.3969706e-08 2.4642023e-07 7.2056041e-06 ... 2.4354147e-18\n",
      "  4.7482634e-14 5.6512369e-13]\n",
      " [4.5093507e-10 2.6594857e-09 9.9994791e-01 ... 2.0260952e-13\n",
      "  1.3623851e-13 9.9203198e-12]] (234745, 34)\n",
      "Server Evaluating complete... 0.8267609477043152 0.39816784858703613\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=4504)\u001b[0m 122/381 [========>.....................] - ETA: 0s - loss: 0.3823 - accuracy: 0.8229\u001b[32m [repeated 38x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m 161/381 [===========>..................] - ETA: 0s - loss: 0.3913 - accuracy: 0.8224\u001b[32m [repeated 23x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m 373/381 [============================>.] - ETA: 0s - loss: 0.3937 - accuracy: 0.8253\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m 299/381 [======================>.......] - ETA: 0s - loss: 0.3904 - accuracy: 0.8225\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m 342/381 [=========================>....] - ETA: 0s - loss: 0.3942 - accuracy: 0.8248\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m Epoch 10/10\u001b[32m [repeated 39x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m \u001b[32m [repeated 612x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m   1/381 [..............................] - ETA: 0s - loss: 0.5062 - accuracy: 0.7812\u001b[32m [repeated 39x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m  32/381 [=>............................] - ETA: 0s - loss: 0.4080 - accuracy: 0.8042\u001b[32m [repeated 40x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m  64/381 [====>.........................] - ETA: 0s - loss: 0.4028 - accuracy: 0.8135\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m  96/381 [======>.......................] - ETA: 0s - loss: 0.3937 - accuracy: 0.8210\u001b[32m [repeated 35x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m 128/381 [=========>....................] - ETA: 0s - loss: 0.3875 - accuracy: 0.8258\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28804)\u001b[0m  60/381 [===>..........................] - ETA: 0s - loss: 0.3915 - accuracy: 0.8193\u001b[32m [repeated 28x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m 192/381 [==============>...............] - ETA: 0s - loss: 0.3908 - accuracy: 0.8221\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m 226/381 [================>.............] - ETA: 0s - loss: 0.3900 - accuracy: 0.8222\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35088)\u001b[0m 238/381 [=================>............] - ETA: 0s - loss: 0.3935 - accuracy: 0.8237\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m 261/381 [===================>..........] - ETA: 0s - loss: 0.3898 - accuracy: 0.8229\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m 316/381 [=======================>......] - ETA: 0s - loss: 0.3917 - accuracy: 0.8213\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m 279/381 [====================>.........] - ETA: 0s - loss: 0.3946 - accuracy: 0.8244\u001b[32m [repeated 26x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m 381/381 [==============================] - 1s 1ms/step - loss: 0.3895 - accuracy: 0.8238\u001b[32m [repeated 49x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=4504)\u001b[0m 320/381 [========================>.....] - ETA: 0s - loss: 0.3831 - accuracy: 0.8278\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=4504)\u001b[0m 363/381 [===========================>..] - ETA: 0s - loss: 0.3834 - accuracy: 0.8280\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m 106/381 [=======>......................] - ETA: 0s - loss: 0.3863 - accuracy: 0.8236\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m 214/381 [===============>..............] - ETA: 0s - loss: 0.3929 - accuracy: 0.8262\u001b[32m [repeated 27x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m 152/381 [==========>...................] - ETA: 0s - loss: 0.3902 - accuracy: 0.8275\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=4504)\u001b[0m 249/381 [==================>...........] - ETA: 0s - loss: 0.3854 - accuracy: 0.8250\u001b[32m [repeated 27x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m 343/381 [==========================>...] - ETA: 0s - loss: 0.3888 - accuracy: 0.8238\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=4504)\u001b[0m 186/381 [=============>................] - ETA: 0s - loss: 0.3866 - accuracy: 0.8233\u001b[32m [repeated 34x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m 175/381 [============>.................] - ETA: 0s - loss: 0.3865 - accuracy: 0.8226\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28804)\u001b[0m 284/381 [=====================>........] - ETA: 0s - loss: 0.3857 - accuracy: 0.8281\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=35088)\u001b[0m Client ID: 6\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35088)\u001b[0m  86/381 [=====>........................] - ETA: 0s - loss: 0.3947 - accuracy: 0.8259\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m Client  7 Training complete...\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=4504)\u001b[0m Client ID: 3\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=35088)\u001b[0m Client  6 Evaluating...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=35088)\u001b[0m  50/381 [==>...........................] - ETA: 0s - loss: 0.4056 - accuracy: 0.8194  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-07-08 15:20:24,446 | server.py:182 | evaluate_round 3 received 5 results and 0 failures\n",
      "DEBUG flwr 2023-07-08 15:20:24,447 | server.py:218 | fit_round 4: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=35088)\u001b[0m Client  6 Evaluating complete... 0.8181408047676086 0.40149521827697754\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m Client  4 Training...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35088)\u001b[0m 381/381 [==============================] - ETA: 0s - loss: 0.4055 - accuracy: 0.8205\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35088)\u001b[0m  19/381 [>.............................] - ETA: 1s - loss: 0.3983 - accuracy: 0.8215\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29032)\u001b[0m 123/381 [========>.....................] - ETA: 0s - loss: 0.3876 - accuracy: 0.8281\u001b[32m [repeated 27x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m 155/381 [===========>..................] - ETA: 0s - loss: 0.3706 - accuracy: 0.8420\u001b[32m [repeated 30x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28804)\u001b[0m 370/381 [============================>.] - ETA: 0s - loss: 0.3743 - accuracy: 0.8357\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30560)\u001b[0m 294/381 [======================>.......] - ETA: 0s - loss: 0.3845 - accuracy: 0.8308\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m 337/381 [=========================>....] - ETA: 0s - loss: 0.3720 - accuracy: 0.8410\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m Epoch 6/10\u001b[32m [repeated 57x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m \u001b[32m [repeated 643x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m   1/381 [..............................] - ETA: 0s - loss: 0.4009 - accuracy: 0.8438\u001b[32m [repeated 62x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m  32/381 [=>............................] - ETA: 0s - loss: 0.3942 - accuracy: 0.8198\u001b[32m [repeated 49x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29032)\u001b[0m  64/381 [====>.........................] - ETA: 0s - loss: 0.3882 - accuracy: 0.8298\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29032)\u001b[0m  92/381 [======>.......................] - ETA: 0s - loss: 0.3911 - accuracy: 0.8280\u001b[32m [repeated 41x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m 137/381 [=========>....................] - ETA: 0s - loss: 0.3657 - accuracy: 0.8426\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30560)\u001b[0m  58/381 [===>..........................] - ETA: 0s - loss: 0.3830 - accuracy: 0.8273\u001b[32m [repeated 30x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 193/381 [==============>...............] - ETA: 0s - loss: 0.3789 - accuracy: 0.8326\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m 217/381 [================>.............] - ETA: 0s - loss: 0.3720 - accuracy: 0.8415\u001b[32m [repeated 28x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30560)\u001b[0m 229/381 [=================>............] - ETA: 0s - loss: 0.3832 - accuracy: 0.8317\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 256/381 [===================>..........] - ETA: 0s - loss: 0.3818 - accuracy: 0.8336\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m 305/381 [=======================>......] - ETA: 0s - loss: 0.3690 - accuracy: 0.8417\u001b[32m [repeated 26x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m 277/381 [====================>.........] - ETA: 0s - loss: 0.3699 - accuracy: 0.8421\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 381/381 [==============================] - 1s 2ms/step - loss: 0.3817 - accuracy: 0.8337\u001b[32m [repeated 52x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m 323/381 [========================>.....] - ETA: 0s - loss: 0.3906 - accuracy: 0.8268\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30560)\u001b[0m 360/381 [===========================>..] - ETA: 0s - loss: 0.3794 - accuracy: 0.8338\u001b[32m [repeated 23x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30560)\u001b[0m 102/381 [=======>......................] - ETA: 0s - loss: 0.3818 - accuracy: 0.8309\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m 211/381 [===============>..............] - ETA: 0s - loss: 0.3655 - accuracy: 0.8415\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m 141/381 [==========>...................] - ETA: 0s - loss: 0.3822 - accuracy: 0.8334\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28804)\u001b[0m 248/381 [==================>...........] - ETA: 0s - loss: 0.3759 - accuracy: 0.8345\u001b[32m [repeated 26x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m 353/381 [==========================>...] - ETA: 0s - loss: 0.3735 - accuracy: 0.8388\u001b[32m [repeated 23x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m 186/381 [=============>................] - ETA: 0s - loss: 0.3700 - accuracy: 0.8423\u001b[32m [repeated 30x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m 173/381 [============>.................] - ETA: 0s - loss: 0.3648 - accuracy: 0.8432\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m 283/381 [=====================>........] - ETA: 0s - loss: 0.3696 - accuracy: 0.8403\u001b[32m [repeated 27x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m  88/381 [=====>........................] - ETA: 0s - loss: 0.4091 - accuracy: 0.8239\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29032)\u001b[0m Client ID: 7\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=15636)\u001b[0m Client  0 Evaluating...\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m  47/381 [==>...........................] - ETA: 0s - loss: 0.3995 - accuracy: 0.8148\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=15636)\u001b[0m Client  0 Evaluating complete... 0.8258978128433228 0.39433979988098145\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29032)\u001b[0m Client  7 Training...\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28804)\u001b[0m  24/381 [>.............................] - ETA: 0s - loss: 0.3798 - accuracy: 0.8366\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m Client  3 Training complete...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-07-08 15:20:32,085 | server.py:232 | fit_round 4 received 10 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server Evaluating... 4\n",
      "7336/7336 [==============================] - 6s 863us/step - loss: 0.3731 - accuracy: 0.8544\n",
      "7336/7336 [==============================] - 5s 741us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2023-07-08 15:20:45,849 | server.py:119 | fit progress: (4, 0.37313494086265564, {'accuracy': 0.854365348815918}, 93.48900349999894)\n",
      "DEBUG flwr 2023-07-08 15:20:45,850 | server.py:168 | evaluate_round 4: strategy sampled 5 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  [[1.35224376e-09 6.78131462e-09 1.51017448e-04 ... 1.44328404e-26\n",
      "  4.77140589e-20 1.03937984e-19]\n",
      " [3.40429574e-06 1.77494712e-07 8.35075298e-07 ... 4.86155089e-21\n",
      "  3.48980115e-14 1.74684553e-13]\n",
      " [4.30334214e-04 2.04459397e-07 3.09195913e-09 ... 1.00850297e-08\n",
      "  9.88633175e-08 1.22909914e-05]\n",
      " ...\n",
      " [2.32063280e-09 8.61256577e-09 2.57728389e-04 ... 1.31999824e-25\n",
      "  2.09210430e-19 5.65709183e-19]\n",
      " [1.87779801e-08 7.92558836e-08 1.00235798e-06 ... 2.02722823e-21\n",
      "  7.18933243e-16 1.22086374e-14]\n",
      " [1.08469839e-11 1.47164156e-11 9.99940038e-01 ... 7.74266411e-16\n",
      "  3.90765918e-16 6.16185705e-14]] (234745, 34)\n",
      "Server Evaluating complete... 0.854365348815918 0.37313494086265564\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m 120/381 [========>.....................] - ETA: 0s - loss: 0.3654 - accuracy: 0.8461\u001b[32m [repeated 33x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28804)\u001b[0m 153/381 [===========>..................] - ETA: 0s - loss: 0.3557 - accuracy: 0.8538\u001b[32m [repeated 28x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m 369/381 [============================>.] - ETA: 0s - loss: 0.3724 - accuracy: 0.8404\u001b[32m [repeated 23x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28804)\u001b[0m 301/381 [======================>.......] - ETA: 0s - loss: 0.3582 - accuracy: 0.8486\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m 339/381 [=========================>....] - ETA: 0s - loss: 0.3725 - accuracy: 0.8402\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29032)\u001b[0m Epoch 10/10\u001b[32m [repeated 43x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29032)\u001b[0m \u001b[32m [repeated 635x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29032)\u001b[0m   1/381 [..............................] - ETA: 0s - loss: 0.3093 - accuracy: 0.9219\u001b[32m [repeated 43x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29032)\u001b[0m  35/381 [=>............................] - ETA: 0s - loss: 0.3470 - accuracy: 0.8571\u001b[32m [repeated 46x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29032)\u001b[0m  67/381 [====>.........................] - ETA: 0s - loss: 0.3738 - accuracy: 0.8414\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29032)\u001b[0m  99/381 [======>.......................] - ETA: 0s - loss: 0.3680 - accuracy: 0.8425\u001b[32m [repeated 37x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29032)\u001b[0m 130/381 [=========>....................] - ETA: 0s - loss: 0.3677 - accuracy: 0.8427\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m  60/381 [===>..........................] - ETA: 0s - loss: 0.3692 - accuracy: 0.8430\u001b[32m [repeated 31x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=31244)\u001b[0m 191/381 [==============>...............] - ETA: 0s - loss: 0.3775 - accuracy: 0.8375\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35088)\u001b[0m 217/381 [================>.............] - ETA: 0s - loss: 0.3644 - accuracy: 0.8481\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 240/381 [=================>............] - ETA: 0s - loss: 0.3615 - accuracy: 0.8465\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 266/381 [===================>..........] - ETA: 0s - loss: 0.3592 - accuracy: 0.8486\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29032)\u001b[0m 305/381 [=======================>......] - ETA: 0s - loss: 0.3669 - accuracy: 0.8448\u001b[32m [repeated 37x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28804)\u001b[0m 274/381 [====================>.........] - ETA: 0s - loss: 0.3541 - accuracy: 0.8526\u001b[32m [repeated 28x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29032)\u001b[0m 381/381 [==============================] - 0s 1ms/step - loss: 0.3658 - accuracy: 0.8460\u001b[32m [repeated 53x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28804)\u001b[0m 329/381 [========================>.....] - ETA: 0s - loss: 0.3577 - accuracy: 0.8493\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29032)\u001b[0m 357/381 [===========================>..] - ETA: 0s - loss: 0.3655 - accuracy: 0.8456\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m 106/381 [=======>......................] - ETA: 0s - loss: 0.3500 - accuracy: 0.8495\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29032)\u001b[0m 208/381 [===============>..............] - ETA: 0s - loss: 0.3666 - accuracy: 0.8466\u001b[32m [repeated 30x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m 152/381 [==========>...................] - ETA: 0s - loss: 0.3587 - accuracy: 0.8488\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29032)\u001b[0m 252/381 [==================>...........] - ETA: 0s - loss: 0.3665 - accuracy: 0.8457\u001b[32m [repeated 32x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28804)\u001b[0m 349/381 [==========================>...] - ETA: 0s - loss: 0.3517 - accuracy: 0.8544\u001b[32m [repeated 27x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m 185/381 [=============>................] - ETA: 0s - loss: 0.3591 - accuracy: 0.8500\u001b[32m [repeated 34x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29032)\u001b[0m 168/381 [============>.................] - ETA: 0s - loss: 0.3674 - accuracy: 0.8456\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35088)\u001b[0m 281/381 [=====================>........] - ETA: 0s - loss: 0.3625 - accuracy: 0.8493\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=4504)\u001b[0m  88/381 [=====>........................] - ETA: 0s - loss: 0.3588 - accuracy: 0.8493\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=29032)\u001b[0m Client ID: 6\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29032)\u001b[0m Client  7 Training complete...\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=30332)\u001b[0m Client ID: 5\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=27348)\u001b[0m Client  3 Evaluating...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=27348)\u001b[0m  47/381 [==>...........................] - ETA: 0s - loss: 0.3558 - accuracy: 0.8584  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-07-08 15:20:46,952 | server.py:182 | evaluate_round 4 received 5 results and 0 failures\n",
      "DEBUG flwr 2023-07-08 15:20:46,953 | server.py:218 | fit_round 5: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=27348)\u001b[0m Client  3 Evaluating complete... 0.8576236367225647 0.3757532835006714\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m Client  2 Training...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35088)\u001b[0m  14/381 [>.............................] - ETA: 1s - loss: 0.3316 - accuracy: 0.8672\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=4504)\u001b[0m 125/381 [========>.....................] - ETA: 0s - loss: 0.3561 - accuracy: 0.8536\u001b[32m [repeated 29x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=31244)\u001b[0m 159/381 [===========>..................] - ETA: 0s - loss: 0.3597 - accuracy: 0.8550\u001b[32m [repeated 30x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=31244)\u001b[0m 376/381 [============================>.] - ETA: 0s - loss: 0.3645 - accuracy: 0.8511\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m 301/381 [======================>.......] - ETA: 0s - loss: 0.3633 - accuracy: 0.8519\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m 331/381 [=========================>....] - ETA: 0s - loss: 0.3628 - accuracy: 0.8522\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m Epoch 6/10\u001b[32m [repeated 51x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29032)\u001b[0m \u001b[32m [repeated 627x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m   1/381 [..............................] - ETA: 0s - loss: 0.4590 - accuracy: 0.7812\u001b[32m [repeated 56x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m  31/381 [=>............................] - ETA: 0s - loss: 0.3667 - accuracy: 0.8488\u001b[32m [repeated 45x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=4504)\u001b[0m  64/381 [====>.........................] - ETA: 0s - loss: 0.3593 - accuracy: 0.8533\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m  91/381 [======>.......................] - ETA: 0s - loss: 0.3631 - accuracy: 0.8458\u001b[32m [repeated 41x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=31244)\u001b[0m 127/381 [=========>....................] - ETA: 0s - loss: 0.3490 - accuracy: 0.8570\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m  62/381 [===>..........................] - ETA: 0s - loss: 0.3654 - accuracy: 0.8470\u001b[32m [repeated 29x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29032)\u001b[0m 193/381 [==============>...............] - ETA: 0s - loss: 0.3504 - accuracy: 0.8531\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=4504)\u001b[0m 217/381 [================>.............] - ETA: 0s - loss: 0.3636 - accuracy: 0.8515\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m 240/381 [=================>............] - ETA: 0s - loss: 0.3688 - accuracy: 0.8505\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29032)\u001b[0m 256/381 [===================>..........] - ETA: 0s - loss: 0.3474 - accuracy: 0.8560\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m 316/381 [=======================>......] - ETA: 0s - loss: 0.3527 - accuracy: 0.8542\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m 271/381 [====================>.........] - ETA: 0s - loss: 0.3652 - accuracy: 0.8518\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m 381/381 [==============================] - 1s 1ms/step - loss: 0.3528 - accuracy: 0.8553\u001b[32m [repeated 46x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29032)\u001b[0m 321/381 [========================>.....] - ETA: 0s - loss: 0.3465 - accuracy: 0.8560\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m 362/381 [===========================>..] - ETA: 0s - loss: 0.3635 - accuracy: 0.8515\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m 104/381 [=======>......................] - ETA: 0s - loss: 0.3530 - accuracy: 0.8538\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m 211/381 [===============>..............] - ETA: 0s - loss: 0.3556 - accuracy: 0.8535\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28804)\u001b[0m 151/381 [==========>...................] - ETA: 0s - loss: 0.3481 - accuracy: 0.8598\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m 246/381 [==================>...........] - ETA: 0s - loss: 0.3553 - accuracy: 0.8535\u001b[32m [repeated 34x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m 353/381 [==========================>...] - ETA: 0s - loss: 0.3533 - accuracy: 0.8549\u001b[32m [repeated 27x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29032)\u001b[0m 188/381 [=============>................] - ETA: 0s - loss: 0.3456 - accuracy: 0.8598\u001b[32m [repeated 34x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m 176/381 [============>.................] - ETA: 0s - loss: 0.3558 - accuracy: 0.8532\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m 281/381 [=====================>........] - ETA: 0s - loss: 0.3545 - accuracy: 0.8531\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m  88/381 [=====>........................] - ETA: 0s - loss: 0.3751 - accuracy: 0.8413\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m Client ID: 4\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m 381/381 [==============================] - ETA: 0s - loss: 0.3648 - accuracy: 0.8460\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28804)\u001b[0m Client  8 Evaluating...\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28804)\u001b[0m  50/381 [==>...........................] - ETA: 0s - loss: 0.3641 - accuracy: 0.8447\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28804)\u001b[0m Client  8 Evaluating complete... 0.8521239757537842 0.3749291002750397\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m Client  7 Training...\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m Client  4 Training complete...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m  25/381 [>.............................] - ETA: 0s - loss: 0.3515 - accuracy: 0.8500\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-07-08 15:20:54,518 | server.py:232 | fit_round 5 received 10 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server Evaluating... 5\n",
      "7336/7336 [==============================] - 7s 901us/step - loss: 0.3565 - accuracy: 0.8565\n",
      "7336/7336 [==============================] - 5s 739us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2023-07-08 15:21:08,551 | server.py:119 | fit progress: (5, 0.35645580291748047, {'accuracy': 0.8565294146537781}, 116.19071600000098)\n",
      "DEBUG flwr 2023-07-08 15:21:08,553 | server.py:168 | evaluate_round 5: strategy sampled 5 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  [[4.05709910e-09 3.94973698e-09 1.53901681e-04 ... 5.77764719e-29\n",
      "  9.12846514e-22 3.85422383e-21]\n",
      " [8.19226614e-07 1.91035294e-08 1.45033539e-07 ... 8.44585744e-25\n",
      "  4.38904845e-17 1.93676797e-16]\n",
      " [2.34643870e-04 4.98196506e-08 6.75602463e-10 ... 1.56078137e-10\n",
      "  1.47620955e-08 4.30186810e-06]\n",
      " ...\n",
      " [6.09000628e-09 4.36791536e-09 3.42802930e-04 ... 9.69790949e-28\n",
      "  5.02305750e-21 3.44720250e-20]\n",
      " [6.79168366e-09 1.59391096e-08 6.49586980e-08 ... 2.75888758e-24\n",
      "  4.85453400e-18 8.82493585e-17]\n",
      " [8.08648612e-13 4.60620474e-13 9.99983311e-01 ... 9.58077891e-18\n",
      "  1.28766677e-17 1.49905265e-15]] (234745, 34)\n",
      "Server Evaluating complete... 0.8565294146537781 0.35645580291748047\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28804)\u001b[0m 125/381 [========>.....................] - ETA: 0s - loss: 0.3274 - accuracy: 0.8692\u001b[32m [repeated 27x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m 156/381 [===========>..................] - ETA: 0s - loss: 0.3493 - accuracy: 0.8585\u001b[32m [repeated 32x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m 374/381 [============================>.] - ETA: 0s - loss: 0.3419 - accuracy: 0.8604\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=31244)\u001b[0m 293/381 [======================>.......] - ETA: 0s - loss: 0.3434 - accuracy: 0.8558\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m 342/381 [=========================>....] - ETA: 0s - loss: 0.3423 - accuracy: 0.8573\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m Epoch 10/10\u001b[32m [repeated 49x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m \u001b[32m [repeated 742x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m   1/381 [..............................] - ETA: 0s - loss: 0.2801 - accuracy: 0.9062\u001b[32m [repeated 49x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m  34/381 [=>............................] - ETA: 0s - loss: 0.3597 - accuracy: 0.8497\u001b[32m [repeated 50x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m  66/381 [====>.........................] - ETA: 0s - loss: 0.3444 - accuracy: 0.8539\u001b[32m [repeated 23x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m  98/381 [======>.......................] - ETA: 0s - loss: 0.3530 - accuracy: 0.8530\u001b[32m [repeated 38x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m 129/381 [=========>....................] - ETA: 0s - loss: 0.3504 - accuracy: 0.8568\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28804)\u001b[0m  62/381 [===>..........................] - ETA: 0s - loss: 0.3334 - accuracy: 0.8632\u001b[32m [repeated 27x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m 191/381 [==============>...............] - ETA: 0s - loss: 0.3431 - accuracy: 0.8550\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m 217/381 [================>.............] - ETA: 0s - loss: 0.3509 - accuracy: 0.8558\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 229/381 [=================>............] - ETA: 0s - loss: 0.3246 - accuracy: 0.8659\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 259/381 [===================>..........] - ETA: 0s - loss: 0.3235 - accuracy: 0.8662\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28804)\u001b[0m 312/381 [=======================>......] - ETA: 0s - loss: 0.3334 - accuracy: 0.8634\u001b[32m [repeated 28x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28804)\u001b[0m 275/381 [====================>.........] - ETA: 0s - loss: 0.3314 - accuracy: 0.8636\u001b[32m [repeated 28x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m 381/381 [==============================] - 1s 1ms/step - loss: 0.3412 - accuracy: 0.8604\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m 329/381 [========================>.....] - ETA: 0s - loss: 0.3405 - accuracy: 0.8606\u001b[32m [repeated 26x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=31244)\u001b[0m 356/381 [===========================>..] - ETA: 0s - loss: 0.3442 - accuracy: 0.8556\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30560)\u001b[0m 103/381 [=======>......................] - ETA: 0s - loss: 0.3279 - accuracy: 0.8662\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28804)\u001b[0m 212/381 [===============>..............] - ETA: 0s - loss: 0.3331 - accuracy: 0.8642\u001b[32m [repeated 29x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=4504)\u001b[0m 152/381 [==========>...................] - ETA: 0s - loss: 0.3412 - accuracy: 0.8571\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m 250/381 [==================>...........] - ETA: 0s - loss: 0.3458 - accuracy: 0.8589\u001b[32m [repeated 38x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28804)\u001b[0m 354/381 [==========================>...] - ETA: 0s - loss: 0.3342 - accuracy: 0.8638\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m 187/381 [=============>................] - ETA: 0s - loss: 0.3516 - accuracy: 0.8562\u001b[32m [repeated 32x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 167/381 [============>.................] - ETA: 0s - loss: 0.3284 - accuracy: 0.8629\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m 286/381 [=====================>........] - ETA: 0s - loss: 0.3435 - accuracy: 0.8595\u001b[32m [repeated 23x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28804)\u001b[0m  85/381 [=====>........................] - ETA: 0s - loss: 0.3437 - accuracy: 0.8577\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=15636)\u001b[0m Client  9 Evaluating...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=15636)\u001b[0m Client  9 Evaluating...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m Client  7 Training complete...\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=35088)\u001b[0m Client ID: 7\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=35088)\u001b[0m Client  7 Evaluating...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=15636)\u001b[0m Client  9 Evaluating complete... 0.8629535436630249 0.33012157678604126\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=35088)\u001b[0m  50/381 [==>...........................] - ETA: 0s - loss: 0.3505 - accuracy: 0.8587  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-07-08 15:21:09,623 | server.py:182 | evaluate_round 5 received 5 results and 0 failures\n",
      "DEBUG flwr 2023-07-08 15:21:09,624 | server.py:218 | fit_round 6: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=4504)\u001b[0m Client  5 Training...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=4504)\u001b[0m  23/381 [>.............................] - ETA: 0s - loss: 0.3342 - accuracy: 0.8546\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 381/381 [==============================] - ETA: 0s - loss: 0.3471 - accuracy: 0.8604\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 115/381 [========>.....................] - ETA: 0s - loss: 0.3305 - accuracy: 0.8610\u001b[32m [repeated 34x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30560)\u001b[0m 162/381 [===========>..................] - ETA: 0s - loss: 0.3434 - accuracy: 0.8595\u001b[32m [repeated 25x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29032)\u001b[0m 376/381 [============================>.] - ETA: 0s - loss: 0.3309 - accuracy: 0.8640\u001b[32m [repeated 25x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m 302/381 [======================>.......] - ETA: 0s - loss: 0.3328 - accuracy: 0.8628\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m 334/381 [=========================>....] - ETA: 0s - loss: 0.3319 - accuracy: 0.8628\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30560)\u001b[0m Epoch 6/10\u001b[32m [repeated 54x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m \u001b[32m [repeated 706x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30560)\u001b[0m   1/381 [..............................] - ETA: 0s - loss: 0.3024 - accuracy: 0.8281\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=31244)\u001b[0m  34/381 [=>............................] - ETA: 0s - loss: 0.3510 - accuracy: 0.8506\u001b[32m [repeated 50x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m  68/381 [====>.........................] - ETA: 0s - loss: 0.2959 - accuracy: 0.8814\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m  89/381 [======>.......................] - ETA: 0s - loss: 0.3072 - accuracy: 0.8718\u001b[32m [repeated 35x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m 139/381 [=========>....................] - ETA: 0s - loss: 0.2984 - accuracy: 0.8806\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m  58/381 [===>..........................] - ETA: 0s - loss: 0.3320 - accuracy: 0.8588\u001b[32m [repeated 37x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m 203/381 [==============>...............] - ETA: 0s - loss: 0.3160 - accuracy: 0.8687\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30560)\u001b[0m 225/381 [================>.............] - ETA: 0s - loss: 0.3419 - accuracy: 0.8591\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 233/381 [=================>............] - ETA: 0s - loss: 0.3306 - accuracy: 0.8624\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 263/381 [===================>..........] - ETA: 0s - loss: 0.3337 - accuracy: 0.8629\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30560)\u001b[0m 317/381 [=======================>......] - ETA: 0s - loss: 0.3430 - accuracy: 0.8570\u001b[32m [repeated 28x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m 271/381 [====================>.........] - ETA: 0s - loss: 0.3358 - accuracy: 0.8616\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30560)\u001b[0m 381/381 [==============================] - 1s 2ms/step - loss: 0.3421 - accuracy: 0.8577\u001b[32m [repeated 49x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28804)\u001b[0m 328/381 [========================>.....] - ETA: 0s - loss: 0.3216 - accuracy: 0.8662\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=4504)\u001b[0m 362/381 [===========================>..] - ETA: 0s - loss: 0.3289 - accuracy: 0.8659\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m 103/381 [=======>......................] - ETA: 0s - loss: 0.2984 - accuracy: 0.8829\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m 212/381 [===============>..............] - ETA: 0s - loss: 0.3053 - accuracy: 0.8763\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 146/381 [==========>...................] - ETA: 0s - loss: 0.3277 - accuracy: 0.8603\u001b[32m [repeated 26x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m 248/381 [==================>...........] - ETA: 0s - loss: 0.3084 - accuracy: 0.8759\u001b[32m [repeated 25x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30560)\u001b[0m 347/381 [==========================>...] - ETA: 0s - loss: 0.3423 - accuracy: 0.8573\u001b[32m [repeated 28x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m 180/381 [=============>................] - ETA: 0s - loss: 0.3367 - accuracy: 0.8604\u001b[32m [repeated 27x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m 175/381 [============>.................] - ETA: 0s - loss: 0.3031 - accuracy: 0.8781\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m 291/381 [=====================>........] - ETA: 0s - loss: 0.3183 - accuracy: 0.8654\u001b[32m [repeated 28x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m  85/381 [=====>........................] - ETA: 0s - loss: 0.3291 - accuracy: 0.8625\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m Client ID: 1\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28804)\u001b[0m Client  4 Evaluating...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28804)\u001b[0m Client  4 Evaluating complete... 0.8554894328117371 0.3406476080417633\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=4504)\u001b[0m  49/381 [==>...........................] - ETA: 0s - loss: 0.3455 - accuracy: 0.8543\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m Client  1 Training...\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28804)\u001b[0m 218/381 [================>.............] - ETA: 0s - loss: 0.3217 - accuracy: 0.8654\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=31244)\u001b[0m Client  8 Training complete...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=4504)\u001b[0m Client  7 Training complete...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-07-08 15:21:20,872 | server.py:232 | fit_round 6 received 10 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m 122/381 [========>.....................] - ETA: 0s - loss: 0.3016 - accuracy: 0.8819\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m 154/381 [===========>..................] - ETA: 0s - loss: 0.3031 - accuracy: 0.8795\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35088)\u001b[0m 376/381 [============================>.] - ETA: 0s - loss: 0.3081 - accuracy: 0.8718\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35088)\u001b[0m 294/381 [======================>.......] - ETA: 0s - loss: 0.3127 - accuracy: 0.8704\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 335/381 [=========================>....] - ETA: 0s - loss: 0.3147 - accuracy: 0.8683\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m Epoch 10/10\u001b[32m [repeated 46x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m \u001b[32m [repeated 670x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m   1/381 [..............................] - ETA: 0s - loss: 0.2671 - accuracy: 0.8750\u001b[32m [repeated 46x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m  31/381 [=>............................] - ETA: 0s - loss: 0.3374 - accuracy: 0.8624\u001b[32m [repeated 48x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m  64/381 [====>.........................] - ETA: 0s - loss: 0.3026 - accuracy: 0.8811\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m  94/381 [======>.......................] - ETA: 0s - loss: 0.3203 - accuracy: 0.8657\u001b[32m [repeated 35x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 128/381 [=========>....................] - ETA: 0s - loss: 0.3173 - accuracy: 0.8677\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m  61/381 [===>..........................] - ETA: 0s - loss: 0.3254 - accuracy: 0.8632\u001b[32m [repeated 29x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=4504)\u001b[0m 192/381 [==============>...............] - ETA: 0s - loss: 0.3157 - accuracy: 0.8712\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m 227/381 [================>.............] - ETA: 0s - loss: 0.3047 - accuracy: 0.8771\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30560)\u001b[0m 230/381 [=================>............] - ETA: 0s - loss: 0.3213 - accuracy: 0.8668\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m 266/381 [===================>..........] - ETA: 0s - loss: 0.3034 - accuracy: 0.8775\u001b[32m [repeated 25x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m 306/381 [=======================>......] - ETA: 0s - loss: 0.3040 - accuracy: 0.8771\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35088)\u001b[0m 277/381 [====================>.........] - ETA: 0s - loss: 0.3144 - accuracy: 0.8708\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m 381/381 [==============================] - 1s 1ms/step - loss: 0.3029 - accuracy: 0.8772\u001b[32m [repeated 56x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28804)\u001b[0m 329/381 [========================>.....] - ETA: 0s - loss: 0.3063 - accuracy: 0.8729\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28804)\u001b[0m 368/381 [===========================>..] - ETA: 0s - loss: 0.3051 - accuracy: 0.8740\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m 108/381 [=======>......................] - ETA: 0s - loss: 0.2967 - accuracy: 0.8753\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 206/381 [===============>..............] - ETA: 0s - loss: 0.3134 - accuracy: 0.8698\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 152/381 [==========>...................] - ETA: 0s - loss: 0.3181 - accuracy: 0.8663\u001b[32m [repeated 23x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 244/381 [==================>...........] - ETA: 0s - loss: 0.3158 - accuracy: 0.8678\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m 347/381 [==========================>...] - ETA: 0s - loss: 0.3046 - accuracy: 0.8770\u001b[32m [repeated 31x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m 189/381 [=============>................] - ETA: 0s - loss: 0.3014 - accuracy: 0.8781\u001b[32m [repeated 25x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 166/381 [============>.................] - ETA: 0s - loss: 0.3167 - accuracy: 0.8678\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 286/381 [=====================>........] - ETA: 0s - loss: 0.3140 - accuracy: 0.8687\u001b[32m [repeated 32x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m  85/381 [=====>........................] - ETA: 0s - loss: 0.3122 - accuracy: 0.8662\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "Server Evaluating... 6\n",
      "7336/7336 [==============================] - 6s 862us/step - loss: 0.3364 - accuracy: 0.8717\n",
      "7336/7336 [==============================] - 5s 742us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2023-07-08 15:21:34,617 | server.py:119 | fit progress: (6, 0.3363931179046631, {'accuracy': 0.8717416524887085}, 142.256156200001)\n",
      "DEBUG flwr 2023-07-08 15:21:34,618 | server.py:168 | evaluate_round 6: strategy sampled 5 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  [[4.8314774e-09 4.2528154e-09 1.3078962e-04 ... 1.1070783e-30\n",
      "  1.4092331e-23 9.6079768e-23]\n",
      " [2.0521833e-07 3.5694312e-09 3.7912010e-08 ... 7.3922035e-28\n",
      "  7.0157459e-20 3.9677075e-19]\n",
      " [7.7358571e-05 2.9121805e-09 5.7117699e-11 ... 6.6030501e-14\n",
      "  2.7111016e-10 2.3470922e-07]\n",
      " ...\n",
      " [5.1285109e-09 3.5935506e-09 3.3422778e-04 ... 2.0643491e-29\n",
      "  7.1677505e-23 1.0010723e-21]\n",
      " [1.6457328e-09 5.2537330e-09 2.7595710e-09 ... 3.3705384e-27\n",
      "  1.2653048e-20 2.5158132e-19]\n",
      " [2.0678072e-13 5.0603283e-14 9.9999762e-01 ... 9.9970236e-19\n",
      "  1.5211112e-18 5.0393452e-16]] (234745, 34)\n",
      "Server Evaluating complete... 0.8717416524887085 0.3363931179046631\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=27348)\u001b[0m Client ID: 7\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=27348)\u001b[0m Client  7 Evaluating...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m Client  9 Training complete...\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=27348)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=27348)\u001b[0m   1/381 [..............................] - ETA: 1:01 - loss: 0.1598 - accuracy: 0.9375\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=27348)\u001b[0m  50/381 [==>...........................] - ETA: 0s - loss: 0.3257 - accuracy: 0.8681  \n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=27348)\u001b[0m  96/381 [======>.......................] - ETA: 0s - loss: 0.3226 - accuracy: 0.8647\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=27348)\u001b[0m 145/381 [==========>...................] - ETA: 0s - loss: 0.3202 - accuracy: 0.8672\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=27348)\u001b[0m 196/381 [==============>...............] - ETA: 0s - loss: 0.3150 - accuracy: 0.8684\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=27348)\u001b[0m 248/381 [==================>...........] - ETA: 0s - loss: 0.3172 - accuracy: 0.8689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-07-08 15:21:35,410 | server.py:182 | evaluate_round 6 received 5 results and 0 failures\n",
      "DEBUG flwr 2023-07-08 15:21:35,411 | server.py:218 | fit_round 7: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=27348)\u001b[0m 297/381 [======================>.......] - ETA: 0s - loss: 0.3163 - accuracy: 0.8690\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=27348)\u001b[0m 348/381 [==========================>...] - ETA: 0s - loss: 0.3204 - accuracy: 0.8681\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=27348)\u001b[0m 381/381 [==============================] - 1s 1ms/step - loss: 0.3222 - accuracy: 0.8673\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=27348)\u001b[0m Client  7 Evaluating complete... 0.8673096895217896 0.3221990764141083\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m Client  2 Training...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m Epoch 1/10\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m  30/381 [=>............................] - ETA: 0s - loss: 0.3066 - accuracy: 0.8729  \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m  24/381 [>.............................] - ETA: 0s - loss: 0.3202 - accuracy: 0.8743  \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29032)\u001b[0m  60/381 [===>..........................] - ETA: 0s - loss: 0.3173 - accuracy: 0.8714\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30560)\u001b[0m  64/381 [====>.........................] - ETA: 0s - loss: 0.3086 - accuracy: 0.8711\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m  79/381 [=====>........................] - ETA: 0s - loss: 0.3204 - accuracy: 0.8732\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m 104/381 [=======>......................] - ETA: 0s - loss: 0.3374 - accuracy: 0.8673\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29032)\u001b[0m 119/381 [========>.....................] - ETA: 0s - loss: 0.3193 - accuracy: 0.8682\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30560)\u001b[0m 157/381 [===========>..................] - ETA: 0s - loss: 0.3591 - accuracy: 0.8689\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m 135/381 [=========>....................] - ETA: 0s - loss: 0.3132 - accuracy: 0.8752\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m 176/381 [============>.................] - ETA: 0s - loss: 0.3307 - accuracy: 0.8650\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m 211/381 [===============>..............] - ETA: 0s - loss: 0.3260 - accuracy: 0.8669\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29032)\u001b[0m 181/381 [=============>................] - ETA: 0s - loss: 0.3182 - accuracy: 0.8676\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30560)\u001b[0m 223/381 [================>.............] - ETA: 0s - loss: 0.3537 - accuracy: 0.8697\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 236/381 [=================>............] - ETA: 0s - loss: 0.3252 - accuracy: 0.8719\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 269/381 [====================>.........] - ETA: 0s - loss: 0.3211 - accuracy: 0.8728\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m 280/381 [=====================>........] - ETA: 0s - loss: 0.3313 - accuracy: 0.8659\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m 319/381 [========================>.....] - ETA: 0s - loss: 0.3314 - accuracy: 0.8662\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29032)\u001b[0m 308/381 [=======================>......] - ETA: 0s - loss: 0.3258 - accuracy: 0.8674\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=31244)\u001b[0m 254/381 [===================>..........] - ETA: 0s - loss: 0.3185 - accuracy: 0.8732\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 361/381 [===========================>..] - ETA: 0s - loss: 0.3215 - accuracy: 0.8737\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29032)\u001b[0m 339/381 [=========================>....] - ETA: 0s - loss: 0.3252 - accuracy: 0.8671\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29032)\u001b[0m 370/381 [============================>.] - ETA: 0s - loss: 0.3219 - accuracy: 0.8684\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30560)\u001b[0m 381/381 [==============================] - ETA: 0s - loss: 0.3359 - accuracy: 0.8678\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29032)\u001b[0m 379/381 [============================>.] - ETA: 0s - loss: 0.3142 - accuracy: 0.8737\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=31244)\u001b[0m Client ID: 9\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=15636)\u001b[0m Client  1 Evaluating...\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=31244)\u001b[0m \u001b[32m [repeated 732x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m   1/381 [..............................] - ETA: 0s - loss: 0.5044 - accuracy: 0.7969\u001b[32m [repeated 65x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=6452)\u001b[0m  48/381 [==>...........................] - ETA: 0s - loss: 0.3277 - accuracy: 0.8600  \u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m  94/381 [======>.......................] - ETA: 0s - loss: 0.3146 - accuracy: 0.8775\u001b[32m [repeated 51x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m 142/381 [==========>...................] - ETA: 0s - loss: 0.3034 - accuracy: 0.8731\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35088)\u001b[0m 191/381 [==============>...............] - ETA: 0s - loss: 0.2997 - accuracy: 0.8775\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m 245/381 [==================>...........] - ETA: 0s - loss: 0.2992 - accuracy: 0.8765\u001b[32m [repeated 38x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m 296/381 [======================>.......] - ETA: 0s - loss: 0.3167 - accuracy: 0.8702\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m 349/381 [==========================>...] - ETA: 0s - loss: 0.2988 - accuracy: 0.8752\u001b[32m [repeated 38x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m 381/381 [==============================] - 1s 1ms/step - loss: 0.2973 - accuracy: 0.8764\u001b[32m [repeated 65x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=6452)\u001b[0m Client  4 Evaluating complete... 0.8664888143539429 0.3148588538169861\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=31244)\u001b[0m Client  9 Training...\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28804)\u001b[0m Epoch 8/10\u001b[32m [repeated 77x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m  34/381 [=>............................] - ETA: 0s - loss: 0.2661 - accuracy: 0.8869\u001b[32m [repeated 83x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29032)\u001b[0m  61/381 [===>..........................] - ETA: 0s - loss: 0.2781 - accuracy: 0.8865\u001b[32m [repeated 45x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m  72/381 [====>.........................] - ETA: 0s - loss: 0.2881 - accuracy: 0.8796\u001b[32m [repeated 38x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28804)\u001b[0m  87/381 [=====>........................] - ETA: 0s - loss: 0.2882 - accuracy: 0.8824\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m 106/381 [=======>......................] - ETA: 0s - loss: 0.2891 - accuracy: 0.8831\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29032)\u001b[0m 123/381 [========>.....................] - ETA: 0s - loss: 0.2823 - accuracy: 0.8838\u001b[32m [repeated 48x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29032)\u001b[0m 154/381 [===========>..................] - ETA: 0s - loss: 0.2845 - accuracy: 0.8851\u001b[32m [repeated 52x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m 139/381 [=========>....................] - ETA: 0s - loss: 0.3005 - accuracy: 0.8796\u001b[32m [repeated 27x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m 177/381 [============>.................] - ETA: 0s - loss: 0.2862 - accuracy: 0.8841\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29032)\u001b[0m 215/381 [===============>..............] - ETA: 0s - loss: 0.2848 - accuracy: 0.8852\u001b[32m [repeated 42x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29032)\u001b[0m 184/381 [=============>................] - ETA: 0s - loss: 0.2846 - accuracy: 0.8849\u001b[32m [repeated 51x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=31244)\u001b[0m 220/381 [================>.............] - ETA: 0s - loss: 0.2837 - accuracy: 0.8872\u001b[32m [repeated 39x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 238/381 [=================>............] - ETA: 0s - loss: 0.2868 - accuracy: 0.8839\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29032)\u001b[0m 278/381 [====================>.........] - ETA: 0s - loss: 0.2853 - accuracy: 0.8857\u001b[32m [repeated 39x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m 281/381 [=====================>........] - ETA: 0s - loss: 0.2900 - accuracy: 0.8838\u001b[32m [repeated 39x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m 324/381 [========================>.....] - ETA: 0s - loss: 0.2968 - accuracy: 0.8802\u001b[32m [repeated 28x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29032)\u001b[0m 308/381 [=======================>......] - ETA: 0s - loss: 0.2843 - accuracy: 0.8853\u001b[32m [repeated 46x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=31244)\u001b[0m 261/381 [===================>..........] - ETA: 0s - loss: 0.2866 - accuracy: 0.8851\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m Client  1 Training complete...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m 366/381 [===========================>..] - ETA: 0s - loss: 0.2986 - accuracy: 0.8791\u001b[32m [repeated 29x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35088)\u001b[0m 338/381 [=========================>....] - ETA: 0s - loss: 0.2909 - accuracy: 0.8838\u001b[32m [repeated 32x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29032)\u001b[0m 369/381 [============================>.] - ETA: 0s - loss: 0.2833 - accuracy: 0.8863\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29032)\u001b[0m 381/381 [==============================] - ETA: 0s - loss: 0.2799 - accuracy: 0.8870\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-07-08 15:21:42,935 | server.py:232 | fit_round 7 received 10 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server Evaluating... 7\n",
      "7336/7336 [==============================] - 6s 871us/step - loss: 0.3197 - accuracy: 0.8790\n",
      "7336/7336 [==============================] - 5s 736us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2023-07-08 15:21:56,751 | server.py:119 | fit progress: (7, 0.31970104575157166, {'accuracy': 0.8790432214736938}, 164.39051069999914)\n",
      "DEBUG flwr 2023-07-08 15:21:56,753 | server.py:168 | evaluate_round 7: strategy sampled 5 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  [[2.1471711e-09 2.5332547e-09 7.5898970e-05 ... 1.5317356e-32\n",
      "  1.0374603e-25 7.7910580e-25]\n",
      " [2.6025578e-08 7.0617795e-10 1.4312834e-08 ... 2.8992359e-30\n",
      "  1.0041609e-22 6.6571086e-22]\n",
      " [2.4942732e-05 8.8816399e-11 7.6135461e-12 ... 2.2093380e-16\n",
      "  3.0519851e-12 7.5283175e-09]\n",
      " ...\n",
      " [1.5760107e-09 1.6273572e-09 2.3481049e-04 ... 2.5103342e-31\n",
      "  4.5818535e-25 8.3664623e-24]\n",
      " [3.0534592e-10 1.1090947e-09 1.4163901e-10 ... 3.3803008e-30\n",
      "  1.6357542e-23 3.2360195e-22]\n",
      " [1.8025441e-13 3.0967860e-14 9.9999893e-01 ... 4.4322679e-19\n",
      "  5.9813342e-19 1.1704157e-15]] (234745, 34)\n",
      "Server Evaluating complete... 0.8790432214736938 0.31970104575157166\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=35088)\u001b[0m Client  1 Evaluating...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=35088)\u001b[0m Client  1 Evaluating...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m \u001b[32m [repeated 575x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m   1/381 [..............................] - ETA: 0s - loss: 0.2903 - accuracy: 0.8906\u001b[32m [repeated 39x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m  92/381 [======>.......................] - ETA: 0s - loss: 0.2911 - accuracy: 0.8818\u001b[32m [repeated 35x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m 150/381 [==========>...................] - ETA: 0s - loss: 0.2913 - accuracy: 0.8817\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29032)\u001b[0m 194/381 [==============>...............] - ETA: 0s - loss: 0.2784 - accuracy: 0.8868\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 242/381 [==================>...........] - ETA: 0s - loss: 0.2752 - accuracy: 0.8886\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m 300/381 [======================>.......] - ETA: 0s - loss: 0.2909 - accuracy: 0.8822\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28804)\u001b[0m 345/381 [==========================>...] - ETA: 0s - loss: 0.2908 - accuracy: 0.8846\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m 381/381 [==============================] - 1s 2ms/step - loss: 0.2867 - accuracy: 0.8847\u001b[32m [repeated 39x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m Epoch 10/10\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m  33/381 [=>............................] - ETA: 0s - loss: 0.2998 - accuracy: 0.8802\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m  62/381 [===>..........................] - ETA: 0s - loss: 0.2797 - accuracy: 0.8853\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m  64/381 [====>.........................] - ETA: 0s - loss: 0.2930 - accuracy: 0.8838\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m 121/381 [========>.....................] - ETA: 0s - loss: 0.2911 - accuracy: 0.8829\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35088)\u001b[0m 154/381 [===========>..................] - ETA: 0s - loss: 0.2787 - accuracy: 0.8842\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29032)\u001b[0m 132/381 [=========>....................] - ETA: 0s - loss: 0.2743 - accuracy: 0.8883\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m 177/381 [============>.................] - ETA: 0s - loss: 0.2892 - accuracy: 0.8806\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m 206/381 [===============>..............] - ETA: 0s - loss: 0.2901 - accuracy: 0.8821\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28804)\u001b[0m 180/381 [=============>................] - ETA: 0s - loss: 0.2939 - accuracy: 0.8839\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29032)\u001b[0m 225/381 [================>.............] - ETA: 0s - loss: 0.2786 - accuracy: 0.8869\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m 237/381 [=================>............] - ETA: 0s - loss: 0.2890 - accuracy: 0.8824\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m 271/381 [====================>.........] - ETA: 0s - loss: 0.2896 - accuracy: 0.8821\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29032)\u001b[0m 289/381 [=====================>........] - ETA: 0s - loss: 0.2788 - accuracy: 0.8879\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29032)\u001b[0m 320/381 [========================>.....] - ETA: 0s - loss: 0.2795 - accuracy: 0.8878\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28804)\u001b[0m 308/381 [=======================>......] - ETA: 0s - loss: 0.2919 - accuracy: 0.8834\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29032)\u001b[0m 256/381 [===================>..........] - ETA: 0s - loss: 0.2762 - accuracy: 0.8884\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m Client  4 Training complete...\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=31244)\u001b[0m 359/381 [===========================>..] - ETA: 0s - loss: 0.2756 - accuracy: 0.8901\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m 338/381 [=========================>....] - ETA: 0s - loss: 0.2908 - accuracy: 0.8821\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m 377/381 [============================>.] - ETA: 0s - loss: 0.2909 - accuracy: 0.8818\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=4504)\u001b[0m Client ID: 2\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=4504)\u001b[0m Client  2 Evaluating...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=35088)\u001b[0m  49/381 [==>...........................] - ETA: 0s - loss: 0.3070 - accuracy: 0.8893  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-07-08 15:21:57,777 | server.py:182 | evaluate_round 7 received 5 results and 0 failures\n",
      "DEBUG flwr 2023-07-08 15:21:57,777 | server.py:218 | fit_round 8: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=35088)\u001b[0m Client  1 Evaluating complete... 0.8867638111114502 0.29656198620796204\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35088)\u001b[0m Client  1 Training...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35088)\u001b[0m 106/381 [=======>......................] - ETA: 0s - loss: 0.3163 - accuracy: 0.8775\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m  85/381 [=====>........................] - ETA: 0s - loss: 0.2829 - accuracy: 0.8857\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m  25/381 [>.............................] - ETA: 0s - loss: 0.2482 - accuracy: 0.8931\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=4504)\u001b[0m 381/381 [==============================] - ETA: 0s - loss: 0.2785 - accuracy: 0.8904\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29032)\u001b[0m \u001b[32m [repeated 676x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m   1/381 [..............................] - ETA: 0s - loss: 0.5452 - accuracy: 0.9375\u001b[32m [repeated 62x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29032)\u001b[0m  97/381 [======>.......................] - ETA: 0s - loss: 0.2814 - accuracy: 0.8906\u001b[32m [repeated 44x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 152/381 [==========>...................] - ETA: 0s - loss: 0.2650 - accuracy: 0.8920\u001b[32m [repeated 28x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=31244)\u001b[0m 194/381 [==============>...............] - ETA: 0s - loss: 0.2794 - accuracy: 0.8891\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 244/381 [==================>...........] - ETA: 0s - loss: 0.2623 - accuracy: 0.8919\u001b[32m [repeated 28x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m 303/381 [======================>.......] - ETA: 0s - loss: 0.2939 - accuracy: 0.8885\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29032)\u001b[0m 348/381 [==========================>...] - ETA: 0s - loss: 0.2802 - accuracy: 0.8895\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m 381/381 [==============================] - 1s 1ms/step - loss: 0.2808 - accuracy: 0.8885\u001b[32m [repeated 52x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m Epoch 6/10\u001b[32m [repeated 57x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28804)\u001b[0m  32/381 [=>............................] - ETA: 0s - loss: 0.2678 - accuracy: 0.8955\u001b[32m [repeated 54x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m  62/381 [===>..........................] - ETA: 0s - loss: 0.3139 - accuracy: 0.8763\u001b[32m [repeated 31x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29032)\u001b[0m  65/381 [====>.........................] - ETA: 0s - loss: 0.2833 - accuracy: 0.8913\u001b[32m [repeated 26x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=4504)\u001b[0m 124/381 [========>.....................] - ETA: 0s - loss: 0.2653 - accuracy: 0.8960\u001b[32m [repeated 32x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30560)\u001b[0m 159/381 [===========>..................] - ETA: 0s - loss: 0.2863 - accuracy: 0.8846\u001b[32m [repeated 23x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=31244)\u001b[0m 129/381 [=========>....................] - ETA: 0s - loss: 0.2752 - accuracy: 0.8907\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m 168/381 [============>.................] - ETA: 0s - loss: 0.2970 - accuracy: 0.8852\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 214/381 [===============>..............] - ETA: 0s - loss: 0.2610 - accuracy: 0.8920\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 183/381 [=============>................] - ETA: 0s - loss: 0.2600 - accuracy: 0.8937\u001b[32m [repeated 25x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28804)\u001b[0m 217/381 [================>.............] - ETA: 0s - loss: 0.2696 - accuracy: 0.8908\u001b[32m [repeated 25x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m 236/381 [=================>............] - ETA: 0s - loss: 0.2887 - accuracy: 0.8863\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m 271/381 [====================>.........] - ETA: 0s - loss: 0.2878 - accuracy: 0.8874\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29032)\u001b[0m 286/381 [=====================>........] - ETA: 0s - loss: 0.2765 - accuracy: 0.8908\u001b[32m [repeated 31x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30560)\u001b[0m 318/381 [========================>.....] - ETA: 0s - loss: 0.2865 - accuracy: 0.8871\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m 305/381 [=======================>......] - ETA: 0s - loss: 0.2837 - accuracy: 0.8890\u001b[32m [repeated 27x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29032)\u001b[0m 254/381 [===================>..........] - ETA: 0s - loss: 0.2803 - accuracy: 0.8891\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 366/381 [===========================>..] - ETA: 0s - loss: 0.2689 - accuracy: 0.8916\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m 339/381 [=========================>....] - ETA: 0s - loss: 0.2815 - accuracy: 0.8894\u001b[32m [repeated 25x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m 373/381 [============================>.] - ETA: 0s - loss: 0.2818 - accuracy: 0.8884\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30560)\u001b[0m Client ID: 7\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=15636)\u001b[0m Client  5 Evaluating...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m  46/381 [==>...........................] - ETA: 0s - loss: 0.2559 - accuracy: 0.8954\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=15636)\u001b[0m Client  5 Evaluating complete... 0.8869690299034119 0.296282559633255\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30560)\u001b[0m Client  7 Training...\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m 103/381 [=======>......................] - ETA: 0s - loss: 0.2561 - accuracy: 0.8958\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m  87/381 [=====>........................] - ETA: 0s - loss: 0.2863 - accuracy: 0.8836\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m Client  4 Training complete...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-07-08 15:22:05,416 | server.py:232 | fit_round 8 received 10 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server Evaluating... 8\n",
      "7336/7336 [==============================] - 6s 865us/step - loss: 0.2996 - accuracy: 0.9016\n",
      "7336/7336 [==============================] - 5s 738us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2023-07-08 15:22:19,212 | server.py:119 | fit progress: (8, 0.2995775043964386, {'accuracy': 0.9015527367591858}, 186.85180830000172)\n",
      "DEBUG flwr 2023-07-08 15:22:19,213 | server.py:168 | evaluate_round 8: strategy sampled 5 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  [[7.7606294e-10 1.1249687e-09 5.8337995e-05 ... 5.9567602e-34\n",
      "  1.6543340e-27 1.7182227e-26]\n",
      " [1.9967286e-09 2.0895971e-10 9.7194484e-09 ... 1.5736840e-32\n",
      "  2.2379525e-25 2.3734906e-24]\n",
      " [4.0421373e-06 2.6712178e-12 3.0611531e-12 ... 8.3214282e-19\n",
      "  5.7008373e-14 2.0220123e-10]\n",
      " ...\n",
      " [2.9507707e-10 4.3906767e-10 2.0666704e-04 ... 4.4740042e-33\n",
      "  3.9073729e-27 1.1837898e-25]\n",
      " [1.9841361e-11 1.6444245e-10 1.0412516e-11 ... 1.5056272e-33\n",
      "  1.4530376e-26 4.0971725e-25]\n",
      " [4.5690735e-13 2.4084111e-14 9.9999952e-01 ... 2.5715600e-19\n",
      "  3.7794689e-19 1.7616339e-15]] (234745, 34)\n",
      "Server Evaluating complete... 0.9015527367591858 0.2995775043964386\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29032)\u001b[0m Client ID: 6\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30560)\u001b[0m \u001b[32m [repeated 658x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30560)\u001b[0m   1/381 [..............................] - ETA: 0s - loss: 0.3075 - accuracy: 0.8438\u001b[32m [repeated 43x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30560)\u001b[0m 101/381 [======>.......................] - ETA: 0s - loss: 0.2631 - accuracy: 0.8994\u001b[32m [repeated 36x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m 144/381 [==========>...................] - ETA: 0s - loss: 0.2586 - accuracy: 0.9038\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 192/381 [==============>...............] - ETA: 0s - loss: 0.2494 - accuracy: 0.9038\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28804)\u001b[0m 253/381 [==================>...........] - ETA: 0s - loss: 0.2484 - accuracy: 0.8988\u001b[32m [repeated 30x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30560)\u001b[0m 303/381 [======================>.......] - ETA: 0s - loss: 0.2679 - accuracy: 0.8955\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30560)\u001b[0m 350/381 [==========================>...] - ETA: 0s - loss: 0.2665 - accuracy: 0.8948\u001b[32m [repeated 25x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30560)\u001b[0m 381/381 [==============================] - 0s 1ms/step - loss: 0.2666 - accuracy: 0.8948\u001b[32m [repeated 53x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30560)\u001b[0m Epoch 10/10\u001b[32m [repeated 43x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30560)\u001b[0m  33/381 [=>............................] - ETA: 0s - loss: 0.2441 - accuracy: 0.9006\u001b[32m [repeated 45x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35088)\u001b[0m  62/381 [===>..........................] - ETA: 0s - loss: 0.2589 - accuracy: 0.8984\u001b[32m [repeated 26x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30560)\u001b[0m  67/381 [====>.........................] - ETA: 0s - loss: 0.2606 - accuracy: 0.8974\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 126/381 [========>.....................] - ETA: 0s - loss: 0.2493 - accuracy: 0.9040\u001b[32m [repeated 31x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 159/381 [===========>..................] - ETA: 0s - loss: 0.2488 - accuracy: 0.9046\u001b[32m [repeated 28x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30560)\u001b[0m 135/381 [=========>....................] - ETA: 0s - loss: 0.2649 - accuracy: 0.8957\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30560)\u001b[0m 171/381 [============>.................] - ETA: 0s - loss: 0.2714 - accuracy: 0.8943\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30560)\u001b[0m 210/381 [===============>..............] - ETA: 0s - loss: 0.2692 - accuracy: 0.8940\u001b[32m [repeated 27x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28804)\u001b[0m 189/381 [=============>................] - ETA: 0s - loss: 0.2475 - accuracy: 0.8985\u001b[32m [repeated 33x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 227/381 [================>.............] - ETA: 0s - loss: 0.2510 - accuracy: 0.9027\u001b[32m [repeated 25x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 239/381 [=================>............] - ETA: 0s - loss: 0.2562 - accuracy: 0.8995\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=4504)\u001b[0m 277/381 [====================>.........] - ETA: 0s - loss: 0.2535 - accuracy: 0.9024\u001b[32m [repeated 25x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28804)\u001b[0m 287/381 [=====================>........] - ETA: 0s - loss: 0.2492 - accuracy: 0.8994\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28804)\u001b[0m 321/381 [========================>.....] - ETA: 0s - loss: 0.2507 - accuracy: 0.8987\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=31244)\u001b[0m 306/381 [=======================>......] - ETA: 0s - loss: 0.2650 - accuracy: 0.8958\u001b[32m [repeated 30x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30560)\u001b[0m 255/381 [===================>..........] - ETA: 0s - loss: 0.2692 - accuracy: 0.8950\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28804)\u001b[0m 359/381 [===========================>..] - ETA: 0s - loss: 0.2501 - accuracy: 0.9001\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m 333/381 [=========================>....] - ETA: 0s - loss: 0.2645 - accuracy: 0.8955\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m 374/381 [============================>.] - ETA: 0s - loss: 0.2649 - accuracy: 0.8953\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=27348)\u001b[0m Client ID: 6\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m Client ID: 6\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30560)\u001b[0m Client  7 Training complete...\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=31244)\u001b[0m Client ID: 4\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=27348)\u001b[0m Client  6 Evaluating...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=27348)\u001b[0m  48/381 [==>...........................] - ETA: 0s - loss: 0.2757 - accuracy: 0.8867  \n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=30560)\u001b[0m 102/381 [=======>......................] - ETA: 0s - loss: 0.2571 - accuracy: 0.8960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-07-08 15:22:20,010 | server.py:182 | evaluate_round 8 received 5 results and 0 failures\n",
      "DEBUG flwr 2023-07-08 15:22:20,011 | server.py:218 | fit_round 9: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=27348)\u001b[0m Client  6 Evaluating complete... 0.8914015889167786 0.279056191444397\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=31244)\u001b[0m Client  9 Training...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30560)\u001b[0m  87/381 [=====>........................] - ETA: 0s - loss: 0.2844 - accuracy: 0.8928\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28804)\u001b[0m 381/381 [==============================] - ETA: 0s - loss: 0.2760 - accuracy: 0.8973\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m \u001b[32m [repeated 690x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=31244)\u001b[0m   1/381 [..............................] - ETA: 0s - loss: 0.3418 - accuracy: 0.8594\u001b[32m [repeated 57x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m  90/381 [======>.......................] - ETA: 0s - loss: 0.2590 - accuracy: 0.9017\u001b[32m [repeated 35x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28804)\u001b[0m 149/381 [==========>...................] - ETA: 0s - loss: 0.2524 - accuracy: 0.9001\u001b[32m [repeated 32x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m 203/381 [==============>...............] - ETA: 0s - loss: 0.2552 - accuracy: 0.9033\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 242/381 [==================>...........] - ETA: 0s - loss: 0.2651 - accuracy: 0.8979\u001b[32m [repeated 27x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28804)\u001b[0m 295/381 [======================>.......] - ETA: 0s - loss: 0.2668 - accuracy: 0.9009\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=31244)\u001b[0m 347/381 [==========================>...] - ETA: 0s - loss: 0.2402 - accuracy: 0.9108\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=31244)\u001b[0m 381/381 [==============================] - 1s 2ms/step - loss: 0.2422 - accuracy: 0.9104\u001b[32m [repeated 47x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=31244)\u001b[0m Epoch 6/10\u001b[32m [repeated 52x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m  34/381 [=>............................] - ETA: 0s - loss: 0.2265 - accuracy: 0.9062\u001b[32m [repeated 51x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28804)\u001b[0m  59/381 [===>..........................] - ETA: 0s - loss: 0.2611 - accuracy: 0.8967\u001b[32m [repeated 35x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m  69/381 [====>.........................] - ETA: 0s - loss: 0.2248 - accuracy: 0.9126\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28804)\u001b[0m 119/381 [========>.....................] - ETA: 0s - loss: 0.2515 - accuracy: 0.9013\u001b[32m [repeated 29x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 153/381 [===========>..................] - ETA: 0s - loss: 0.2632 - accuracy: 0.8975\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m 138/381 [=========>....................] - ETA: 0s - loss: 0.2415 - accuracy: 0.9053\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m 172/381 [============>.................] - ETA: 0s - loss: 0.2419 - accuracy: 0.9050\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m 208/381 [===============>..............] - ETA: 0s - loss: 0.2418 - accuracy: 0.9063\u001b[32m [repeated 26x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=4504)\u001b[0m 180/381 [=============>................] - ETA: 0s - loss: 0.2602 - accuracy: 0.9076\u001b[32m [repeated 26x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30560)\u001b[0m 218/381 [================>.............] - ETA: 0s - loss: 0.2441 - accuracy: 0.9089\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28804)\u001b[0m 233/381 [=================>............] - ETA: 0s - loss: 0.2679 - accuracy: 0.9002\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 271/381 [====================>.........] - ETA: 0s - loss: 0.2638 - accuracy: 0.8984\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=31244)\u001b[0m 286/381 [=====================>........] - ETA: 0s - loss: 0.2413 - accuracy: 0.9101\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28804)\u001b[0m 325/381 [========================>.....] - ETA: 0s - loss: 0.2644 - accuracy: 0.9007\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30560)\u001b[0m 309/381 [=======================>......] - ETA: 0s - loss: 0.2447 - accuracy: 0.9070\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m 264/381 [===================>..........] - ETA: 0s - loss: 0.2507 - accuracy: 0.9019\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 361/381 [===========================>..] - ETA: 0s - loss: 0.2671 - accuracy: 0.8985\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30560)\u001b[0m 340/381 [=========================>....] - ETA: 0s - loss: 0.2466 - accuracy: 0.9073\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=31244)\u001b[0m 377/381 [============================>.] - ETA: 0s - loss: 0.2406 - accuracy: 0.9110\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m Client ID: 1\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=15636)\u001b[0m Client  7 Evaluating...\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=31244)\u001b[0m  48/381 [==>...........................] - ETA: 0s - loss: 0.2743 - accuracy: 0.8919  \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m 102/381 [=======>......................] - ETA: 0s - loss: 0.2513 - accuracy: 0.9084\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=15636)\u001b[0m Client  7 Evaluating complete... 0.8945208191871643 0.27162835001945496\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m Client  5 Training...\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=31244)\u001b[0m  85/381 [=====>........................] - ETA: 0s - loss: 0.2199 - accuracy: 0.9165\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m Client  7 Training complete...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-07-08 15:22:27,708 | server.py:232 | fit_round 9 received 10 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server Evaluating... 9\n",
      "7336/7336 [==============================] - 7s 902us/step - loss: 0.2668 - accuracy: 0.9240\n",
      "7336/7336 [==============================] - 5s 736us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2023-07-08 15:22:41,735 | server.py:119 | fit progress: (9, 0.26678675413131714, {'accuracy': 0.9239813685417175}, 209.3748689999993)\n",
      "DEBUG flwr 2023-07-08 15:22:41,736 | server.py:168 | evaluate_round 9: strategy sampled 5 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  [[1.4877292e-10 8.2796753e-10 2.4245233e-05 ... 3.4145933e-35\n",
      "  1.7527058e-29 8.0765293e-29]\n",
      " [2.5827174e-10 1.1502479e-10 1.2408298e-08 ... 2.3175787e-34\n",
      "  9.6365157e-28 2.1574297e-26]\n",
      " [8.9835339e-07 1.7911924e-13 1.1704238e-12 ... 3.1985764e-21\n",
      "  8.1611704e-17 1.1363807e-11]\n",
      " ...\n",
      " [5.2621379e-11 2.8751831e-10 1.6645984e-04 ... 1.6199550e-34\n",
      "  3.0974611e-29 4.7600013e-28]\n",
      " [1.7706149e-12 6.1469864e-11 3.5642910e-12 ... 2.7647162e-36\n",
      "  1.9723587e-29 1.8100918e-27]\n",
      " [4.4729991e-13 1.6126747e-14 9.9999976e-01 ... 1.3975940e-20\n",
      "  4.8114030e-20 1.8075831e-16]] (234745, 34)\n",
      "Server Evaluating complete... 0.9239813685417175 0.26678675413131714\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=4504)\u001b[0m 381/381 [==============================] - ETA: 0s - loss: 0.2411 - accuracy: 0.9114\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m \u001b[32m [repeated 682x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m   1/381 [..............................] - ETA: 0s - loss: 0.1310 - accuracy: 0.9531\u001b[32m [repeated 48x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m  93/381 [======>.......................] - ETA: 0s - loss: 0.2360 - accuracy: 0.9118\u001b[32m [repeated 40x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35088)\u001b[0m 149/381 [==========>...................] - ETA: 0s - loss: 0.2261 - accuracy: 0.9138\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m 191/381 [==============>...............] - ETA: 0s - loss: 0.2420 - accuracy: 0.9088\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m 250/381 [==================>...........] - ETA: 0s - loss: 0.2318 - accuracy: 0.9111\u001b[32m [repeated 33x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28804)\u001b[0m 300/381 [======================>.......] - ETA: 0s - loss: 0.2270 - accuracy: 0.9161\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m 345/381 [==========================>...] - ETA: 0s - loss: 0.2354 - accuracy: 0.9106\u001b[32m [repeated 27x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m 381/381 [==============================] - 1s 1ms/step - loss: 0.2354 - accuracy: 0.9107\u001b[32m [repeated 58x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m Epoch 10/10\u001b[32m [repeated 48x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m  33/381 [=>............................] - ETA: 0s - loss: 0.2722 - accuracy: 0.9039\u001b[32m [repeated 49x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m  61/381 [===>..........................] - ETA: 0s - loss: 0.2465 - accuracy: 0.9086\u001b[32m [repeated 33x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m  64/381 [====>.........................] - ETA: 0s - loss: 0.2097 - accuracy: 0.9199\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m 125/381 [========>.....................] - ETA: 0s - loss: 0.2445 - accuracy: 0.9110\u001b[32m [repeated 35x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m 158/381 [===========>..................] - ETA: 0s - loss: 0.2428 - accuracy: 0.9100\u001b[32m [repeated 26x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m 129/381 [=========>....................] - ETA: 0s - loss: 0.2462 - accuracy: 0.9109\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30560)\u001b[0m 166/381 [============>.................] - ETA: 0s - loss: 0.2195 - accuracy: 0.9214\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=31244)\u001b[0m 204/381 [===============>..............] - ETA: 0s - loss: 0.2275 - accuracy: 0.9180\u001b[32m [repeated 28x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28804)\u001b[0m 188/381 [=============>................] - ETA: 0s - loss: 0.2257 - accuracy: 0.9164\u001b[32m [repeated 37x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m 228/381 [================>.............] - ETA: 0s - loss: 0.2432 - accuracy: 0.9093\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35088)\u001b[0m 231/381 [=================>............] - ETA: 0s - loss: 0.2183 - accuracy: 0.9211\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35088)\u001b[0m 267/381 [====================>.........] - ETA: 0s - loss: 0.2178 - accuracy: 0.9212\u001b[32m [repeated 26x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m 282/381 [=====================>........] - ETA: 0s - loss: 0.2379 - accuracy: 0.9108\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30560)\u001b[0m 328/381 [========================>.....] - ETA: 0s - loss: 0.2228 - accuracy: 0.9201\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35088)\u001b[0m 305/381 [=======================>......] - ETA: 0s - loss: 0.2191 - accuracy: 0.9204\u001b[32m [repeated 32x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m 265/381 [===================>..........] - ETA: 0s - loss: 0.2401 - accuracy: 0.9098\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30560)\u001b[0m 361/381 [===========================>..] - ETA: 0s - loss: 0.2233 - accuracy: 0.9196\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m 332/381 [=========================>....] - ETA: 0s - loss: 0.2196 - accuracy: 0.9176\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m 371/381 [============================>.] - ETA: 0s - loss: 0.2221 - accuracy: 0.9174\u001b[32m [repeated 29x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=35088)\u001b[0m Client ID: 8\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=31244)\u001b[0m 102/381 [=======>......................] - ETA: 0s - loss: 0.2168 - accuracy: 0.9202\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m Client  5 Training complete...\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=4504)\u001b[0m Client ID: 7\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=30332)\u001b[0m Client  9 Evaluating...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=4504)\u001b[0m  50/381 [==>...........................] - ETA: 0s - loss: 0.2483 - accuracy: 0.9291  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-07-08 15:22:42,531 | server.py:182 | evaluate_round 9 received 5 results and 0 failures\n",
      "DEBUG flwr 2023-07-08 15:22:42,532 | server.py:218 | fit_round 10: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=30332)\u001b[0m Client  9 Evaluating complete... 0.9281727075576782 0.21980679035186768\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=4504)\u001b[0m Client  8 Training...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m  83/381 [=====>........................] - ETA: 0s - loss: 0.2189 - accuracy: 0.9192\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35088)\u001b[0m  71/381 [====>.........................] - ETA: 0s - loss: 0.1780 - accuracy: 0.9397\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m \u001b[32m [repeated 748x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m   1/381 [..............................] - ETA: 0s - loss: 0.1029 - accuracy: 0.9844\u001b[32m [repeated 66x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m  93/381 [======>.......................] - ETA: 0s - loss: 0.2001 - accuracy: 0.9286\u001b[32m [repeated 50x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m 143/381 [==========>...................] - ETA: 0s - loss: 0.2077 - accuracy: 0.9281\u001b[32m [repeated 29x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29032)\u001b[0m 192/381 [==============>...............] - ETA: 0s - loss: 0.2128 - accuracy: 0.9285\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m 245/381 [==================>...........] - ETA: 0s - loss: 0.2149 - accuracy: 0.9246\u001b[32m [repeated 34x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m 302/381 [======================>.......] - ETA: 0s - loss: 0.2098 - accuracy: 0.9279\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m 351/381 [==========================>...] - ETA: 0s - loss: 0.2133 - accuracy: 0.9249\u001b[32m [repeated 28x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m 381/381 [==============================] - 1s 1ms/step - loss: 0.2126 - accuracy: 0.9254\u001b[32m [repeated 56x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m Epoch 7/10\u001b[32m [repeated 61x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m  37/381 [=>............................] - ETA: 0s - loss: 0.1816 - accuracy: 0.9388\u001b[32m [repeated 61x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m  63/381 [===>..........................] - ETA: 0s - loss: 0.1895 - accuracy: 0.9400\u001b[32m [repeated 38x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m  71/381 [====>.........................] - ETA: 0s - loss: 0.1780 - accuracy: 0.9397\u001b[32m [repeated 25x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m 126/381 [========>.....................] - ETA: 0s - loss: 0.2102 - accuracy: 0.9291\u001b[32m [repeated 33x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=4504)\u001b[0m 163/381 [===========>..................] - ETA: 0s - loss: 0.2030 - accuracy: 0.9302\u001b[32m [repeated 28x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28804)\u001b[0m 128/381 [=========>....................] - ETA: 0s - loss: 0.1983 - accuracy: 0.9292\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=31244)\u001b[0m 166/381 [============>.................] - ETA: 0s - loss: 0.1893 - accuracy: 0.9320\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m 209/381 [===============>..............] - ETA: 0s - loss: 0.2155 - accuracy: 0.9245\u001b[32m [repeated 28x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m 187/381 [=============>................] - ETA: 0s - loss: 0.2113 - accuracy: 0.9311\u001b[32m [repeated 35x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m 218/381 [================>.............] - ETA: 0s - loss: 0.2125 - accuracy: 0.9295\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m 241/381 [=================>............] - ETA: 0s - loss: 0.2063 - accuracy: 0.9272\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m 279/381 [====================>.........] - ETA: 0s - loss: 0.2140 - accuracy: 0.9246\u001b[32m [repeated 25x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m 280/381 [=====================>........] - ETA: 0s - loss: 0.2084 - accuracy: 0.9305\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29032)\u001b[0m 318/381 [========================>.....] - ETA: 0s - loss: 0.2106 - accuracy: 0.9302\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m 309/381 [=======================>......] - ETA: 0s - loss: 0.2122 - accuracy: 0.9312\u001b[32m [repeated 29x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29032)\u001b[0m 256/381 [===================>..........] - ETA: 0s - loss: 0.2118 - accuracy: 0.9291\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m 362/381 [===========================>..] - ETA: 0s - loss: 0.2129 - accuracy: 0.9282\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m 340/381 [=========================>....] - ETA: 0s - loss: 0.2137 - accuracy: 0.9307\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m 374/381 [============================>.] - ETA: 0s - loss: 0.2095 - accuracy: 0.9289\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m 106/381 [=======>......................] - ETA: 0s - loss: 0.2097 - accuracy: 0.9232\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30560)\u001b[0m Client ID: 7\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=15636)\u001b[0m Client  3 Evaluating...\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=15636)\u001b[0m  49/381 [==>...........................] - ETA: 0s - loss: 0.2139 - accuracy: 0.9276  \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=15636)\u001b[0m Client  3 Evaluating complete... 0.9260414242744446 0.26997092366218567\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m Client  5 Training...\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m 381/381 [==============================] - ETA: 0s - loss: 0.1987 - accuracy: 0.9369\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m  84/381 [=====>........................] - ETA: 0s - loss: 0.1836 - accuracy: 0.9436\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=6452)\u001b[0m Client  5 Training complete...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-07-08 15:22:49,844 | server.py:232 | fit_round 10 received 10 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server Evaluating... 10\n",
      "7336/7336 [==============================] - 6s 863us/step - loss: 0.2041 - accuracy: 0.9552\n",
      "7336/7336 [==============================] - 5s 735us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2023-07-08 15:23:03,594 | server.py:119 | fit progress: (10, 0.20413264632225037, {'accuracy': 0.9552195072174072}, 231.23347550000108)\n",
      "DEBUG flwr 2023-07-08 15:23:03,595 | server.py:168 | evaluate_round 10: strategy sampled 5 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  [[1.7080903e-11 2.2275586e-10 7.0441010e-06 ... 1.0163127e-36\n",
      "  1.0346972e-31 1.4476251e-31]\n",
      " [5.2131858e-11 9.6757075e-11 1.6702206e-08 ... 7.4794222e-36\n",
      "  1.3233827e-29 3.0075276e-28]\n",
      " [1.3724775e-07 1.1797741e-14 3.7588378e-14 ... 2.9015667e-24\n",
      "  1.0445218e-19 2.4682405e-13]\n",
      " ...\n",
      " [6.0257988e-12 1.1210903e-10 7.2082708e-05 ... 5.9792431e-36\n",
      "  2.1515374e-31 1.1070483e-30]\n",
      " [1.5991832e-13 2.4862657e-11 9.4986627e-13 ... 1.2295819e-38\n",
      "  6.4488143e-32 9.1913216e-30]\n",
      " [1.7147567e-13 7.3698566e-15 9.9999988e-01 ... 5.3699377e-23\n",
      "  1.8645592e-21 4.5314153e-18]] (234745, 34)\n",
      "Server Evaluating complete... 0.9552195072174072 0.20413264632225037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m \u001b[32m [repeated 611x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m   1/381 [..............................] - ETA: 0s - loss: 0.1469 - accuracy: 0.9375\u001b[32m [repeated 39x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m  97/381 [======>.......................] - ETA: 0s - loss: 0.1754 - accuracy: 0.9439\u001b[32m [repeated 31x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m 151/381 [==========>...................] - ETA: 0s - loss: 0.1938 - accuracy: 0.9429\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m 193/381 [==============>...............] - ETA: 0s - loss: 0.1820 - accuracy: 0.9505\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m 246/381 [==================>...........] - ETA: 0s - loss: 0.1836 - accuracy: 0.9437\u001b[32m [repeated 26x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m 297/381 [======================>.......] - ETA: 0s - loss: 0.1749 - accuracy: 0.9474\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35088)\u001b[0m 343/381 [==========================>...] - ETA: 0s - loss: 0.1662 - accuracy: 0.9464\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m 381/381 [==============================] - 1s 1ms/step - loss: 0.1739 - accuracy: 0.9466\u001b[32m [repeated 49x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m Epoch 10/10\u001b[32m [repeated 39x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m  34/381 [=>............................] - ETA: 0s - loss: 0.1495 - accuracy: 0.9504\u001b[32m [repeated 39x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m  62/381 [===>..........................] - ETA: 0s - loss: 0.1717 - accuracy: 0.9468\u001b[32m [repeated 23x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m  67/381 [====>.........................] - ETA: 0s - loss: 0.1964 - accuracy: 0.9452\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m 122/381 [========>.....................] - ETA: 0s - loss: 0.1764 - accuracy: 0.9456\u001b[32m [repeated 23x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m 162/381 [===========>..................] - ETA: 0s - loss: 0.1729 - accuracy: 0.9483\u001b[32m [repeated 26x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m 130/381 [=========>....................] - ETA: 0s - loss: 0.1872 - accuracy: 0.9486\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29032)\u001b[0m 167/381 [============>.................] - ETA: 0s - loss: 0.1827 - accuracy: 0.9400\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=31244)\u001b[0m 205/381 [===============>..............] - ETA: 0s - loss: 0.1682 - accuracy: 0.9456\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m 180/381 [=============>................] - ETA: 0s - loss: 0.1921 - accuracy: 0.9425\u001b[32m [repeated 26x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m 224/381 [================>.............] - ETA: 0s - loss: 0.1695 - accuracy: 0.9483\u001b[32m [repeated 25x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=4504)\u001b[0m 230/381 [=================>............] - ETA: 0s - loss: 0.1774 - accuracy: 0.9497\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=31244)\u001b[0m 273/381 [====================>.........] - ETA: 0s - loss: 0.1668 - accuracy: 0.9465\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35088)\u001b[0m 292/381 [=====================>........] - ETA: 0s - loss: 0.1595 - accuracy: 0.9498\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28804)\u001b[0m 321/381 [========================>.....] - ETA: 0s - loss: 0.1821 - accuracy: 0.9381\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=31244)\u001b[0m 305/381 [=======================>......] - ETA: 0s - loss: 0.1669 - accuracy: 0.9471\u001b[32m [repeated 32x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=15636)\u001b[0m 259/381 [===================>..........] - ETA: 0s - loss: 0.1781 - accuracy: 0.9513\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28804)\u001b[0m 361/381 [===========================>..] - ETA: 0s - loss: 0.1812 - accuracy: 0.9381\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m 338/381 [=========================>....] - ETA: 0s - loss: 0.1737 - accuracy: 0.9474\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=35088)\u001b[0m 375/381 [============================>.] - ETA: 0s - loss: 0.1578 - accuracy: 0.9510\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=31244)\u001b[0m 102/381 [=======>......................] - ETA: 0s - loss: 0.1676 - accuracy: 0.9450\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=27348)\u001b[0m Client  9 Evaluating...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=27348)\u001b[0m Client  9 Evaluating...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m Client  9 Evaluating...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27348)\u001b[0m  88/381 [=====>........................] - ETA: 0s - loss: 0.1994 - accuracy: 0.9379\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=30332)\u001b[0m Client  4 Training complete...\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=35088)\u001b[0m Client ID: 2\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=35088)\u001b[0m Client  2 Evaluating...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=15636)\u001b[0m  50/381 [==>...........................] - ETA: 0s - loss: 0.2024 - accuracy: 0.9459  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-07-08 15:23:04,372 | server.py:182 | evaluate_round 10 received 5 results and 0 failures\n",
      "INFO flwr 2023-07-08 15:23:04,373 | server.py:147 | FL finished in 232.01294979999875\n",
      "INFO flwr 2023-07-08 15:23:04,374 | app.py:218 | app_fit: losses_distributed [(1, 0.4529240369796753), (2, 0.4178868234157562), (3, 0.39630854725837705), (4, 0.37226383090019227), (5, 0.34312092007480566), (6, 0.3164464056491852), (7, 0.3025070667266846), (8, 0.264240980523829), (9, 0.24068239479652787), (10, 0.17945314726750933)]\n",
      "INFO flwr 2023-07-08 15:23:04,376 | app.py:219 | app_fit: metrics_distributed_fit {}\n",
      "INFO flwr 2023-07-08 15:23:04,377 | app.py:220 | app_fit: metrics_distributed {}\n",
      "INFO flwr 2023-07-08 15:23:04,377 | app.py:221 | app_fit: losses_centralized [(0, 3.512744188308716), (1, 0.45169058442115784), (2, 0.418056458234787), (3, 0.39816784858703613), (4, 0.37313494086265564), (5, 0.35645580291748047), (6, 0.3363931179046631), (7, 0.31970104575157166), (8, 0.2995775043964386), (9, 0.26678675413131714), (10, 0.20413264632225037)]\n",
      "INFO flwr 2023-07-08 15:23:04,378 | app.py:222 | app_fit: metrics_centralized {'accuracy': [(0, 0.013934269547462463), (1, 0.7998551726341248), (2, 0.8190845251083374), (3, 0.8267609477043152), (4, 0.854365348815918), (5, 0.8565294146537781), (6, 0.8717416524887085), (7, 0.8790432214736938), (8, 0.9015527367591858), (9, 0.9239813685417175), (10, 0.9552195072174072)]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=35088)\u001b[0m Client  2 Evaluating complete... 0.9543197154998779 0.1708652675151825\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "History (loss, distributed):\n",
       "\tround 1: 0.4529240369796753\n",
       "\tround 2: 0.4178868234157562\n",
       "\tround 3: 0.39630854725837705\n",
       "\tround 4: 0.37226383090019227\n",
       "\tround 5: 0.34312092007480566\n",
       "\tround 6: 0.3164464056491852\n",
       "\tround 7: 0.3025070667266846\n",
       "\tround 8: 0.264240980523829\n",
       "\tround 9: 0.24068239479652787\n",
       "\tround 10: 0.17945314726750933\n",
       "History (loss, centralized):\n",
       "\tround 0: 3.512744188308716\n",
       "\tround 1: 0.45169058442115784\n",
       "\tround 2: 0.418056458234787\n",
       "\tround 3: 0.39816784858703613\n",
       "\tround 4: 0.37313494086265564\n",
       "\tround 5: 0.35645580291748047\n",
       "\tround 6: 0.3363931179046631\n",
       "\tround 7: 0.31970104575157166\n",
       "\tround 8: 0.2995775043964386\n",
       "\tround 9: 0.26678675413131714\n",
       "\tround 10: 0.20413264632225037\n",
       "History (metrics, centralized):\n",
       "{'accuracy': [(0, 0.013934269547462463), (1, 0.7998551726341248), (2, 0.8190845251083374), (3, 0.8267609477043152), (4, 0.854365348815918), (5, 0.8565294146537781), (6, 0.8717416524887085), (7, 0.8790432214736938), (8, 0.9015527367591858), (9, 0.9239813685417175), (10, 0.9552195072174072)]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import flwr as fl\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "print('scikit-learn {}.'.format(sklearn.__version__))\n",
    "print(\"flwr\", fl.__version__)\n",
    "print(\"numpy\", np.__version__)\n",
    "print(\"tf\", tf.__version__)\n",
    "# Make TensorFlow log less verbose\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "\n",
    "class NumpyFlowerClient(fl.client.NumPyClient):\n",
    "    def __init__(self, cid, model, train_data, train_labels):\n",
    "        self.model = model\n",
    "        self.cid = cid\n",
    "        self.train_data = train_data\n",
    "        self.train_labels = train_labels\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        return self.model.get_weights()\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        self.model.set_weights(parameters)\n",
    "        print (\"Client \", self.cid, \"Training...\")\n",
    "        self.model.fit(self.train_data, self.train_labels, epochs=10, batch_size=64)\n",
    "        print (\"Client \", self.cid, \"Training complete...\")\n",
    "        return self.model.get_weights(), len(self.train_data), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        self.model.set_weights(parameters)\n",
    "        print (\"Client \", self.cid, \"Evaluating...\")\n",
    "        loss, accuracy = self.model.evaluate(self.train_data, self.train_labels, batch_size=64)\n",
    "        print (\"Client \", self.cid, \"Evaluating complete...\", accuracy, loss)\n",
    "        return loss, len(self.train_data), {\"accuracy\": accuracy}\n",
    "    \n",
    "    def predict(self, incoming):\n",
    "        prediction = np.argmax( self.model.predict(incoming) ,axis=1)\n",
    "        return prediction\n",
    "\n",
    "def client_fn(cid: str) -> NumpyFlowerClient:\n",
    "    \"\"\"Create a Flower client representing a single organization.\"\"\"\n",
    "\n",
    "    # Load model\n",
    "    #model = tf.keras.applications.MobileNetV2((32, 32, 3), classes=10, weights=None)\n",
    "    #model.compile(\"adam\", \"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    print (\"Client ID:\", cid)\n",
    "\n",
    "    model = Sequential([\n",
    "      #Flatten(input_shape=(79,1)),\n",
    "      Flatten(input_shape=(fl_X_train[0].shape[1] , 1)),\n",
    "      Dense(50, activation='relu'),  \n",
    "      Dense(25, activation='relu'),  \n",
    "      Dense(len(label.unique()), activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "   \n",
    "    partition_id = int(cid)\n",
    "    X_train_c = fl_X_train[partition_id]\n",
    "    y_train_c = fl_y_train[partition_id]\n",
    "\n",
    "    # Create a  single Flower client representing a single organization\n",
    "    return NumpyFlowerClient(cid, model, X_train_c, y_train_c)\n",
    "\n",
    "\n",
    "print (\"Deploy simulation...\")\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "eval_count = 0\n",
    "\n",
    "def get_evaluate_fn(server_model):\n",
    "    global eval_count\n",
    "    \"\"\"Return an evaluation function for server-side evaluation.\"\"\"\n",
    "    # The `evaluate` function will be called after every round\n",
    "    \n",
    "    \n",
    "    def evaluate(server_round, parameters, config):\n",
    "        global eval_count\n",
    "        \n",
    "        # Update model with the latest parameters\n",
    "        server_model.set_weights(parameters)\n",
    "        print (\"Server Evaluating...\", eval_count)\n",
    "        loss, accuracy = server_model.evaluate(X_test, y_test)\n",
    "        \n",
    "        y_pred = server_model.predict(X_test)\n",
    "        print (\"Prediction: \", y_pred, y_pred.shape)\n",
    "        #cmatrix = confusion_matrix(y_test, np.rint(y_pred))\n",
    "        #print (\"confusion_matrix:\", cmatrix, cmatrix.shape)\n",
    "                        \n",
    "        print (\"Server Evaluating complete...\", accuracy, loss)\n",
    "        \n",
    "        np.save(\"y_pred-\" + str(eval_count) + \".npy\", y_pred)\n",
    "        #np.save(\"cmatrix-\" + str(eval_count) + \".npy\", cmatrix)\n",
    "        eval_count = eval_count + 1\n",
    "        \n",
    "        return loss, {\"accuracy\": accuracy}\n",
    "    return evaluate\n",
    "\n",
    "\n",
    "\n",
    "server_model = Sequential([\n",
    "    #Flatten(input_shape=(79,1)),\n",
    "    Flatten(input_shape=(fl_X_train[0].shape[1] , 1)),\n",
    "    Dense(50, activation='relu'),  \n",
    "    Dense(25, activation='relu'),  \n",
    "    Dense(len(label.unique()), activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "server_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "# Create FedAvg strategy\n",
    "strategy = fl.server.strategy.FedAvg(\n",
    "        fraction_fit=1.0,\n",
    "        fraction_evaluate=0.5,\n",
    "        min_fit_clients=2, #10,\n",
    "        min_evaluate_clients=2, #5,\n",
    "        min_available_clients=2, #10,\n",
    "        evaluate_fn=get_evaluate_fn(server_model),\n",
    "        #evaluate_metrics_aggregation_fn=weighted_average,\n",
    ")\n",
    "\n",
    "# Start simulation\n",
    "fl.simulation.start_simulation(\n",
    "    client_fn=client_fn,\n",
    "    num_clients=NUM_OF_CLIENTS,\n",
    "    config=fl.server.ServerConfig(num_rounds=NUM_OF_ROUNDS),\n",
    "    strategy=strategy,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
